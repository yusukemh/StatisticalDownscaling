{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#others\n",
    "from xgboost import XGBRegressor\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "import time\n",
    "import xarray as xr\n",
    "import sherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models {RandomForestRegressor, GradientBoostingRegressor, XGBRegressor}\n",
    "# Datasets {original, +elev, +seasonality, 6grids, Linear-Interpolation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hyperparameter Tuning on Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 865561 samples.\n",
      "Each sample is associated with lat and lon coordinates.\n",
      "Use only the closest observation to represent each field, from 16 different NetCDF files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Variables from config file\n",
    "BASE_DIR = \"/home/yusukemh/github/yusukemh/StatisticalDownscaling/dataset\"\n",
    "\n",
    "# Load the dataset\n",
    "df_metadata = pd.read_excel(f\"{BASE_DIR}/FilledDataset2012.xlsx\", sheet_name=\"Header\")\n",
    "df_data_original = pd.read_csv(f\"{BASE_DIR}/dataset.csv\")\n",
    "\n",
    "# make sure there is no NaN value\n",
    "assert df_data_original.isnull().values.any() == False\n",
    "print(f\"There are {df_data_original.shape[0]} samples.\")\n",
    "print(\n",
    "    \"Each sample is associated with lat and lon coordinates.\\n\" + \n",
    "    \"Use only the closest observation to represent each field, from 16 different NetCDF files.\", )\n",
    "\n",
    "df_combined = df_data_original.merge(right=df_metadata[[\"SKN\", \"ElevFT\"]], left_on=\"skn\", right_on=\"SKN\")\n",
    "df_clean = (\n",
    "    df_combined.drop(\n",
    "        labels=[\"lat\", \"lon\", \"year\", \"month\", \"SKN\", \"skn\", \"Lon_DD_updated\"],\n",
    "        axis=1\n",
    "    ).rename(\n",
    "        columns={\"Lat_DD\": \"lat\", \"Lon_DD\": \"lon\", \"ElevFT\": \"elev\"}\n",
    "    )\n",
    ")\n",
    "\n",
    "# split the dataset without \"elev\"\n",
    "X = np.array(df_clean.drop(labels=[\"data_in\", \"elev\"], axis=1))\n",
    "Y = np.array(df_clean[\"data_in\"])\n",
    "\n",
    "Xtemp, Xtest, Ytemp, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtemp, Ytemp, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 RadomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sherpa.core:\n",
      "-------------------------------------------------------\n",
      "SHERPA Dashboard running. Access via\n",
      "http://10.100.11.206:8880 if on a cluster or\n",
      "http://localhost:8880 if running locally.\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'sherpa.app.app' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:werkzeug: * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 160, 'max_depth': None, 'min_samples_split': 5, 'verbose': True, 'n_jobs': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.9s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 160 out of 160 | elapsed:    7.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=8)]: Done 160 out of 160 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 280, 'max_depth': None, 'min_samples_split': 8, 'verbose': True, 'n_jobs': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:  3.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 290, 'max_depth': None, 'min_samples_split': 4, 'verbose': True, 'n_jobs': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 290 out of 290 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=8)]: Done 290 out of 290 | elapsed:   14.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=8)]: Done 290 out of 290 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 70, 'max_depth': None, 'min_samples_split': 5, 'verbose': True, 'n_jobs': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   55.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done  70 out of  70 | elapsed:    3.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done  70 out of  70 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'max_depth': None, 'min_samples_split': 6, 'verbose': True, 'n_jobs': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'max_depth': None, 'min_samples_split': 2, 'verbose': True, 'n_jobs': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.0min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:   19.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    6.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 280, 'max_depth': None, 'min_samples_split': 3, 'verbose': True, 'n_jobs': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed:  3.7min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:   14.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=8)]: Done 280 out of 280 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 150, 'max_depth': None, 'min_samples_split': 3, 'verbose': True, 'n_jobs': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:   10.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 150 out of 150 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 250, 'max_depth': None, 'min_samples_split': 9, 'verbose': True, 'n_jobs': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "file_name = './hyperparametertuning/RFR_original.txt'\n",
    "\n",
    "parameters = [\n",
    "    sherpa.Choice('n_estimators', list(range(50, 310, 10))),\n",
    "    sherpa.Discrete('min_samples_split', [2, 10])\n",
    "]\n",
    "alg = sherpa.algorithms.RandomSearch(max_num_trials=50)\n",
    "study = sherpa.Study(parameters=parameters,\n",
    "                     algorithm=alg,\n",
    "                     lower_is_better=True)\n",
    "\n",
    "for trial in study:\n",
    "    start = time.time()\n",
    "    line = '===============================================\\n'\n",
    "    params = {\n",
    "        \"n_estimators\": trial.parameters['n_estimators'],\n",
    "        \"max_depth\": None,\n",
    "        \"min_samples_split\": trial.parameters[\"min_samples_split\"],\n",
    "        \"verbose\": True,\n",
    "        \"n_jobs\": -1\n",
    "    }\n",
    "    print(params)\n",
    "    line += str(params) + '\\n'\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    training_error = mean_squared_error(Ytrain, model.predict(Xtrain))\n",
    "    validation_error = mean_squared_error(Yvalid, model.predict(Xvalid))\n",
    "    study.add_observation(\n",
    "        trial=trial,\n",
    "        iteration=1,\n",
    "        objective=validation_error,\n",
    "        context={'training_error': training_error}\n",
    "    )\n",
    "    end = time.time()\n",
    "    line += \"MSE on training set  : {:.6f}\".format(training_error) + '\\n'\n",
    "    line += \"MSE on validation set: {:.6f}\".format(validation_error) + '\\n'\n",
    "    line += \"elapsed time         : {:.3f}\".format(end - start) + '\\n'\n",
    "    \n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write(line)\n",
    "\n",
    "    study.finalize(trial)\n",
    "\n",
    "print(study.get_best_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
