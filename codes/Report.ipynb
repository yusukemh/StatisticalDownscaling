{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# Project Report\n",
    "##### Yusuke Hatanaka at University of Hawaii at Manoa\n",
    "### Table of contents\n",
    "\n",
    "- <a href='#project_overview'><u style=\"color:white\">Project Overview</u></a>\n",
    "- <a href='#model_comparison'><u style=\"color:white\">Model Comparison</u></a>\n",
    "    - <a href='#aggregate'>Aggregate Model<u style=\"color:white\"></u></a>\n",
    "    - <a href='#site_specific'>Site-Specific Model<u style=\"color:white\"></u></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"project_overview\"></a>\n",
    "## Project Overview\n",
    "<a href='#top'>Return to top<u style=\"color:white\"></u></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write down stuff here and define some datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# others\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "from copy import deepcopy\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Variables from config file\n",
    "from config import BASE_DIR, FILE_NAMES, LABELS, ATTRIBUTES, BEST_MODEL_COLUMNS, ISLAND_RANGES, C_SINGLE, C_INT50, C_INT100, C_GRID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model_comparison\"></a>\n",
    "## Model Comparison\n",
    "<a id='aggregate'></a>\n",
    "### 1. Aggregate model\n",
    "##### Aggregate models refer to a single model making prediction on all of the stations, as opposed to site-specific models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#top'>Return to top<u style=\"color:white\"></u></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset Type: SINGLE\n",
    "columns = C_SINGLE\n",
    "\n",
    "# load datasets\n",
    "df_train = pd.read_csv(f\"{BASE_DIR}/train.csv\", usecols=columns + ['data_in'])\n",
    "df_valid = pd.read_csv(f\"{BASE_DIR}/valid.csv\", usecols=columns + ['data_in'])\n",
    "df_test = pd.read_csv(f\"{BASE_DIR}/test.csv\", usecols=columns + ['data_in'])\n",
    "df_combined = pd.concat([df_train, df_valid, df_test]).sort_values(by=['year', 'month'])\n",
    "\n",
    "X = np.array(df_combined[columns])\n",
    "Y = np.array(df_combined['data_in'])\n",
    "\n",
    "# Lienar Regression\n",
    "linear_regression = LinearRegression()\n",
    "yhat_linear_regression = cross_val_predict(linear_regression, X, Y, n_jobs=-1)\n",
    "\n",
    "# Random Forest Regressor\n",
    "random_forest = RandomForestRegressor(\n",
    "    n_estimators=180,\n",
    "    max_depth=None,\n",
    "    min_samples_split=4,\n",
    "    n_jobs=-1,\n",
    "    verbose=False,\n",
    ")\n",
    "yhat_random_forest = cross_val_predict(random_forest, X, Y, n_jobs=-1)\n",
    "\n",
    "# Gradient Boosted Trees\n",
    "gradient_boost = GradientBoostingRegressor(\n",
    "    n_estimators=170, \n",
    "    learning_rate=0.1,\n",
    "    max_depth=7,\n",
    "    min_samples_split=3,\n",
    "    verbose=False\n",
    ")\n",
    "yhat_gbt = cross_val_predict(gradient_boost, X, Y, n_jobs=-1)\n",
    "\n",
    "# XGBoost\n",
    "xgboost = XGBRegressor(\n",
    "    n_estimators=280,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=9,\n",
    "    verbosity=0\n",
    ")\n",
    "yhat_xgb = cross_val_predict(xgboost, X, Y, n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='site_specific'></a>\n",
    "### 2. Site-Specific models\n",
    "##### Site-Specific models are trained over all the stations, where each model trains and makes prediction on the data solely from the specific station.\n",
    "<a href='#top'>Return to top<u style=\"color:white\"></u></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.749854531885"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset Type: SINGLE\n",
    "columns = C_SINGLE\n",
    "\n",
    "# load datasets\n",
    "df_train = pd.read_csv(f\"{BASE_DIR}/train.csv\", usecols=columns + ['data_in'])\n",
    "df_valid = pd.read_csv(f\"{BASE_DIR}/valid.csv\", usecols=columns + ['data_in'])\n",
    "df_test = pd.read_csv(f\"{BASE_DIR}/test.csv\", usecols=columns + ['data_in'])\n",
    "df_combined = pd.concat([df_train, df_valid, df_test]).sort_values(by=['year', 'month'])\n",
    "\n",
    "for i, (skn, group) in enumerate(df_combined.groupby('skn')):\n",
    "    if \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset Type: INT50\n",
    "# dataset Type: INT100\n",
    "# dataset Type: GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use cross_val_predict to run experiments for ALL of the models: LR, RF, GBT, XGB, NN\n",
    "# report the running time as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open the file.\n",
    "2. Find the following code block on line 21:\n",
    "\n",
    "        <html>\n",
    "          <head>\n",
    "            <title>Test</title>\n",
    "          </head>\n",
    "\n",
    "3. Update the title to match the name of your website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is it so different:\n",
    "\n",
    "        for i in range(10):\n",
    "            print(f\"Hello World{i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp",
   "language": "python",
   "name": "tfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
