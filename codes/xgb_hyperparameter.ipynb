{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#others\n",
    "from xgboost import XGBRegressor\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "import time\n",
    "import xarray as xr\n",
    "import sherpa\n",
    "import time\n",
    "from scipy.spatial import Delaunay\n",
    "from scipy import interpolate\n",
    "from copy import deepcopy\n",
    "\n",
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Variables from config file\n",
    "from config import BASE_DIR, FILE_NAMES, LABELS, ATTRIBUTES, BEST_MODEL_COLUMNS, ISLAND_RANGES\n",
    "from math import pi as PI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore hyperparameter tuning for site-specific xgb models\n",
    "\n",
    "Site specific linear regression models performs better than single-xgb for the stations with higher numbers of samples. <br>\n",
    "<u>This is the case even if we have site-specific xgb models with shared hyperparameter.</u><br>\n",
    "Since a single xgb makes prediction for all stations, the model might not be using optimal hyperparameter in terms of the number of samples.<br>\n",
    "From now on, we test:\n",
    "### If we have site-specific xgb models with different hyperparameters (that are obtained via hyperparameter tuning), can xgb outperform linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using site-specific Linear Regression models: 4.098\n",
      "RMSE using a sigle XGBost model: 3.998\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result = pd.read_csv(f\"{BASE_DIR}/SiteSpecific/result.csv\")\n",
    "\n",
    "rmse_per_station_linear = df_result.groupby(by=\"skn\").apply(lambda group: mean_squared_error(group['data_in'], group['prediction_multi_linear'], squared=False))\n",
    "rmse_per_station_xgb = df_result.groupby(by=\"skn\").apply(lambda group: mean_squared_error(group['data_in'], group['prediction_single_xgb'], squared=False))\n",
    "n_data = df_result.groupby(by=\"skn\").size()\n",
    "df_rmse = pd.DataFrame({\"n_data\": n_data, \"rmse_linear\": rmse_per_station_linear, \"rmse_xgb\": rmse_per_station_xgb})\n",
    "df_rmse['diff'] = df_rmse['rmse_linear'] - df_rmse['rmse_xgb']\n",
    "\n",
    "rmse_linear = mean_squared_error(df_result['data_in'], df_result['prediction_multi_linear'], squared=False)\n",
    "rmse_xgb = mean_squared_error(df_result['data_in'], df_result['prediction_single_xgb'], squared=False)\n",
    "\n",
    "print(\"RMSE using site-specific Linear Regression models: {:.3f}\".format(rmse_linear))\n",
    "print(\"RMSE using a sigle XGBost model: {:.3f}\".format(rmse_xgb))\n",
    "\n",
    "# df_stats = df_combined.groupby('skn').size().reset_index().rename(columns={0:\"n_data\"}).groupby(\"n_data\").size().reset_index().rename(columns={0: \"n_stations\"})\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(20,5))\n",
    "ax.bar(\n",
    "    x=df_rmse['n_data'],\n",
    "    height=df_rmse['diff'],\n",
    "    width=1,\n",
    "    color=['b' if item >= 0 else 'r' for item in df_rmse['diff']],\n",
    "    alpha=0.3\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_ylim((-100, 200))\n",
    "ax.axhline(y=0, linestyle='-', linewidth=1, color='k', alpha=0.2)\n",
    "ax.axvline(127, linewidth=1, color='orange')\n",
    "ax.set_xlabel('# of samples')\n",
    "ax.set_ylabel('RMSE in inch')\n",
    "# ax.axhline(y=100, linewidth=1, linestyle='--')\n",
    "    \n",
    "ax.set_title(\"RMSE(linear - xgb) per station: 5-fold cross validation\")\n",
    "ax.set(yscale='symlog')\n",
    "# plt.tight_layout()\n",
    "\n",
    "# ax.scatter(df_stats['n_data'], df_stats['n_stations'], s=1, c='k', marker='x')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air2m air1000_500 hgt500 hgt1000 omega500 pottemp1000-500 pottemp1000-850 pr_wtr shum-uwnd-700 shum-uwnd-925 shum-vwnd-700 shum-vwnd-950 shum700 shum925 skt slp season_wet elevation lat lon "
     ]
    }
   ],
   "source": [
    "# Split the stations by the number of samples available\n",
    "columns = deepcopy(LABELS)\n",
    "columns.extend([\"season_wet\", \"elevation\", \"lat\", \"lon\"])\n",
    "for item in columns:\n",
    "    print(item, end=' ')\n",
    "\n",
    "# load datasets\n",
    "df_train = pd.read_csv(f\"{BASE_DIR}/train.csv\", usecols=columns + ['year', 'month', 'skn', 'data_in'])\n",
    "df_valid = pd.read_csv(f\"{BASE_DIR}/valid.csv\", usecols=columns + ['year', 'month', 'skn', 'data_in'])\n",
    "df_test = pd.read_csv(f\"{BASE_DIR}/test.csv\", usecols=columns + ['year', 'month', 'skn', 'data_in'])\n",
    "df_combined = pd.concat([df_train, df_valid, df_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skn selsction:\n",
    "1. Split the entire data into two: everything 2007 (inclusive) and everything after 2007 (exclusive)\n",
    "2. select the stations which exist both on the test set and the training set, AND which have more than 400 training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare held-out test set: any data after 2007 (exclusive)\n",
    "df_train_original = df_combined[df_combined['year'] <= 2007]\n",
    "df_test_original = df_combined[df_combined['year'] > 2007]\n",
    "\n",
    "# get the intersection\n",
    "intersection = set(df_test_original['skn'].unique()).intersection(set(df_train_original['skn'].unique()))\n",
    "df_intersection_skn = pd.DataFrame(intersection, columns={\"skn\"})\n",
    "\n",
    "df_train_intersection = df_train_original.merge(right=df_intersection_skn, left_on='skn', right_on='skn')\n",
    "df_test_intersection = df_test_original.merge(right=df_intersection_skn, left_on='skn', right_on='skn')\n",
    "\n",
    "# prune stations without enough data\n",
    "threshold = 400\n",
    "df_train_intersection_skn = df_train_intersection.groupby('skn').size().reset_index().rename(columns={0: \"n_samples\"})\n",
    "df_train_intersection_skn_high_samples = df_train_intersection_skn[df_train_intersection_skn[\"n_samples\"] > threshold]\n",
    "df_train = df_train_intersection.merge(right=df_train_intersection_skn_high_samples, left_on='skn', right_on='skn')\n",
    "df_test = df_test_intersection.merge(right=df_train_intersection_skn_high_samples, left_on='skn', right_on='skn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(df_train['skn'].unique())\n",
    "b = set(df_test['skn'].unique())\n",
    "assert len(a - b) == 0\n",
    "assert len(b - a) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning:\n",
    "# for a specific parameter, get site-specific predictions using cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_skn_samples = pd.DataFrame(np.random.choice(df_train['skn'].unique(), size=30, replace=False), columns={\"skn\"})\n",
    "df_train_samples = df_train.merge(right=df_skn_samples, left_on='skn', right_on='skn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sherpa.core:\n",
      "-------------------------------------------------------\n",
      "SHERPA Dashboard running. Access via\n",
      "http://10.100.11.206:8880 if on a cluster or\n",
      "http://localhost:8880 if running locally.\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'sherpa.app.app' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:werkzeug: * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 250, 'learning_rate': 0.1, 'max_depth': 3, 'early_stopping_rounds': 6, 'verbosity': 0}\n",
      "RMSE on test set: 4.857173589587817\n",
      "{'n_estimators': 300, 'learning_rate': 0.05, 'max_depth': 4, 'early_stopping_rounds': 6, 'verbosity': 0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_131636/3051592670.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             model.fit(\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parameters = [\n",
    "    sherpa.Choice('n_estimators', list(range(100, 310, 10))),\n",
    "    sherpa.Choice('early_stopping_rounds', list(range(1, 10))),\n",
    "    sherpa.Choice('learning_rate', [0.05, 0.1]),\n",
    "    sherpa.Discrete('max_depth', [1, 5]),\n",
    "]\n",
    "\n",
    "\n",
    "alg = sherpa.algorithms.RandomSearch(max_num_trials=10)\n",
    "study = sherpa.Study(parameters=parameters,\n",
    "                     algorithm=alg,\n",
    "                     lower_is_better=True)\n",
    "\n",
    "n_folds = 5\n",
    "for trial in study:\n",
    "    # set up the hyperparameters\n",
    "    start = time.time()\n",
    "    line = '===============================================\\n'\n",
    "    params = {\n",
    "        \"n_estimators\": trial.parameters['n_estimators'],\n",
    "        \"learning_rate\": trial.parameters['learning_rate'],\n",
    "        \"max_depth\": trial.parameters['max_depth'],\n",
    "        \"early_stopping_rounds\": trial.parameters['early_stopping_rounds'],\n",
    "        \"verbosity\": 0\n",
    "    }\n",
    "    \n",
    "    print(params)\n",
    "    line += str(params) + '\\n'\n",
    "    \n",
    "    # stations with low number of samples\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for name, group in df_train_samples.groupby('skn'):\n",
    "        line = ''\n",
    "        group.sort_values(by=[\"year\", \"month\"], inplace=True)\n",
    "        \n",
    "        X = np.array(group[columns])\n",
    "        Y = np.array(group['data_in'])\n",
    "        \n",
    "        kf = KFold(n_splits=5)\n",
    "#         for temp_index, test_index in kf.split(X):\n",
    "#             train_index, valid_index = train_test_split(temp_index, test_size=0.2, shuffle=False)\n",
    "#             Xtrain, Xvalid, Xtest = X[train_index], X[valid_index], X[test_index]\n",
    "#             Ytrain, Yvalid, Ytest = Y[train_index], Y[valid_index], Y[test_index]\n",
    "            \n",
    "#             model = XGBRegressor(**params)\n",
    "#             model.fit(\n",
    "#                 Xtrain,\n",
    "#                 Ytrain,\n",
    "#                 eval_set=[(Xtrain, Ytrain), (Xvalid, Yvalid)],\n",
    "#                 early_stopping_rounds=trial.parameters['early_stopping_rounds'],\n",
    "#                 verbose=False\n",
    "#             )\n",
    "            \n",
    "#             y_true.extend(Ytest)\n",
    "#             y_pred.extend(model.predict(Xtest))\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            Xtrain, Xtest = X[train_index], X[test_index]\n",
    "            Ytrain, Ytest = Y[train_index], Y[test_index]\n",
    "            model = XGBRegressor(**params)\n",
    "            model.fit(\n",
    "                Xtrain, Ytrain,\n",
    "                eval_set=[(Xtrain, Ytrain), (Xtest, Ytest)],\n",
    "                # early_stopping_rounds=trial.parameters['early_stopping_rounds'],\n",
    "                verbose=False,\n",
    "                # eval_metric=\"rmse\"\n",
    "            )\n",
    "            \n",
    "            y_true.extend(Ytest)\n",
    "            y_pred.extend(model.predict(Xtest))\n",
    "            \n",
    "        # print('===========')\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    print(f\"RMSE on test set: {rmse}\")\n",
    "    \n",
    "    study.add_observation(\n",
    "        trial=trial,\n",
    "        iteration=1,\n",
    "        objective=rmse,\n",
    "        # context={'rmse_high': rmse_high}\n",
    "    )\n",
    "\n",
    "    study.finalize(trial)\n",
    "\n",
    "# print(study.get_best_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'n_estimators': 200, 'learning_rate': 0.05, 'max_depth': 5, 'early_stopping_rounds': 4, 'verbosity': 0}\n",
    "params = {'n_estimators': 250, 'learning_rate': 0.1, 'max_depth': 3, 'early_stopping_rounds': 6, 'verbosity': 0}\n",
    "params = {'n_estimators': 260, 'learning_rate': 0.1, 'max_depth': 3, 'early_stopping_rounds': 8, 'verbosity': 0}\n",
    "# y_pred = []\n",
    "# y_true = []\n",
    "df_xgb = []\n",
    "df_xgb_train = []\n",
    "\n",
    "for name, group in df_train.groupby('skn'):\n",
    "    \n",
    "    group.sort_values(by=[\"year\", \"month\"], inplace=True)\n",
    "    xgboost = XGBRegressor(**params)\n",
    "    Xtemp = np.array(group[columns])\n",
    "    Ytemp = np.array(group['data_in'])\n",
    "    \n",
    "    Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtemp, Ytemp, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    Xtest = np.array(df_test[df_test['skn'] == name][columns])\n",
    "    Ytest = np.array(df_test[df_test['skn'] == name]['data_in'])\n",
    "    xgboost.fit(Xtrain, Ytrain, eval_set=[(Xtrain, Ytrain), (Xvalid, Yvalid)], early_stopping_rounds=params['early_stopping_rounds'], verbose=False)\n",
    "    \n",
    "    yhat = xgboost.predict(Xtest)\n",
    "    \n",
    "    df_xgb.append(pd.DataFrame({\"skn\": [name] * len(Ytest), \"pred\": yhat, \"data_in\": Ytest}))\n",
    "    df_xgb_train.append(pd.DataFrame({\"skn\": [name] * len(Ytrain), \"pred\": xgboost.predict(Xtrain), \"data_in\": Ytrain}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.922172061254523"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xgb = pd.concat(df_xgb)\n",
    "mean_squared_error(df_xgb['data_in'], df_xgb['pred'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "df_linear = []\n",
    "df_linear_train = []\n",
    "for name, group in df_train.groupby('skn'):\n",
    "    linear_regression = LinearRegression()\n",
    "    group.sort_values(by=[\"year\", \"month\"], inplace=True)\n",
    "    Xtrain = np.array(group[columns])\n",
    "    Ytrain = np.array(group['data_in'])\n",
    "    \n",
    "    Xtest = np.array(df_test[df_test['skn'] == name][columns])\n",
    "    Ytest = np.array(df_test[df_test['skn'] == name]['data_in'])\n",
    "    \n",
    "    linear_regression.fit(Xtrain, Ytrain)\n",
    "    \n",
    "    yhat = linear_regression.predict(Xtest)\n",
    "    \n",
    "    y_pred.extend(yhat)\n",
    "    y_true.extend(Ytest)\n",
    "    \n",
    "    df_linear.append(pd.DataFrame({\"skn\": [name] * len(Ytest), \"pred\": yhat, \"data_in\": Ytest}))\n",
    "    df_linear_train.append(pd.DataFrame({\"skn\": [name] * len(Ytrain), \"pred\": linear_regression.predict(Xtrain), \"data_in\": Ytrain}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7977115828253067"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_linear = pd.concat(df_linear)\n",
    "df_linear_train = pd.concat(df_linear_train)\n",
    "mean_squared_error(df_linear['data_in'], df_linear['pred'], squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use only the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_excel(f\"{BASE_DIR}/FilledDataset2012.xlsx\", sheet_name=\"Source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for index, row in df_original.iterrows():\n",
    "    if row.Year < 1948:\n",
    "        # No need to keep data older than 1948 becase no data exists in netCDF files\n",
    "        continue\n",
    "    for i, cell in enumerate(row[2:]):\n",
    "        X.append([row.SKN, row.Year, i + 1, cell])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonan = pd.DataFrame(X, columns=['skn', 'year', 'month', 'method']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_method = [\n",
    "    'State/NCDC', 'State', 'NCDC', 'RAWS', 'Hydronet', 'SCAN', 'USGS',\n",
    "    'Hydronet/NCDC', 'HaleNet', 'HC&S', 'AlanMair', 'AlanMair/State',\n",
    "    'USGS/State', 'USGS/NCDC'\n",
    "]\n",
    "df_valid_method = pd.DataFrame({\"method\": valid_method})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_method = df_nonan.merge(right=df_valid_method, left_on='method', right_on='method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join with valid method\n",
    "df_data_valid = df_combined.merge(right=df_valid_method, left_on=[\"skn\", \"year\", \"month\"], right_on=['skn', 'year', 'month'])\n",
    "# inner join with valid station (more than 300 stations)\n",
    "threshold = 300\n",
    "df_skn_valid = df_combined_valid.groupby('skn').size().reset_index().rename(columns={0: \"n_samples\"})\n",
    "df_skn_valid = df_skn_valid[df_skn_valid['n_samples'] > threshold]\n",
    "\n",
    "df_data_valid = df_data_valid.merge(right=df_skn_valid, left_on='skn', right_on='skn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single predictor, split is random. (no chrono)\n",
    "params = {'n_estimators': 260, 'learning_rate': 0.1, 'max_depth': 3, 'early_stopping_rounds': 8, 'verbosity': 0}\n",
    "\n",
    "X = np.array(df_data_valid[columns])\n",
    "Y = np.array(df_data_valid['data_in'])\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgboost = XGBRegressor(**params)\n",
    "xgboost.fit(Xtrain, Ytrain)\n",
    "\n",
    "yhat = xgboost.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5407494159077513"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Ytest, yhat, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for name, group in df_data_valid.groupby('skn'):\n",
    "    group.sort_values([\"year\", \"month\"], inplace=True)\n",
    "    \n",
    "    X = np.array(group[columns])\n",
    "    Y = np.array(group['data_in'])\n",
    "    \n",
    "    xgboost = XGBRegressor(**params)\n",
    "    \n",
    "    yhat = cross_val_predict(xgboost, X, Y, n_jobs=-1)\n",
    "    \n",
    "    y_pred.extend(yhat)\n",
    "    y_true.extend(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.804589730797675"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single linear regression\n",
    "X = np.array(df_data_valid[columns])\n",
    "Y = np.array(df_data_valid['data_in'])\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(Xtrain, Ytrain)\n",
    "\n",
    "yhat = linear_regression.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.342004264021995"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Ytest, yhat, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.45024446475492"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# site-specific linear regression\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for name, group in df_data_valid.groupby('skn'):\n",
    "    if group.shape[0] < 10: continue\n",
    "    X = np.array(group[columns])\n",
    "    Y = np.array(group['data_in'])\n",
    "    \n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    linear_regression = LinearRegression()\n",
    "    linear_regression.fit(Xtrain, Ytrain)\n",
    "    yhat = linear_regression.predict(Xtest)\n",
    "    y_pred.extend(yhat)\n",
    "    y_true.extend(Ytest)\n",
    "\n",
    "mean_squared_error(y_pred, y_true, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
