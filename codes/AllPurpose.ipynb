{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-02 23:01:18.689270: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/tools/nmap/7.80/lib\n"
     ]
    }
   ],
   "source": [
    "# set the environment variable for warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# others\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "from copy import deepcopy\n",
    "import sherpa\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "import time\n",
    "from scipy.stats import gamma, norm, beta\n",
    "\n",
    "# Variables from config file\n",
    "sys.path.append('/home/yusukemh/github/yusukemh/StatisticalDownscaling/codes/')\n",
    "from config import BASE_DIR, FILE_NAMES, LABELS, ATTRIBUTES, BEST_MODEL_COLUMNS, ISLAND_RANGES, C_SINGLE, C_INT50, C_INT100, C_GRID, C_COMMON\n",
    "\n",
    "# util\n",
    "from util import cross_val_predict_for_nn, sample_station, estimate_epochs, define_model, define_hetero_model_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_air2m = xr.open_dataset(f\"{BASE_DIR}/air.2m.mon.mean.regridded.nc\")\n",
    "ds_air1000_500 = xr.open_dataset(f\"{BASE_DIR}/air.1000-500.mon.mean.nc\")\n",
    "ds_hgt500 = xr.open_dataset(f\"{BASE_DIR}/hgt500.mon.mean.nc\")\n",
    "ds_hgt1000 = xr.open_dataset(f\"{BASE_DIR}/hgt1000.mon.mean.nc\")\n",
    "ds_omega500 = xr.open_dataset(f\"{BASE_DIR}/omega500.mon.mean.nc\")\n",
    "ds_pottemp_1000_500 = xr.open_dataset(f\"{BASE_DIR}/pottmp.1000-500.mon.mean.nc\")\n",
    "ds_pottemp_1000_850 = xr.open_dataset(f\"{BASE_DIR}/pottmp.1000-850.mon.mean.nc\")\n",
    "ds_pwtr = xr.open_dataset(f\"{BASE_DIR}/pwtr.mon.mean.nc\")\n",
    "ds_u700 = xr.open_dataset(f\"{BASE_DIR}/shum_x_uwnd.700.mon.mean.nc\")\n",
    "ds_u925 = xr.open_dataset(f\"{BASE_DIR}/shum_x_uwnd.925.mon.mean.nc\")\n",
    "ds_v700 = xr.open_dataset(f\"{BASE_DIR}/shum_x_vwnd.700.mon.mean.nc\")\n",
    "ds_v950 = xr.open_dataset(f\"{BASE_DIR}/shum_x_vwnd.925.mon.mean.nc\")\n",
    "ds_shum700 = xr.open_dataset(f\"{BASE_DIR}/shum700.mon.mean.nc\")\n",
    "ds_shum925 = xr.open_dataset(f\"{BASE_DIR}/shum925.mon.mean.nc\")\n",
    "ds_skt = xr.open_dataset(f\"{BASE_DIR}/skt.mon.mean.regridded.nc\")\n",
    "ds_slp = xr.open_dataset(f\"{BASE_DIR}/slp.mon.mean.nc\")\n",
    "\n",
    "# ait temperature difference\n",
    "datasets = [ # list of tuples. (dataset object, attribute string in ds)\n",
    "    (ds_air2m, \"air\"), # surface air temperature 2m\n",
    "    (ds_air1000_500, \"air\"), # air temperature difference\n",
    "    (ds_hgt500, \"hgt\"), # geopotential height (500hPa)\n",
    "    (ds_hgt1000, \"hgt\"), # geopotential height (1000hPa)\n",
    "    (ds_omega500, \"omega\"), # omega\n",
    "    (ds_pottemp_1000_500, \"pottmp\"), # potential temperature difference 1000-500\n",
    "    (ds_pottemp_1000_850, \"pottmp\"), # potential temperature fifference 1000-850\n",
    "    (ds_pwtr, \"pr_wtr\"), # precipitable water\n",
    "    (ds_u700, \"shum\"), # zonal moisture (u) transport\n",
    "    (ds_u925, \"shum\"), # zonal moisture (u) transport\n",
    "    (ds_v700, \"shum\"), # meridional moisture (v) transport\n",
    "    (ds_v950, \"shum\"), # meridional moisture (v) transport\n",
    "    (ds_shum700, \"shum\"), # specific humidity: 700 hPa \n",
    "    (ds_shum925, \"shum\"), # specific humidity: 925 hPa\n",
    "    (ds_skt, \"skt\"), # skin temperature\n",
    "    (ds_slp, \"slp\") # sea level pressure\n",
    "]\n",
    "# combine all the cdf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (lat: 73, level: 1, lon: 144, time: 840)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n",
       "  * level    (level) float32 700.0\n",
       "  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n",
       "  * time     (time) datetime64[ns] 1948-01-01 1948-02-01 ... 2017-12-01\n",
       "Data variables:\n",
       "    shum     (time, level, lat, lon) float32 ...\n",
       "Attributes:\n",
       "    description:    Data is from NMC initialized reanalysis\\n(4x/day).  It co...\n",
       "    platform:       Model\n",
       "    Conventions:    COARDS\n",
       "    NCO:            4.2.6\n",
       "    history:        Sun Aug 26 20:22:35 2018: ncks -O -d level,700.000000 -d ...\n",
       "    title:          monthly mean shum from the NCEP Reanalysis\n",
       "    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n",
       "    dataset_title:  NCEP-NCAR Reanalysis 1</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-b4da56dc-0b96-4388-a1d1-ddc57e1c11b6' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-b4da56dc-0b96-4388-a1d1-ddc57e1c11b6' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>lat</span>: 73</li><li><span class='xr-has-index'>level</span>: 1</li><li><span class='xr-has-index'>lon</span>: 144</li><li><span class='xr-has-index'>time</span>: 840</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-bfad2530-3a33-41da-9726-cdb7b6bbb592' class='xr-section-summary-in' type='checkbox'  checked><label for='section-bfad2530-3a33-41da-9726-cdb7b6bbb592' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>90.0 87.5 85.0 ... -87.5 -90.0</div><input id='attrs-cb30f434-0378-482f-aa42-1c317ca163bf' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-cb30f434-0378-482f-aa42-1c317ca163bf' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d21d5538-519a-475a-9927-247c939c2c73' class='xr-var-data-in' type='checkbox'><label for='data-d21d5538-519a-475a-9927-247c939c2c73' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>axis :</span></dt><dd>Y</dd><dt><span>actual_range :</span></dt><dd>[ 90. -90.]</dd></dl></div><div class='xr-var-data'><pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n",
       "        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n",
       "        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n",
       "        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n",
       "       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n",
       "       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n",
       "       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n",
       "       -85. , -87.5, -90. ], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>level</span></div><div class='xr-var-dims'>(level)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>700.0</div><input id='attrs-b5d2b117-1ea8-47ff-acf1-43df46da0f4e' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b5d2b117-1ea8-47ff-acf1-43df46da0f4e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8889dbf0-8ca7-4a94-94f9-a1da24293cc2' class='xr-var-data-in' type='checkbox'><label for='data-8889dbf0-8ca7-4a94-94f9-a1da24293cc2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>millibar</dd><dt><span>long_name :</span></dt><dd>Level</dd><dt><span>positive :</span></dt><dd>down</dd><dt><span>GRIB_id :</span></dt><dd>100</dd><dt><span>GRIB_name :</span></dt><dd>hPa</dd><dt><span>axis :</span></dt><dd>Z</dd><dt><span>actual_range :</span></dt><dd>[700. 700.]</dd></dl></div><div class='xr-var-data'><pre>array([700.], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.0 2.5 5.0 ... 352.5 355.0 357.5</div><input id='attrs-eceef105-7970-4fda-b722-699781b2f032' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-eceef105-7970-4fda-b722-699781b2f032' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-09f0bb34-1be8-49c4-ac32-55d5347b3d6f' class='xr-var-data-in' type='checkbox'><label for='data-09f0bb34-1be8-49c4-ac32-55d5347b3d6f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>axis :</span></dt><dd>X</dd><dt><span>actual_range :</span></dt><dd>[  0.  357.5]</dd></dl></div><div class='xr-var-data'><pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n",
       "        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n",
       "        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n",
       "        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n",
       "       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n",
       "       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n",
       "       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n",
       "       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n",
       "       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n",
       "       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n",
       "       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n",
       "       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n",
       "       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n",
       "       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n",
       "       350. , 352.5, 355. , 357.5], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1948-01-01 ... 2017-12-01</div><input id='attrs-c6fae67c-febb-4f20-96bc-06638d273c3a' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c6fae67c-febb-4f20-96bc-06638d273c3a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1b3f3b6e-ed74-4ec5-b775-8afc436149f2' class='xr-var-data-in' type='checkbox'><label for='data-1b3f3b6e-ed74-4ec5-b775-8afc436149f2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Time</dd><dt><span>delta_t :</span></dt><dd>0000-01-00 00:00:00</dd><dt><span>avg_period :</span></dt><dd>0000-01-00 00:00:00</dd><dt><span>prev_avg_period :</span></dt><dd>0000-00-01 00:00:00</dd><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>axis :</span></dt><dd>T</dd><dt><span>actual_range :</span></dt><dd>[1297320. 1910208.]</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1948-01-01T00:00:00.000000000&#x27;, &#x27;1948-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;1948-03-01T00:00:00.000000000&#x27;, ..., &#x27;2017-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-11-01T00:00:00.000000000&#x27;, &#x27;2017-12-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-b414eef0-ebd9-44de-bb64-3e7ecc435eba' class='xr-section-summary-in' type='checkbox'  checked><label for='section-b414eef0-ebd9-44de-bb64-3e7ecc435eba' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>shum</span></div><div class='xr-var-dims'>(time, level, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-0d7daaf5-4498-4fc8-bb3d-4df20e412678' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-0d7daaf5-4498-4fc8-bb3d-4df20e412678' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4047ff6a-a9b4-45f9-8397-641dd4b5f73c' class='xr-var-data-in' type='checkbox'><label for='data-4047ff6a-a9b4-45f9-8397-641dd4b5f73c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Monthly Mean of Specific Humidity</dd><dt><span>units :</span></dt><dd>grams/kg</dd><dt><span>precision :</span></dt><dd>3</dd><dt><span>var_desc :</span></dt><dd>Specific Humidity</dd><dt><span>level_desc :</span></dt><dd>Multiple levels</dd><dt><span>statistic :</span></dt><dd>Mean</dd><dt><span>parent_stat :</span></dt><dd>Other</dd><dt><span>valid_range :</span></dt><dd>[-9.999999e-02  1.004300e+02]</dd><dt><span>dataset :</span></dt><dd>NCEP Reanalysis Derived Products</dd><dt><span>actual_range :</span></dt><dd>[7.9994202e-03 1.0523001e+01]</dd></dl></div><div class='xr-var-data'><pre>[8830080 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-20c1056a-9e5e-4cec-824b-55c529a44362' class='xr-section-summary-in' type='checkbox'  checked><label for='section-20c1056a-9e5e-4cec-824b-55c529a44362' class='xr-section-summary' >Attributes: <span>(8)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>description :</span></dt><dd>Data is from NMC initialized reanalysis\n",
       "(4x/day).  It consists of most variables interpolated to\n",
       "pressure surfaces from model (sigma) surfaces.</dd><dt><span>platform :</span></dt><dd>Model</dd><dt><span>Conventions :</span></dt><dd>COARDS</dd><dt><span>NCO :</span></dt><dd>4.2.6</dd><dt><span>history :</span></dt><dd>Sun Aug 26 20:22:35 2018: ncks -O -d level,700.000000 -d lat,-90.000000,90.000000 -d lon,0.000000,357.500000 -d time,0,839 /Datasets/ncep.reanalysis.derived/pressure/shum.mon.mean.nc /Public/www/X98.151.202.176.237.20.22.34.nc\n",
       "Mon Jul  5 22:28:55 1999: ncrcat shum.mon.mean.nc /Datasets/ncep.reanalysis.derived/pressure/shum.mon.mean.nc /dm/dmwork/nmc.rean.ingest/combinedMMs/shum.mon.mean.nc\n",
       "/home/hoop/crdc/cpreanjuke2farm/cpreanjuke2farm Tue Oct 17 20:07:08 1995 from shum.85.nc\n",
       "created 95/02/06 by Hoop (netCDF2.3)\n",
       "Converted to chunked, deflated non-packed NetCDF4 2014/09</dd><dt><span>title :</span></dt><dd>monthly mean shum from the NCEP Reanalysis</dd><dt><span>References :</span></dt><dd>http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.derived.html</dd><dt><span>dataset_title :</span></dt><dd>NCEP-NCAR Reanalysis 1</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 73, level: 1, lon: 144, time: 840)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n",
       "  * level    (level) float32 700.0\n",
       "  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n",
       "  * time     (time) datetime64[ns] 1948-01-01 1948-02-01 ... 2017-12-01\n",
       "Data variables:\n",
       "    shum     (time, level, lat, lon) float32 ...\n",
       "Attributes:\n",
       "    description:    Data is from NMC initialized reanalysis\\n(4x/day).  It co...\n",
       "    platform:       Model\n",
       "    Conventions:    COARDS\n",
       "    NCO:            4.2.6\n",
       "    history:        Sun Aug 26 20:22:35 2018: ncks -O -d level,700.000000 -d ...\n",
       "    title:          monthly mean shum from the NCEP Reanalysis\n",
       "    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n",
       "    dataset_title:  NCEP-NCAR Reanalysis 1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[12][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations = pd.read_csv(f\"{BASE_DIR}/SKNlocations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18.91367961, 22.23135314)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_locations['Lat_DD'].min(), df_locations['Lat_DD'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air2m_0 air1000_500_0 hgt500_0 hgt1000_0 omega500_0 pottemp1000-500_0 pottemp1000-850_0 pr_wtr_0 shum-uwnd-700_0 shum-uwnd-925_0 shum-vwnd-700_0 shum-vwnd-950_0 shum700_0 shum925_0 skt_0 slp_0 air2m_1 air1000_500_1 hgt500_1 hgt1000_1 omega500_1 pottemp1000-500_1 pottemp1000-850_1 pr_wtr_1 shum-uwnd-700_1 shum-uwnd-925_1 shum-vwnd-700_1 shum-vwnd-950_1 shum700_1 shum925_1 skt_1 slp_1 air2m_2 air1000_500_2 hgt500_2 hgt1000_2 omega500_2 pottemp1000-500_2 pottemp1000-850_2 pr_wtr_2 shum-uwnd-700_2 shum-uwnd-925_2 shum-vwnd-700_2 shum-vwnd-950_2 shum700_2 shum925_2 skt_2 slp_2 air2m_3 air1000_500_3 hgt500_3 hgt1000_3 omega500_3 pottemp1000-500_3 pottemp1000-850_3 pr_wtr_3 shum-uwnd-700_3 shum-uwnd-925_3 shum-vwnd-700_3 shum-vwnd-950_3 shum700_3 shum925_3 skt_3 slp_3 air2m_4 air1000_500_4 hgt500_4 hgt1000_4 omega500_4 pottemp1000-500_4 pottemp1000-850_4 pr_wtr_4 shum-uwnd-700_4 shum-uwnd-925_4 shum-vwnd-700_4 shum-vwnd-950_4 shum700_4 shum925_4 skt_4 slp_4 air2m_5 air1000_500_5 hgt500_5 hgt1000_5 omega500_5 pottemp1000-500_5 pottemp1000-850_5 pr_wtr_5 shum-uwnd-700_5 shum-uwnd-925_5 shum-vwnd-700_5 shum-vwnd-950_5 shum700_5 shum925_5 skt_5 slp_5 data_in lat lon elevation season_wet season_dry "
     ]
    }
   ],
   "source": [
    "reanalysis_data = [\n",
    "    'air2m', 'air1000_500', 'hgt500', 'hgt1000', 'omega500',\n",
    "    'pottemp1000-500', 'pottemp1000-850', 'pr_wtr', 'shum-uwnd-700',\n",
    "    'shum-uwnd-925', 'shum-vwnd-700', 'shum-vwnd-950', 'shum700', 'shum925', \n",
    "    'skt', 'slp'\n",
    "]\n",
    "\n",
    "columns = []\n",
    "for i in range(6):\n",
    "    for item in reanalysis_data:\n",
    "        columns.append(f\"{item}_{i}\")\n",
    "\n",
    "columns.extend(['data_in', 'lat', 'lon', 'elevation', 'season_wet', 'season_dry'])\n",
    "for item in columns:\n",
    "    print(item, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "df_train = pd.read_csv(f\"{BASE_DIR}/train.csv\", usecols=columns + ['year', 'month', 'skn', 'data_in'])\n",
    "df_valid = pd.read_csv(f\"{BASE_DIR}/valid.csv\", usecols=columns + ['year', 'month', 'skn', 'data_in'])\n",
    "df_test = pd.read_csv(f\"{BASE_DIR}/test.csv\", usecols=columns + ['year', 'month', 'skn', 'data_in'])\n",
    "df_combined = pd.concat([df_train, df_valid, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def process(i):\n",
    "    return i * i\n",
    "    \n",
    "results = Parallel(n_jobs=2)(delayed(process)(i) for i in range(10))\n",
    "print(results)  # prints [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 2, 2, 0, 2, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "n_cpu = cpu_count()\n",
    "def return_random_number(_):\n",
    "    return np.random.randint(3)\n",
    "with Pool(n_cpu) as p:\n",
    "    result = p.map(return_random_number, [_ for _ in range(n_cpu)])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'hello.<locals>.loop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         result \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mmap(loop, [_ \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_cpu)])\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mhello\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mhello\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     def loop(_):\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#         print(temp)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(n_cpu) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m----> 9\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_cpu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/sadow_lts/personal/yusukemh/Anaconda3/envs/tfp/lib/python3.10/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sadow_lts/personal/yusukemh/Anaconda3/envs/tfp/lib/python3.10/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/sadow_lts/personal/yusukemh/Anaconda3/envs/tfp/lib/python3.10/multiprocessing/pool.py:537\u001b[0m, in \u001b[0;36mPool._handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     \u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     job, idx \u001b[38;5;241m=\u001b[39m task[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/sadow_lts/personal/yusukemh/Anaconda3/envs/tfp/lib/python3.10/multiprocessing/connection.py:211\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_writable()\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_bytes(\u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/sadow_lts/personal/yusukemh/Anaconda3/envs/tfp/lib/python3.10/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'hello.<locals>.loop'"
     ]
    }
   ],
   "source": [
    "def hello():\n",
    "    temp = 19\n",
    "    n_cpu = cpu_count()\n",
    "    def loop(_):\n",
    "        return 19\n",
    "#     def loop(_):\n",
    "#         print(temp)\n",
    "    with Pool(n_cpu) as p:\n",
    "        result = p.map(loop, [_ for _ in range(n_cpu)])\n",
    "        print(result)\n",
    "hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1,2,3] for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def sqrt_func(i, j):\n",
    "    return i + j\n",
    "result = Parallel(n_jobs=-1)(delayed(sqrt_func)(i, j) for i in range(5) for j in range(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 2, 2, 3, 3, 4, 4, 5]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def func(X, Y):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    Y = scaler.transform(Y)\n",
    "    return X, Y\n",
    "    \n",
    "X = np.random.random((10,10))\n",
    "Y = np.random.random((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77278497, 0.3523481 , 0.44008981, 0.44132626, 0.74630071,\n",
       "        0.26041846, 0.6445427 , 0.37371003, 0.60245987, 0.76818882],\n",
       "       [0.22351023, 0.56613931, 0.97605876, 0.41191462, 0.60281716,\n",
       "        0.46592501, 0.80463901, 0.20344072, 0.43559862, 0.24372955],\n",
       "       [0.8808992 , 0.2514928 , 0.27569716, 0.2712373 , 0.77735979,\n",
       "        0.8186965 , 0.59878394, 0.9547254 , 0.93762773, 0.76537389],\n",
       "       [0.905788  , 0.72661338, 0.94508593, 0.79022218, 0.58737696,\n",
       "        0.35757129, 0.7151338 , 0.2031919 , 0.18484327, 0.54981129],\n",
       "       [0.28793288, 0.03955429, 0.77359109, 0.03490754, 0.6811471 ,\n",
       "        0.06922893, 0.6925942 , 0.05142748, 0.25145844, 0.85500327],\n",
       "       [0.60790958, 0.35081524, 0.22201916, 0.32241246, 0.82647519,\n",
       "        0.39572965, 0.42907647, 0.16655156, 0.33024554, 0.36269539],\n",
       "       [0.53498888, 0.86188524, 0.46927766, 0.4162485 , 0.32442874,\n",
       "        0.68898393, 0.58763007, 0.30337506, 0.65304007, 0.04284047],\n",
       "       [0.03659361, 0.33176209, 0.6835159 , 0.24873069, 0.37888982,\n",
       "        0.36935902, 0.78651116, 0.39081234, 0.80173842, 0.61950685],\n",
       "       [0.86996169, 0.53555408, 0.6291334 , 0.67321849, 0.29252803,\n",
       "        0.48099147, 0.68793495, 0.25598557, 0.27663934, 0.92111367],\n",
       "       [0.40232538, 0.97131511, 0.79607436, 0.72977227, 0.87078774,\n",
       "        0.15326682, 0.61031304, 0.83302589, 0.09549151, 0.67490252]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = func(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77278497, 0.3523481 , 0.44008981, 0.44132626, 0.74630071,\n",
       "        0.26041846, 0.6445427 , 0.37371003, 0.60245987, 0.76818882],\n",
       "       [0.22351023, 0.56613931, 0.97605876, 0.41191462, 0.60281716,\n",
       "        0.46592501, 0.80463901, 0.20344072, 0.43559862, 0.24372955],\n",
       "       [0.8808992 , 0.2514928 , 0.27569716, 0.2712373 , 0.77735979,\n",
       "        0.8186965 , 0.59878394, 0.9547254 , 0.93762773, 0.76537389],\n",
       "       [0.905788  , 0.72661338, 0.94508593, 0.79022218, 0.58737696,\n",
       "        0.35757129, 0.7151338 , 0.2031919 , 0.18484327, 0.54981129],\n",
       "       [0.28793288, 0.03955429, 0.77359109, 0.03490754, 0.6811471 ,\n",
       "        0.06922893, 0.6925942 , 0.05142748, 0.25145844, 0.85500327],\n",
       "       [0.60790958, 0.35081524, 0.22201916, 0.32241246, 0.82647519,\n",
       "        0.39572965, 0.42907647, 0.16655156, 0.33024554, 0.36269539],\n",
       "       [0.53498888, 0.86188524, 0.46927766, 0.4162485 , 0.32442874,\n",
       "        0.68898393, 0.58763007, 0.30337506, 0.65304007, 0.04284047],\n",
       "       [0.03659361, 0.33176209, 0.6835159 , 0.24873069, 0.37888982,\n",
       "        0.36935902, 0.78651116, 0.39081234, 0.80173842, 0.61950685],\n",
       "       [0.86996169, 0.53555408, 0.6291334 , 0.67321849, 0.29252803,\n",
       "        0.48099147, 0.68793495, 0.25598557, 0.27663934, 0.92111367],\n",
       "       [0.40232538, 0.97131511, 0.79607436, 0.72977227, 0.87078774,\n",
       "        0.15326682, 0.61031304, 0.83302589, 0.09549151, 0.67490252]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "\thel;\n"
     ]
    }
   ],
   "source": [
    "print('s')\n",
    "print('\\thel;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# others\n",
    "from copy import deepcopy\n",
    "from xgboost import XGBRegressor\n",
    "import sherpa\n",
    "import sys\n",
    "\n",
    "# Variables from config file\n",
    "sys.path.append('/home/yusukemh/github/yusukemh/StatisticalDownscaling/codes/')\n",
    "from config import BASE_DIR, FILE_NAMES, LABELS, ATTRIBUTES, BEST_MODEL_COLUMNS, ISLAND_RANGES, C_SINGLE, C_INT50, C_INT100, C_GRID, C_COMMON\n",
    "\n",
    "# util\n",
    "from util import cross_val_predict_for_nn, estimate_epochs\n",
    "\n",
    "# define models\n",
    "def define_model(input_dim=20, lr=0.005):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=256, activation='elu')(inputs)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    outputs = Dense(units=1, kernel_initializer='normal', activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss='mse',\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def define_hetero_model_normal(input_dim=20, lr=0.0065):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=512, activation='selu', kernel_initializer='normal')(inputs)\n",
    "    x = Dense(units=512, activation='selu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=512, activation='selu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    m = Dense(units=256, activation='selu', kernel_initializer='normal')(x)\n",
    "    m = Dense(units=10, activation='selu', kernel_initializer='normal')(m)\n",
    "    m = Dense(units=1, activation='linear', kernel_initializer='normal')(m)\n",
    "    \n",
    "    s = Dense(units=256, activation='selu', kernel_initializer='normal')(x)\n",
    "    s = Dense(units=10, activation='selu', kernel_initializer='normal')(s)\n",
    "    s = Dense(units=1, activation='linear', kernel_initializer='normal', kernel_regularizer=tf.keras.regularizers.L2(l2=100))(s)\n",
    "    \n",
    "    ms = Concatenate(axis=-1)([m, s])\n",
    "    outputs = tfp.layers.DistributionLambda(\n",
    "        make_distribution_fn=lambda t: tfd.Normal(\n",
    "            loc=2.5 * t[...,0] + 0.01, scale=tf.math.softplus(0.001*t[...,1]+0.03)#this part is important\n",
    "        ),\n",
    "        convert_to_tensor_fn=lambda s: s.mean()\n",
    "    )(ms)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss=lambda y, p_y: -p_y.log_prob(y),\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def safe_nll(y, p_y):\n",
    "    epsilon=1e-5\n",
    "    return -p_y.log_prob(y + epsilon) # y = 0 yields nan\n",
    "\n",
    "def define_hetero_model_gamma(input_dim=20, lr=0.0065):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(inputs)\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    m = Dense(units=256, activation='elu', kernel_initializer='normal')(x)\n",
    "    m = Dense(units=10, activation='elu', kernel_initializer='normal')(m)\n",
    "    m = Dense(units=1, activation='linear', kernel_initializer='normal')(m)\n",
    "    \n",
    "    s = Dense(units=256, activation='elu', kernel_initializer='normal')(x)\n",
    "    s = Dense(units=10, activation='elu', kernel_initializer='normal')(s)\n",
    "    s = Dense(units=1, activation='linear', kernel_initializer='normal')(s)\n",
    "    \n",
    "    ms = Concatenate(axis=-1)([m, s])\n",
    "    outputs = tfp.layers.DistributionLambda(\n",
    "        make_distribution_fn=lambda t: tfd.Gamma(\n",
    "            concentration=tf.math.softplus(t[...,0]), rate=tf.math.softplus(t[...,1])\n",
    "        ),\n",
    "        convert_to_tensor_fn=lambda d: d.mean()\n",
    "    )(ms)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        #loss=lambda y, p_y: -p_y.log_prob(y),\n",
    "        loss=safe_nll,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def run_single_experiment(\n",
    "    X, Y,\n",
    "    model_func, model_params,\n",
    "    n_trial, skn\n",
    "):\n",
    "    # first, run linear regression\n",
    "    linear_regression = LinearRegression()\n",
    "    y_pred = cross_val_predict(linear_regression, X, Y, n_jobs=-1)\n",
    "    rmse_lr = mean_squared_error(Y, y_pred, squared=False)\n",
    "    # estimate the # epochs\n",
    "    estimated_epochs = estimate_epochs(\n",
    "        X=X, Y=Y, model_func=model_func, model_params=model_params, n_iter=30\n",
    "    )\n",
    "    \n",
    "    rmses = []\n",
    "    for trial in range(n_trial):\n",
    "        y_pred = cross_val_predict_for_nn(\n",
    "            X=X, Y=Y, model_func=model_func, model_params=model_params, callback=None, batch_size=64,\n",
    "            epochs=int(estimated_epochs), early_stopping=False, verbose=False\n",
    "        )\n",
    "        rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "        rmses.append(rmse)\n",
    "    rmses = np.array(rmses)\n",
    "    m, s = np.mean(rmses), np.std(rmses)\n",
    "    return pd.DataFrame(\n",
    "        dict(\n",
    "            n_samples=X.shape[0],\n",
    "            estimated_epochs=estimated_epochs,\n",
    "            rmse_LR=rmse_lr,\n",
    "            rmse_NN_mean=m,\n",
    "            rmse_NN_std=s,\n",
    "            rel_imp=(rmse_lr - m)/rmse_lr\n",
    "        ),\n",
    "        index=[skn]\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    file_name = './progress.txt'\n",
    "\n",
    "    columns = C_SINGLE\n",
    "    # load nonfilled dataset\n",
    "    df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "    # sample a station: returned object is sorted.\n",
    "\n",
    "    df_n_data = df_nonfilled.groupby('skn').size().reset_index().rename(columns={0:\"n_data\"})\n",
    "    valid_skn = df_n_data[df_n_data['n_data'] > 750]['skn']\n",
    "\n",
    "    stats_regular = []\n",
    "    stats_normal = []\n",
    "    stats_gamma = []\n",
    "\n",
    "    for i, skn in enumerate(valid_skn):\n",
    "        with open(file_name, 'a') as f:\n",
    "            f.write(f'Running experiment on skn {skn}\\n')\n",
    "            f.write(f'{i}/{valid_skn.shape[0]}\\n')\n",
    "\n",
    "        df_station = df_nonfilled[df_nonfilled['skn'] == skn].sort_values(['year', 'month'])\n",
    "\n",
    "        X = np.array(df_station[columns])\n",
    "        Y = np.array(df_station['data_in'])\n",
    "\n",
    "        with open(file_name, 'a') as f:\n",
    "            f.write(f'\\tRunning regular NN\\n')\n",
    "\n",
    "        # regular NN\n",
    "        stats_regular.append(\n",
    "            run_single_experiment(\n",
    "                X, Y, model_func=define_model, model_params=dict(input_dim=len(columns), lr=0.0005),\n",
    "                n_trial=20, skn=skn\n",
    "            )\n",
    "        )\n",
    "\n",
    "        with open(file_name, 'a') as f:\n",
    "            f.write(f'\\tRunning normal NN\\n')\n",
    "\n",
    "        stats_normal.append(\n",
    "            run_single_experiment(\n",
    "                X, Y, model_func=define_hetero_model_normal, model_params=dict(input_dim=len(columns), lr=0.0005),\n",
    "                n_trial=20, skn=skn\n",
    "            )\n",
    "        )\n",
    "\n",
    "        with open(file_name, 'a') as f:\n",
    "            f.write(f'\\tRunning gamma NN\\n')\n",
    "\n",
    "        stats_gamma.append(\n",
    "            run_single_experiment(\n",
    "                X, Y, model_func=define_hetero_model_gamma, model_params=dict(input_dim=len(columns), lr=0.001),\n",
    "                n_trial=20, skn=skn\n",
    "            )\n",
    "        )\n",
    "\n",
    "    pd.concat(stats_regular).to_csv(f\"./stats_regular.csv\", index=False)\n",
    "    pd.concat(stats_normal).to_csv(f\"./stats_normal.csv\", index=False)\n",
    "    pd.concat(stats_gamma).to_csv(f\"./stats_gamma.csv\", index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 20:20:10.892195: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/tools/nmap/7.80/lib\n"
     ]
    }
   ],
   "source": [
    "# set the environment variable for warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# others\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "from copy import deepcopy\n",
    "import sherpa\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "import time\n",
    "from scipy.stats import gamma, norm, beta\n",
    "\n",
    "# Variables from config file\n",
    "sys.path.append('/home/yusukemh/github/yusukemh/StatisticalDownscaling/codes/')\n",
    "from config import BASE_DIR, FILE_NAMES, LABELS, ATTRIBUTES, BEST_MODEL_COLUMNS, ISLAND_RANGES, C_SINGLE, C_INT50, C_INT100, C_GRID, C_COMMON\n",
    "\n",
    "# util\n",
    "from util import cross_val_predict_for_nn, sample_station, estimate_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station with skn: 396.0 was chosen out of all stations with more than 750 historical (non-filled) rainfall observations.\n",
      "There are 778 rainfall observations from this station.\n"
     ]
    }
   ],
   "source": [
    "columns = C_SINGLE\n",
    "# load nonfilled dataset\n",
    "df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "# sample a station: returned object is sorted.\n",
    "df_station = sample_station(df=df_nonfilled, threshold=750, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a NN model\n",
    "def define_model(input_dim=20, lr=0.005):\n",
    "    \n",
    "    inputs = Input(shape=(input_dim,))\n",
    "        \n",
    "#     inputs_1 = tf.keras.layers.GaussianNoise(stddev=1)(inputs)\n",
    "#     inputs_2 = tf.keras.layers.GaussianNoise(stddev=0.5)(inputs)\n",
    "#     inputs_3 = tf.keras.layers.GaussianNoise(stddev=0.2)(inputs)\n",
    "    \n",
    "    x = Dense(units=256, activation='elu')(inputs)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    \n",
    "    outputs_1 = Dense(units=1, activation='linear')(x)\n",
    "    \n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    \n",
    "    outputs_2 = Dense(units=1, activation='linear')(x)\n",
    "    \n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    \n",
    "    outputs_3 = Dense(units=1, activation='linear')(x)\n",
    "\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    \n",
    "    outputs = Dense(units=1, kernel_initializer='normal', activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    rates = tf.constant([1.4, 0.9, 0.3, 0.1])\n",
    "    #rates = tf.constant([1.,1.,1.,1.])\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        \n",
    "        loss_1 = mse(\n",
    "            tf.keras.layers.GaussianNoise(stddev=3)(y_true),\n",
    "            outputs_1\n",
    "        )\n",
    "        \n",
    "        loss_2 = mse(\n",
    "            tf.keras.layers.GaussianNoise(stddev=1)(y_true),\n",
    "            outputs_2\n",
    "        )\n",
    "        \n",
    "        loss_3 = mse(\n",
    "            tf.keras.layers.GaussianNoise(stddev=0.2)(y_true),\n",
    "            outputs_3\n",
    "        )\n",
    "        \n",
    "        loss = mse(y_true, y_pred)\n",
    "        # return rates[0] * loss_1 + rates[1] * loss_2 + rates[2] * loss_3 + rates[3] * loss\n",
    "\n",
    "        losses = tf.stack([loss_1, loss_2, loss_3, loss], axis=0)\n",
    "        # final_loss = tf.math.multiply(rates, [loss_1, loss_2, loss_3, loss])\n",
    "        final_loss = tf.math.multiply(rates, losses)\n",
    "        return tf.reduce_sum(final_loss, axis=-1)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss=custom_loss,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_52:0' shape=(4,) dtype=float32>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(np.arange(3 + 1, 0, -1).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a NN model\n",
    "def define_model(input_dim=20, lr=0.005, n_stacks=3):\n",
    "    \n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = tf.keras.layers.Lambda(lambda x: x)(inputs)\n",
    "     \n",
    "    intermediate_outputs = []\n",
    "    for stack in range(n_stacks):\n",
    "        x = Dense(units=256, activation='elu')(x)\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "        x = Dense(units=256, activation='elu')(x)\n",
    "        _outputs = Dense(units=1, activation='linear')(x)\n",
    "        intermediate_outputs.append(_outputs)\n",
    "\n",
    "    # outputs = tf.keras.layers.Lambda(lambda x: x)(x)\n",
    "    outputs = Dense(units=1, kernel_initializer='normal', activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    rates = tf.constant(np.arange(n_stacks + 1).astype('float32'))\n",
    "    std = tf.constant(np.log(np.arange(n_stacks + 1, 0, -1).astype('float32')))\n",
    "    \n",
    "    def custom_loss(y_true, y_pred):\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        \n",
    "        mses = []\n",
    "        for i in range(n_stacks):\n",
    "            mses.append(mse(\n",
    "                tf.keras.layers.GaussianNoise(stddev=std[i])(y_true),\n",
    "                intermediate_outputs[i]\n",
    "            ))\n",
    "        mses.append(mse(y_true, y_pred))\n",
    "\n",
    "        losses = tf.stack(mses, axis=0)\n",
    "        final_loss = tf.math.multiply(rates, mses)\n",
    "        return tf.reduce_sum(final_loss, axis=-1)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss=custom_loss,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean number of epochs: 14.0\n",
      "Std: 0.000\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_station[columns])\n",
    "Y = np.array(df_station['data_in'])\n",
    "# model = define_model(input_dim=len(columns), lr=0.005)\n",
    "model_params={\"input_dim\": len(columns), \"lr\": 0.005, \"n_stacks\": 10}\n",
    "estimated_epochs = estimate_epochs(\n",
    "    X=X, Y=Y,\n",
    "    model_func=define_model,\n",
    "    model_params=model_params,\n",
    "    n_iter=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: single observation, normal NN\n",
      "RMSE with NN: 1.885\n",
      "RMSE with LR: 1.535\n"
     ]
    }
   ],
   "source": [
    "# now fix the epoch, remove early stopping, and run cross_val_predict\n",
    "yhat_nn = cross_val_predict_for_nn(# implemented in util.py\n",
    "    model_func=define_model,\n",
    "    model_params=model_params,\n",
    "    X=X, Y=Y,\n",
    "    callback=None,\n",
    "    batch_size=64,\n",
    "    epochs=int(estimated_epochs),\n",
    "    early_stopping=False,\n",
    "    verbose=False\n",
    ")\n",
    "rmse_nn = mean_squared_error(Y, yhat_nn, squared=False)\n",
    "linear_regression = LinearRegression()\n",
    "yhat_lr = cross_val_predict(linear_regression, X, Y, n_jobs=-1)\n",
    "rmse_lr = mean_squared_error(Y, yhat_lr, squared=False)\n",
    "\n",
    "print(\"Result: single observation, normal NN\")\n",
    "print(\"RMSE with NN: {:.3f}\".format(rmse_nn))\n",
    "print(\"RMSE with LR: {:.3f}\".format(rmse_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station with skn: 396.0 was chosen out of all stations with more than 750 historical (non-filled) rainfall observations.\n",
      "There are 778 rainfall observations from this station.\n"
     ]
    }
   ],
   "source": [
    "columns = C_SINGLE\n",
    "# load nonfilled dataset\n",
    "df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "# sample a station: returned object is sorted.\n",
    "df_station = sample_station(df=df_nonfilled, threshold=750, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hetero_model_gamma(input_dim=20, lr=0.0065):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(inputs)\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    m = Dense(units=256, activation='elu', kernel_initializer='normal')(x)\n",
    "    m = Dense(units=10, activation='elu', kernel_initializer='normal')(m)\n",
    "    m = Dense(units=1, activation='linear', kernel_initializer='normal')(m)\n",
    "    \n",
    "    s = Dense(units=256, activation='elu', kernel_initializer='normal')(x)\n",
    "    s = Dense(units=10, activation='elu', kernel_initializer='normal')(s)\n",
    "    s = Dense(units=1, activation='linear', kernel_initializer='normal')(s)\n",
    "    \n",
    "    ms = Concatenate(axis=-1)([m, s])\n",
    "    outputs = tfp.layers.DistributionLambda(\n",
    "        make_distribution_fn=lambda t: tfd.Gamma(\n",
    "            concentration=tf.math.softplus(t[...,0]), rate=tf.math.softplus(t[...,1])\n",
    "        ),\n",
    "        convert_to_tensor_fn=lambda d: d.mean()\n",
    "    )(ms)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    epsilon=1e-5 # for loss function\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss=lambda y, p_y: -p_y.log_prob(y + epsilon),\n",
    "        # loss=safe_nll,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean number of epochs: 13.2\n",
      "Std: 3.400\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_station[columns])\n",
    "Y = np.array(df_station['data_in'])\n",
    "# Y = np.clip(Y, a_min=1e-10, a_max=None)\n",
    "\n",
    "\n",
    "model_params = dict(\n",
    "    input_dim=len(columns),\n",
    "    lr=0.001\n",
    ")\n",
    "batch_size = 64\n",
    "\n",
    "estimated_epochs = estimate_epochs(\n",
    "    X=X, Y=Y,\n",
    "    model_func=define_hetero_model_gamma,\n",
    "    model_params=model_params,\n",
    "    n_iter=10,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with NN: 1.456\n"
     ]
    }
   ],
   "source": [
    "# now fix the epoch, remove early stopping, and run cross_val_predict\n",
    "epochs = int(estimated_epochs)\n",
    "n_ensamble = 10\n",
    "y_preds = []\n",
    "for _ in range(n_ensamble):\n",
    "    yhat_nn = cross_val_predict_for_nn(# implemented in util.py\n",
    "        model_func=define_hetero_model_gamma,\n",
    "        model_params=model_params,\n",
    "        X=X, Y=Y,\n",
    "        callback=None,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        early_stopping=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    y_preds.append(yhat_nn)\n",
    "    print(f\"{_+1}/{n_ensamble}\", end='\\r')\n",
    "mean_pred = np.mean(y_preds, axis=0)\n",
    "rmse_nn = mean_squared_error(Y, mean_pred, squared=False)\n",
    "print(\"RMSE with NN: {:.3f}\".format(rmse_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean number of epochs: 33.7\n",
      "Std: 11.411\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_station[columns])\n",
    "Y = np.array(df_station['data_in'])\n",
    "# Y = np.clip(Y, a_min=1e-10, a_max=None)\n",
    "\n",
    "\n",
    "model_params = dict(\n",
    "    input_dim=len(columns),\n",
    "    lr=0.001\n",
    ")\n",
    "batch_size = 64\n",
    "\n",
    "estimated_epochs = estimate_epochs(\n",
    "    X=X, Y=Y,\n",
    "    model_func=define_hetero_model_normal_rev,\n",
    "    model_params=model_params,\n",
    "    n_iter=10,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with NN: 1.474\n"
     ]
    }
   ],
   "source": [
    "# now fix the epoch, remove early stopping, and run cross_val_predict\n",
    "epochs = int(estimated_epochs)\n",
    "n_ensamble = 10\n",
    "y_preds = []\n",
    "for _ in range(n_ensamble):\n",
    "    yhat_nn = cross_val_predict_for_nn(# implemented in util.py\n",
    "        model_func=define_hetero_model_normal_rev,\n",
    "        model_params=model_params,\n",
    "        X=X, Y=Y,\n",
    "        callback=None,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        early_stopping=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    y_preds.append(yhat_nn)\n",
    "    print(f\"{_+1}/{n_ensamble}\", end='\\r')\n",
    "mean_pred = np.mean(y_preds, axis=0)\n",
    "rmse_nn = mean_squared_error(Y, mean_pred, squared=False)\n",
    "print(\"RMSE with NN: {:.3f}\".format(rmse_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model__(\n",
    "    input_dim=20, \n",
    "    lr=0.005, \n",
    "    activation='relu',\n",
    "    n_units=256,\n",
    "    n_layers=4,\n",
    "    dropout=0.5\n",
    "):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=n_units, activation=activation)(inputs)\n",
    "    \n",
    "    for i in range(n_layers - 1):\n",
    "        if dropout:\n",
    "            x = Dropout(rate=dropout)(x)\n",
    "        x = Dense(units=n_units, activation=activation)(x)\n",
    "    outputs = Dense(units=1, kernel_initializer='normal', activation='relu')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss='mse',\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station with skn: 396.0 was chosen out of all stations with more than 750 historical (non-filled) rainfall observations.\n",
      "There are 778 rainfall observations from this station.\n"
     ]
    }
   ],
   "source": [
    "columns = C_SINGLE\n",
    "# load nonfilled dataset\n",
    "df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "# sample a station: returned object is sorted.\n",
    "df_station = sample_station(df=df_nonfilled, threshold=750, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean number of epochs: 12.5\n",
      "Std: 2.655\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "model_params = {\n",
    "    \"input_dim\"         : len(columns),\n",
    "    \"activation\"        : 'relu',\n",
    "    \"dropout\"           : 0.4578657205946084,\n",
    "    \"lr\"                : 0.0043961731420066,\n",
    "    \"n_layers\"          : 2,\n",
    "    \"n_units\"           : 905,\n",
    "}\n",
    "batch_size = 116\n",
    "#############################################\n",
    "\n",
    "X = np.array(df_station[columns])\n",
    "Y = np.array(df_station['data_in'])\n",
    "\n",
    "estimated_epochs = estimate_epochs(\n",
    "    X=X, Y=Y,\n",
    "    model_func=define_model,\n",
    "    model_params=model_params,\n",
    "    batch_size=batch_size,\n",
    "    n_iter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: single observation, normal NN\n",
      "RMSE with NN: 1.446\n",
      "RMSE with LR: 1.535\n"
     ]
    }
   ],
   "source": [
    "# now fix the epoch, remove early stopping, and run cross_val_predict\n",
    "yhat_nn = cross_val_predict_for_nn(# implemented in util.py\n",
    "    model_func=define_model,\n",
    "    model_params=model_params,\n",
    "    X=X, Y=Y,\n",
    "    callback=None,\n",
    "    batch_size=batch_size,\n",
    "    epochs=int(estimated_epochs),\n",
    "    early_stopping=False,\n",
    "    verbose=False\n",
    ")\n",
    "rmse_nn = mean_squared_error(Y, yhat_nn, squared=False)\n",
    "linear_regression = LinearRegression()\n",
    "yhat_lr = cross_val_predict(linear_regression, X, Y, n_jobs=-1)\n",
    "rmse_lr = mean_squared_error(Y, yhat_lr, squared=False)\n",
    "\n",
    "print(\"Result: single observation, normal NN\")\n",
    "print(\"RMSE with NN: {:.3f}\".format(rmse_nn))\n",
    "print(\"RMSE with LR: {:.3f}\".format(rmse_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_(\n",
    "    input_dim=20, \n",
    "    lr=0.005, \n",
    "    activation='relu',\n",
    "    n_units=256,\n",
    "    n_layers=4,\n",
    "    dropout=0.5\n",
    "):\n",
    "#     inputs = Input(shape=(input_dim,))\n",
    "#     x = Dense(units=n_units, activation=activation)(inputs)\n",
    "    \n",
    "#     for i in range(n_layers - 1):\n",
    "#         if dropout:\n",
    "#             x = Dropout(rate=dropout)(x)\n",
    "#         x = Dense(units=n_units, activation=activation)(x)\n",
    "#     outputs = Dense(units=1, kernel_initializer=tf.keras.initializers.HeNormal, activation='linear')(x)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "#     model.compile(\n",
    "#         optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "#         loss='mse',\n",
    "#         metrics=[RootMeanSquaredError()]\n",
    "#     )\n",
    "\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=512, activation='relu')(inputs)\n",
    "    x = Dense(units=512, activation='relu')(x)\n",
    "#    x = Dense(units=512, activation='selu')(x)\n",
    "    \n",
    "    outputs = Dense(units=1, activation='softplus')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=0.006),\n",
    "        loss='mse',\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station with skn: 396.0 was chosen out of all stations with more than 750 historical (non-filled) rainfall observations.\n",
      "There are 778 rainfall observations from this station.\n"
     ]
    }
   ],
   "source": [
    "columns = C_SINGLE\n",
    "columns.append('month')\n",
    "# load nonfilled dataset\n",
    "df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "# sample a station: returned object is sorted.\n",
    "df_station = sample_station(df=df_nonfilled, threshold=750, seed=42)\n",
    "\n",
    "model = define_model_(input_dim = len(columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean number of epochs: 10.6\n",
      "Std: 2.375\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_station[columns])\n",
    "Y = np.array(df_station['data_in'])\n",
    "\n",
    "# define hyperparameters\n",
    "############################\n",
    "model_params = dict(\n",
    "    input_dim=len(columns),\n",
    "    lr=0.0005,\n",
    "    activation='elu',\n",
    "    n_units=256,\n",
    "    n_layers=2,\n",
    "    dropout=0.5\n",
    ")\n",
    "batch_size = 64\n",
    "#############################\n",
    "\n",
    "estimated_epochs = estimate_epochs(\n",
    "    X=X, Y=Y,\n",
    "    model_func=define_model_,\n",
    "    model_params=model_params,\n",
    "    batch_size=batch_size,\n",
    "    n_iter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: single observation, normal NN\n",
      "RMSE with NN: 1.547\n",
      "RMSE with LR: 1.539\n"
     ]
    }
   ],
   "source": [
    "# now fix the epoch, remove early stopping, and run cross_val_predict\n",
    "yhat_nn = cross_val_predict_for_nn(# implemented in util.py\n",
    "    model_func=define_model_,\n",
    "    model_params=model_params,\n",
    "    X=X, Y=Y,\n",
    "    callback=None,\n",
    "    batch_size=batch_size,\n",
    "    epochs=int(estimated_epochs),\n",
    "    early_stopping=False,\n",
    "    verbose=False\n",
    ")\n",
    "rmse_nn = mean_squared_error(Y, yhat_nn, squared=False)\n",
    "linear_regression = LinearRegression()\n",
    "yhat_lr = cross_val_predict(linear_regression, X, Y, n_jobs=-1)\n",
    "rmse_lr = mean_squared_error(Y, yhat_lr, squared=False)\n",
    "\n",
    "print(\"Result: single observation, normal NN\")\n",
    "print(\"RMSE with NN: {:.3f}\".format(rmse_nn))\n",
    "print(\"RMSE with LR: {:.3f}\".format(rmse_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2abf3f644ee0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAi9ElEQVR4nO3dfZBU9Z3v8feXYUYYUGBgROXBgYHFTFJKdJIYNBoC3qtZC/ePxU3qJpd9uIXZ2jUkN3s38W4qdbcqd5OqXc2S7K01VDYJucl6r7i5G8uKuyohRCRiBoNGQWTGGeQpOMwAygwwD/zuH/1gT8/pp9Onu885/XlVUTPT09Pn20339/zO93x/v2POOUREJHqm1DoAERHxRwlcRCSilMBFRCJKCVxEJKKUwEVEImpqNTc2b94819bWVs1NiohE3t69e08551qzb69qAm9ra6Orq6uamxQRiTwzO+x1u0ooIiIRpQQuIhJRSuAiIhGlBC4iElFK4CIiEaUELiISUUrgIiIRpQQuIhKQwaERvr2zh8GhkapsTwlcRCQg27qO8LUnX2Nb15GqbK+qMzFFROJsfeeiCV8rTQlcRCQgLTOauO/29qptTyUUEZGIUgIXEYkoJXARkYhSAhcRiaiCCdzMvmtmb5nZKxm3tZjZ02Z2KPl1TmXDFBGRbMWMwL8P3Jl125eA7c655cD25M8iIlJFBRO4c+4XwGDWzfcAW5PfbwV+L9iwRESkEL818PnOuRMAya9X5rqjmW00sy4z6+rv7/e5ORERyVbxk5jOuS3OuU7nXGdr66RrcoqIiE9+E/hJM7saIPn1reBCEhGRYvhN4I8DG5LfbwB+Ekw4IiJSrGLaCB8BfgmsMLOjZvYnwNeBO8zsEHBH8mcREamigotZOec+meNXawKORURESqCZmCIiEaUELiISUUrgIiIRpQQuIhJRSuAiIhGlBC4iElFK4CIhNTg0wrd39jA4NFLrUCSklMBFQmpb1xG+9uRrbOs6UutQJKR0VXqRkFrfuWjCV5FsSuAiIdUyo4n7bm+vdRgSYiqhiIhElBK4iEhEKYGLiESUErhIlagtUIKmBC5VVc9JTG2BEjR1oUhVpZIYUHcdFmoLlKApgUtV1XMSU1ugBE0JXKpKSUwkOKqBi4hElBK4iEhEKYGLiESUEriISEQpgYuIRJQSuKSFbZJN2OIRCRslcEkL20zBsMUjEjbqA5e0sE2yCVs8ImFjzrmqbayzs9N1dXVVbXsiInFgZnudc53Zt6uEIiISUWUlcDP7vJm9amavmNkjZjYtqMBERCQ/3wnczBYAnwU6nXPvAxqATwQVmIiI5FduCWUqMN3MpgLNwPHyQxIRkWL4TuDOuWPA3wFvAieAs865p7LvZ2YbzazLzLr6+/v9RyoiIhOUU0KZA9wDLAGuAWaY2aey7+ec2+Kc63TOdba2tvqPVEREJiinhLIW6HXO9TvnRoEfA6uCCUuiTrMoRSqvnAT+JnCzmTWbmQFrgAPBhCVRp1mUIpXneyamc26PmT0GvAiMAb8GtgQVmESbZlGKVJ5mYoqIhJxmYoqIxIwSuIhIRCmBS2yo80XqjRK4xIY6X6TeaD1wARKj121dR1jfuYiWGU21DscXdb5IvdEIXIB4jF5bZjRx3+3tkd0BiZRKI3ABNHqtZ3E4+qpXGoELUB+jV53k9BaHo696pRG41I1UogK47/b2QB4zDqNXHX1FlxK4xCIJFaMSiaoSO4VqSx19SfQogUtoklCldySVSFQavUotKYFLaJJQWHYkpdDoVWpJCVxCk4TCsiMRiQp1oURI3Lso6qETRiRISuARonYvEcmkEkqEqMQgIpk0Ao+QqJcY4l4CEqk2JfA6EJbEmVkCCktMIlGmEkodCEt7XmYJKCwxiUSZEngdCEvtPLNdMSwxiUSZSih1IIy180rGpPKM1AslcPElzEmyku2WYX7eUn9UQhFfwlzDrmR5JszPW+qPErj4EuYadiWXBgjz85b6oxKK+JKrhh33EkMYzydI/VICl0Bpur9I9aiEIoFSiaF09XJBDQmeRuASKJUYSqejFvFLI3CRGtNRi/hV1gjczGab2WNm9pqZHTCzDwcVmIRH3E9M1pqOWsSvcksom4F/c85dB9wAHCg/JAkbHeJHj3a69cF3CcXMrgBuA/4QwDk3AujdEkM6xI8eTTiqD+XUwJcC/cD3zOwGYC+wyTk3lHknM9sIbARYvHhxGZuTIPjpeAjLNTOleNrp1odySihTgRuBf3TOvR8YAr6UfSfn3BbnXKdzrrO1tbWMzUkQVA6pD6qr14dyRuBHgaPOuT3Jnx/DI4FLuGhkJhIfvkfgzrnfAkfMbEXypjXA/kCikorRyKy2dHJRglRuF8r9wI/M7GVgJfA3ZUckEmNeJSwldfGrrIk8zrl9QGcwoUilaKp2eHiVsMLQMaL3SDRpJmYdCEOC8CtuicWroycM5yWi/B6pZ0rgdSAMCcKvekgsYWjTjPJ7pJ4pgdeBMCQIv5RYqiPK75F6pgQuoabEIpKblpONMa/uBnU8iMSHEniMebWsaSamSHyohBJjXvVj1ZRF4kMj8CqpRenCa9alZmJKJpXUok0JvEpUuoimuCc4vS+jTSWUKlHporqCmgAU9z50vS+jTQm8StQOV11BJd64Jzi9L6NNCVxqqlJT5YNKvEEluLgtCSDhoBp4jcW9xlpIpWqwYTtZq1qzVIJG4DUW9xprIXEvUaRE7XnqiCEalMBrLGof7KDVSw02as+z3gcWUaEEXmNR+2BLfaj3gUVUKIGLyCQaWESDTmKKiESUEriISEQpgYuIRJQSeMSErW88bPHkE6VYRYqhBB4xYZsQErZ48olSrCLFiEUXShgmHVQrhrC1d4UtnnyiFKtIMWIxAg9yZOX3MLtQDEEdvodtinjY4sknSrGKFCMWI/AgR1Z+Z6AViiEOM9vCcKRTSBRijBq9puEViwQe5KQDvzuDQjHE4fC92jshP4kjDjvKsNFrGl6xSOBBqtQMtDjMbKv2TshP4qhGjPU2Io3D4COu6j6Bx+3DWMnnU+2dkJ/EUY0Y621EGofBR1zF4iRmOSrZWpY6cdnTf65q/cdxapUr9aRjtfq813cu4oG7rtOINADqzS9P2SNwM2sAuoBjzrm7yw+psrJHqJU8PEwl0+ffGGDHwX6gvBFbMaPrzOcTt6OLQqo1MtaINDj1djQTtCBKKJuAA8AVATxWxWW/YSr5YUwl07Ud87l56cmydxLFvNkzn8+3d/bU1YejFrXaettJBk319fKUlcDNbCHwu8D/BP5rIBEFIN+HqppvmMxk2n77zLIfr9TY6+3DUYuRsUaQ5dHRTHnKHYH/PfCXwOW57mBmG4GNAIsXLy5zc8XJ96GK8hum1NjD9FzjOlKtt52khIvvk5hmdjfwlnNub777Oee2OOc6nXOdra2tfjdXklJPMtX6REqtt18NcTq5mkmzO6WWyhmB3wKsM7OPA9OAK8zsh865TwUTmn+ljjyDOgz2O8qsh8NwjVRFguc7gTvnHgAeADCzjwJ/EYbk7UdQyaVS0/DjoNBONa4lFpFKqvuJPBBcrbhS0/DrQT0cheSjHZj4EUgCd879HPh5EI8VZUrE/tXDUUg+9b4DE380Ao+IzBEaELvRWr3v/Op9Byb+KIFHxNbdfWzefojhkXGamxo0WouZet+BxV2lSmSRXAulHtruJnPpr7Vqk6zP112kfJVqo43kCDzIemHYTh7limfDqiU0N01N316LNsk412nD9j6QeKlUiSySCTwMV+ApVbEJIlc8mUm71GQT1OsV5jptuQk4zjsnqb1KlcgimcDDcAUeL/mSSLEJoph4Sk02Qb1eYa7TlpuAw7xzihIdyVRXJBN4kIJMSvmSSLEJoph4lGwmK/c1CfPOKUp0JFNd5pwrfK+AdHZ2uq6urqptrxx+RhJxH33E/flJ+fQeqQwz2+uc68y+PZJdKOXK1U2Rebufs8ZxX9ioEmfS1dkSL3H/DIRNXZZQch3mZd6+vnMRwyPjDI+MMTg0UtM3ZFhGNZUo3eiQW8S/2CXw7GQ3ODTC1t29gLFhVVvey6hl3t4yoyk9Yaa5aWpN2xUrkeT8xFOJOrHq+SL+xS6BZye7bV1H2Ly9G4Dmpoa8l1HLvj3I5LJ1dy+bt3czcO4ic2deVlLijNPIN3vHEZWTh2E5ChLJFLsEnp3sEqWQMc6PXiq5HFJKckl9wNd2zOeZ/Sc9PugGwP4T77CruxcoPnFWeuRbzeQU1ZJJVOOWeItdAs9Odi0zmvj8HSvSF/gtVA4p96IMua5Av2FVG81NDRMSfC3V6uLHUS2ZRDVuibfYJfBcih1xeo20iknqha5AH/QFjnPxswOq1YWeoySqcUu81U0bYWZ7U752OK+Fooppn0s9fnvrTM82qmq1y4Wt/bGYlk0R8aduRuApg0MjDI+Ms2nNMs8Rp9dIK4gRauok5vDIGJ+/Y4XvxykkbIf6xbRsamQr4k/dJfBEV8ohNq1ZXnSpwe/hc2Y54/zIJYD010oJ26F+MS2bIuJPrEooxRyWr+9cxKY1y+nqGyxYakg9Xk//uYKP67XtzHLG9KYGgPTXaqtVySJXeSaIso3KMFLvIjMCL+bkXDGH5akJOs/1DLB6RWtRq/7l6iwptO3sUWZzU4OvEWcQbX5xLFnE8Tnlo150yRaZBJ6ZTB+8d6XnG7jYw/LsGZeF7pers6TQtrPLGX6TTBCJKo4lizg+p3zqbYclhUVmNcKe/nNs/EEXPf1DPHDXdXX1Bg5q5FXO4xT6W40OK0+vcf2K/GqEj+87Tk//ELcum1c3I66UoNr8yllNMPtvs+vPlbrmXyniXhPXSn+SLTIllNRFfW+6dnbBN7DfkYrXQlhBjjoTC2v1AY4Nq5ZU/YNYTskh+2+zD+fDUM5QiUHqTWQSeOZFfQvx+0H2Wggr3+OUup1UCyMQyAqH+XjtXLJr8qXsgAot9BWG9sUw7EREqikyCTy1DGwq4QA5k4/fD7LXQlj5HqeUBaESE4jG2HjbUqY3Tik5tlJH+8XsXMoZsfpJ2JWu4YZhJyJSTZFJ4DAx4QA5k4/fD7LXQlj5HqeUBaFSy9r6PQFbbLLNXBURcu98Cs1IrYTsC2bohFzl6cRnvEUqgXuNiKuRfEpZzCr1Nftvyj28L/bvi030qXLOA3ddV7UPduZzUL26OvQ6x5xzztc/YBGwAzgAvApsKvQ3N910kwvCwLmL7uGfd7uBcxcDebxCHv55t7v2i0+4h3/eXdG/CULma5PvdQrqNfT7ONX+P6xXep3jAehyHjm1nDbCMeALzrn3ADcDf2ZmHWXuT4oSRMtaKS1nazvms3pFa7osUejxvMoT1WpxK3bVxaBa0rbu7uNrT76W7K7xF6dUjl7nePOdwJ1zJ5xzLya/f4fESHxBUIHl47Xka6agrzr/zP6T7DjYz1ef2J8zAaceb/3Du3l4Zw+btx+iuWlq+oNTqI+6Egq9TsFwWV9FpFoCqYGbWRvwfmCPx+82AhsBFi9eXNZ2MuvKheq7xVx1PvNrvu2t7ZifXg9lW9cRzws9rO9cxKNdR+jpH+KqK85OSpyF+qj9ylefr0ZXRqq9c23HfL69s0cny0SqqOwEbmYzgX8BPuecezv79865LcAWSEylL2dbxSa9YpYwLSa5ZW7vwXtXTmhhzP79+s5FrLluPlfPOstf3/M+2lsnXnWnmAsm++kYqPVJqtTzquZl2YKg7gyJg7ISuJk1kkjeP3LO/TiYkHIrthOjmKvOl9pZkv23W3f3cn70UrrOva3rCFuefYPVK1qZ01w4IXjFWEwyLqa7JaiZqKWI2iSaWu/4RILguwZuZgb8E3DAOfdQcCHllu+ETHZNuVCNuZTLpHldN3Pz9m62/OINwNKJ9Jb2uew42M/W3b2+nl8xNevsuL1i9HuSt5yTw1E7WVad8wMilVVOF8otwKeBj5nZvuS/jwcUV0G5FlP6wqP7PE9SZt8/+wNcyknFVLJOcOntvXfBrORtVlTM2YpJgsUkHr/JqdS/i/LiUVHb4Yh48uotrNS/oPrAnZvcZz1w7qL7w+/uSd+W3f9aqC+70O+zHy/z59TfPvTUa3l7sGvVG14p5T6fKPYoRzFmiT5y9IFHYiamV23WazElrxONKYXWLclVw03dd3hkjM3buwHSI7dcV95J3H88vXCV1/1qeRItqG0XW/fOtb0w1qELvTZhjFnqmFdWr9Q/vyPwoGdCvjtiPlhwNFXovrlG+pmj8WLiq+bIrtpHArm2F8bRbKlHYiLVQJRH4H46HFK9216zJ1OPMzwyVnA0ld2Jki3futjFXK4t6L7wYlS7YyTX9sK4emCh1yaMMUsd88rqlfoXZA280EjIaySVr45d6LGLuW8pj1fs89GIT0SowFooNZXZZeLVDeHVUVGoBS/1OFt3905qp8vV1QLv1sRzteGV27JY60uV5RLlLhSROIhECQXyT2DJLj/kOhFV6PA49Tib1iwvaSp8KoZca3CXU7IodHK1ljMJdUJPpLYik8BTyWJ4ZIzTw6PsPNjPN/5g5aRkPjg0whce3ceOg/1AaYklu36dGmF6Tb3PrLFv3d3H5u2HGB4Z5/N3/M6kx81VNy0mCef620LJsxoJPmqzL0XiJjIllFRJBIwf/PIwhweH+W+PvTQpUW3rOsKOg/2sXtE6KbEUKkdklzHyTQZ6fN9xdhzs5/F9x8lckS91n57+cxOWl/UqNZRTHik06abYx/aKbXBohG88/TrfePpg3vKIJsNI0FSWK00kRuCptUfAWLfyGk4Pj7DzYD9/+/s3lNQFsr5zEcMj4wyPjDE4NFLwSvP5yiaZSTvzgsup+6RWLwTSPeQD5y4yd+ZledcxyRdPZryp5Jl9lJD5XAs9dvZzSo3kc118OTuWzP+XDavalMilbCrLlSYSCTy19ghAc1MDn1v7O8xpbmLn62+xbmViCfLMCT333d5OT/857v/nF3nvgll8JjlKbJnRRHNTQ/oNkkq6mYln6+5eNm/v5tlD/Xzzkzemk/L6zkUTyiZzmpsm/H32ZJ21HfO5eelJ1ncuSl/sYP+Jd9jV3Zu+XzEljkJv6HzXmSzmA+CV6FM7OnA5V1+87/b2Sf8v+sBJuVSWK00kEngioYwBlk5SmSPEzJOIj+87Bhh7Dw/yXM8Az/UMML2xIV2bfrcHfDxHYkysY7KreyBdfsi8kPKOg/3cvPQk993eXnDFw/bbE0vKbljVRnNTA2s75vPM/pOeJ15TSr2WZr6TucXwSvQtM5o8a/nZsWT/v3jFL1IK9dmXJhIJHN5N1JAoSWy8bSnTG6fkLFt8aEkL18yaxvGzFzhx5jx/9L0X+PLdHbS3zkyXHpqbGiYlxg2r2kiUR2zSqNTr+0IyE1qmXIk5dUJ0YGiEuckEnu8NnW9Kf9CyP1yJRL9iwn10CCxSPZFI4Kmk8OyhUzjneK5ngNUrWvny3R1s3d3H+ZFxNn5kCZix/MqZyVLFKW5dNpfjZy/w1P6TnDk/Su+pX3HPymvYsGqJ59rgqRFy6vcpmYmo1KQ0sW5Oekfz4L0rczxWorb+6rGzPNczUHCb2SPeWidNHQKLVE8kEvjajvk82nWEXd2nAJg9vZEdB/sZHX+FXd2JJNcyo5HBoVEeuOs6vvnJZWzrOsIH2lo4cfYlevqHmNPcSN/AcEbNdmo6YadOMmaO4ItJhPnKBZk7BXg3oXldmi1T6oToB9paaPrZoUlLAXh13YRpxBuGnUgQVAqSKIhEAn9833F6+odYNGc6V8+axgt9pwEYHXds/MhSnnzlBEdOn2d2cyLxbd3dy+mhUR55YR99A8OsXtHK8vmXs+UXb/ChJXPYe/gMu7pPpZNpauJO5onHYuRLnrl+l2/FRJh4ibJUvT1VS/d6XD8j3kT3SB+pDholqMnCtmMU8RKJBH5+ZAyAI6fPc+Pi2UxrnMLiluns6R1k6hRj9Yor+cHzhzkzPMa3fnYoPYoGaJvbzIP3rgRgemMDz79xKl1e+fLdHemEnUpi7bfPzNmaly2z4yT7/vkW08pWyvK22bf7GfHmahOUd6kUJFEQiQR+5vwoAB1XzeTfXz3JhbFLvDlwHoDnegZ47zWzuHXZXDqunsUffHAR1y88xo6D/bx89Cy3LW9N9yy/fPQMe3oTo/ebrp2T89qVxY6+8l3Q95n9J4saQee6rZjrevqVq01Q3hWXUpDEWyQS+Au9gwAcO3OBC2OXAPjoilbOXRyn4+rLmd40hV3dAzQ2TGH/sbP87+cP85Flc3n56FnmzGgESM/QvKV9Lp1tLWxY1Tahe+XBe1dyeniErz6xn/s/NnktlHw10Vy91Nm3lXrfTEHWZHO1CYpItEQigT9070r+/J9f5J0LiZH4ojnTOT08yp7eQU6cPc/f/v4NdPWdZsfBfp5/Y4Dzo5d4av9bbFqzjHUrF/DtnT18oK2F1Stauf9jy/lVX2KHsL5zEc8e6k9fiPjlo2fT5Zfv/dEHJ8SQOUpe2zGfrz6xny/f3cGc5qYJNe1ca6d4yUzKha5Cn31FIBGRSCTwG6+dQ8MU452L40yxRC38yOnzzGlupKd/iIeePkj7lTN5rmeADy+dyy+TSfz86CW+8q+v8FzPAG1zm+kbGGZk7BLP9QykZ1redG0Lu7oH2Hv4NP/l1qW8OTjM/R9bPimGzFHyZx95kV3dA4yOv8JHlremR/HXL5xVMMl6tRUWc//MFRKDGo1XotNC3Rsi1ROJBD44NMLoeKJ0cim5BMlVs6bxH94znx88f5jRccfB374NwMj4JT59cxtbnn2Dl46cTte8+waGaW+dQXtrItGnZlquW3kNP9l3LN2O2NM/xLd+dogH713pufYIQMfVs9jVPUDH1bNY37ko3c1y/cLZRV0xPvNr9vf57p+Kx6vm7keQnRY6UhCpvkisRrh1dy+/ffvihNveuXCRaU0N3NI+lz29g9ywcA6rV7Ty1/e8j9RkmBXzr+CW9rlAouzS0z8EOG5pn8vG25ayvnMRz+w/Sd/AMABLW2eyekVruk8bvFdH+8xH23ngruv4zEcTCer6hbPYtGY561Zew/DIOFt3905YjTBT5gp+xazm53WfQisRFiuox4HMnYEF9pil0Cp2Uo8iMQJPrU8yo2kKQyOJkfjQRceWX7zBjYtns2D2NJ5/4xTXXXUFX/nXV2hvTXR9zJnRxLfuuJFtXUc4duY8P/jlYQ6ePMee3kE621rSE222HzjJC32n+fXhQZova0wndyjcIfKNpw+yeXs3m9Ys45n9J9PteZn19KDX6w6qQyLITot8q0BWg/q2pR5FIoFfflkDBunkDTBvRiMXxy7x4ptngESHysvH3k7/PnMUODwyni6xHD9znv9882L2Hh5Ml00+3D6PF/pO85vj7wCJlfUK9WO/y9JfM9vz1q1ckHdSUNwSTq3b7tS3LfXIEtfLrI7Ozk7X1dVV8t8t++8/ZexScXFOmzqFdTdcw+zmRjDjpSNn2JNsQ5zT3Mjp4VHaW2fQ0z/E6hWt6Uk+n33k1+zqPkXb3GYeunclO19/i2LWufY7kvbzdzpBKFKfzGyvc64z+/ZIjMCvnNnE8awaOEBjgzE6/m5inzrFuDB2iUf3HvV8nDveM5/jZ8+ztHUmd19/9YRp5N/85PvTybGUda79jjyzL8iQudRsruQct1G7iJQnEgn8VI4TUzOaGjhzfiz989glx+zpjemZm6ma+fzLL+PkOxe5evY0Zjc3suXZXj7YNocNq5Z4Pq7XOte5lDsq9loKN1dyVplARDJFIoGPjHuXTzKTN8AV06Zy5vwo06ZO4cLYpXTNvG3eDP741iWs7ZjPp7+zB4AX+k5PWBEwe3Sbuc519nKzmcm63FGx1xV8cql1nVlEwiUSCbxYrZdfxvDIeHq6fcdVMxkevcQX77yOtnkz+MKj+zh+9gKQaCvMnBSTWnQqtTBVKlmnZl2mZnlmj5LLHRV7XcFHRKQYZSVwM7sT2Aw0AN9xzn09kKh8OjI4POFk57Smqez/7Rl2vt7PztffSky2WXA5b18Y56HkRJ3sSTGpn1PJOvU1dQGJ7FGyRsUiUiu+E7iZNQD/C7gDOAr8yswed87tDyq4Uo2MO6Y3TuH8aGIEfuLMheRvEpdIA3j7wjh9A8P8qm+QG6+d43mdR3i3pJH5tdBJxmzqGhGRSipnJuYHgW7n3BvOuRHg/wD3BBOWPx9a0sITn/0IH1rSAsCJty9w67J5AKxbeQ23LptL38Awty6bO2k97VSCTf2cunZm6usz+0/ytSdfS8/QLEaqPl7K34iIFKucEsoCIDMzHQU+lH0nM9sIbARYvHixrw01AqM5fndr+1w6FsxieuOUdFvgzUtb2NM7yC3tc7np2tls3t5Nc9PU9MJVN13bUvKI2E+tW10jIlJJ5SRw87htUruIc24LsAUSE3n8bOj//ukq/vSHexkeGeOWZXM5PTzGDQtn85mPeq8jkrquZCpxTvx+8pXoi+Gn1q36uIhUku+ZmGb2YeB/OOf+Y/LnBwCcc1/L9Td+Z2KKiNSzXDMxy6mB/wpYbmZLzKwJ+ATweBmPJyIiJfBdQnHOjZnZnwP/TqKN8LvOuVcDi0xERPIqqw/cOfdT4KcBxSIiIiWIxAUdRERkMiVwEZGIUgIXEYkoJXARkYiq6hV5zKwfOOzzz+cBpwIMp5KiEmtU4gTFWglRiRMU67XOudbsG6uawMthZl1ejexhFJVYoxInKNZKiEqcoFhzUQlFRCSilMBFRCIqSgl8S60DKEFUYo1KnKBYKyEqcYJi9RSZGriIiEwUpRG4iIhkUAIXEYmoSCRwM7vTzA6aWbeZfanW8Xgxs0VmtsPMDpjZq2a2qdYxFWJmDWb2azN7otax5GNms83sMTN7Lfn6frjWMXkxs88n/+9fMbNHzGxarWNKMbPvmtlbZvZKxm0tZva0mR1Kfp1TyxhTcsT6t8n//5fN7P+Z2ewahpjmFWvG7/7CzJyZzavU9kOfwDMunnwX0AF80sw6ahuVpzHgC8659wA3A38W0jgzbQIO1DqIImwG/s05dx1wAyGM2cwWAJ8FOp1z7yOxxPInahvVBN8H7sy67UvAdufccmB78ucw+D6TY30aeJ9z7nrgdeCBageVw/eZHCtmtojEBd/frOTGQ5/ACeHFk7045044515Mfv8OiSSzoLZR5WZmC4HfBb5T61jyMbMrgNuAfwJwzo04587UNKjcpgLTzWwq0Awcr3E8ac65XwCDWTffA2xNfr8V+L1qxpSLV6zOuaecc2PJH58HFlY9MA85XleAbwB/icdlJoMUhQTudfHk0CZGADNrA94P7KlxKPn8PYk32KUax1HIUqAf+F6y3PMdM5tR66CyOeeOAX9HYsR1AjjrnHuqtlEVNN85dwISAxDgyhrHU6w/Bp6sdRC5mNk64Jhz7qVKbysKCbyoiyeHhZnNBP4F+Jxz7u1ax+PFzO4G3nLO7a11LEWYCtwI/KNz7v3AEOE51E9L1o/vAZYA1wAzzOxTtY0qfszsr0iUK39U61i8mFkz8FfAV6qxvSgk8KNA5mXkFxKiQ9NMZtZIInn/yDn341rHk8ctwDoz6yNRkvqYmf2wtiHldBQ46pxLHc08RiKhh81aoNc51++cGwV+DKyqcUyFnDSzqwGSX9+qcTx5mdkG4G7gP7nwTmBpJ7ETfyn5+VoIvGhmV1ViY1FI4JG4eLKZGYk67QHn3EO1jicf59wDzrmFzrk2Eq/nz5xzoRwtOud+CxwxsxXJm9YA+2sYUi5vAjebWXPyvbCGEJ5szfI4sCH5/QbgJzWMJS8zuxP4IrDOOTdc63hycc79xjl3pXOuLfn5OgrcmHwfBy70CTx54iJ18eQDwKMhvXjyLcCnSYxm9yX/fbzWQcXE/cCPzOxlYCXwN7UNZ7LkEcJjwIvAb0h8tkIz/dvMHgF+Cawws6Nm9ifA14E7zOwQiY6Jr9cyxpQcsf4DcDnwdPKz9XBNg0zKEWv1th/eIxEREckn9CNwERHxpgQuIhJRSuAiIhGlBC4iElFK4CIiEaUELiISUUrgIiIR9f8B2tOy0UsZx2IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.scatter(Y, yhat_nn, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skn</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>data_in</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elevation</th>\n",
       "      <th>Observer</th>\n",
       "      <th>Status2010</th>\n",
       "      <th>...</th>\n",
       "      <th>skt_5</th>\n",
       "      <th>slp_0</th>\n",
       "      <th>slp_1</th>\n",
       "      <th>slp_2</th>\n",
       "      <th>slp_3</th>\n",
       "      <th>slp_4</th>\n",
       "      <th>slp_5</th>\n",
       "      <th>season_dry</th>\n",
       "      <th>season_wet</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1948</td>\n",
       "      <td>2</td>\n",
       "      <td>1.33</td>\n",
       "      <td>KALAE</td>\n",
       "      <td>18.916176</td>\n",
       "      <td>-155.674994</td>\n",
       "      <td>35.0</td>\n",
       "      <td>USCG</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>...</td>\n",
       "      <td>22.042482</td>\n",
       "      <td>1015.34310</td>\n",
       "      <td>1015.23580</td>\n",
       "      <td>1015.47690</td>\n",
       "      <td>1016.23553</td>\n",
       "      <td>1015.97990</td>\n",
       "      <td>1015.8755</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>State/NCDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1948</td>\n",
       "      <td>2</td>\n",
       "      <td>2.96</td>\n",
       "      <td>KAMAOA</td>\n",
       "      <td>19.004216</td>\n",
       "      <td>-155.663882</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>KAWAIHAE RANCH</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>...</td>\n",
       "      <td>22.042482</td>\n",
       "      <td>1015.34310</td>\n",
       "      <td>1015.23580</td>\n",
       "      <td>1015.47690</td>\n",
       "      <td>1016.23553</td>\n",
       "      <td>1015.97990</td>\n",
       "      <td>1015.8755</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1948</td>\n",
       "      <td>2</td>\n",
       "      <td>3.12</td>\n",
       "      <td>KAMAOA-P RANCH</td>\n",
       "      <td>19.025326</td>\n",
       "      <td>-155.667215</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>PARKER RANCH</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>...</td>\n",
       "      <td>22.042482</td>\n",
       "      <td>1015.34310</td>\n",
       "      <td>1015.23580</td>\n",
       "      <td>1015.47690</td>\n",
       "      <td>1016.23553</td>\n",
       "      <td>1015.97990</td>\n",
       "      <td>1015.8755</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1948</td>\n",
       "      <td>2</td>\n",
       "      <td>8.20</td>\n",
       "      <td>KIOLAKAA A&amp;F</td>\n",
       "      <td>19.070326</td>\n",
       "      <td>-155.635548</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>STATE DIV FTRY</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>...</td>\n",
       "      <td>22.042482</td>\n",
       "      <td>1015.34310</td>\n",
       "      <td>1015.23580</td>\n",
       "      <td>1015.47690</td>\n",
       "      <td>1016.23553</td>\n",
       "      <td>1015.97990</td>\n",
       "      <td>1015.8755</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NCDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1948</td>\n",
       "      <td>2</td>\n",
       "      <td>3.79</td>\n",
       "      <td>KIOLAKAA-HAYSELD</td>\n",
       "      <td>19.050326</td>\n",
       "      <td>-155.622216</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>HAYSELDEN WH</td>\n",
       "      <td>Discontinued</td>\n",
       "      <td>...</td>\n",
       "      <td>22.042482</td>\n",
       "      <td>1015.34310</td>\n",
       "      <td>1015.23580</td>\n",
       "      <td>1015.47690</td>\n",
       "      <td>1016.23553</td>\n",
       "      <td>1015.97990</td>\n",
       "      <td>1015.8755</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>State/NCDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412247</th>\n",
       "      <td>1117.8</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>3.16</td>\n",
       "      <td>Hanalei</td>\n",
       "      <td>22.198500</td>\n",
       "      <td>-159.495300</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Hydronet</td>\n",
       "      <td>Current</td>\n",
       "      <td>...</td>\n",
       "      <td>23.491749</td>\n",
       "      <td>1018.06537</td>\n",
       "      <td>1018.20557</td>\n",
       "      <td>1018.53784</td>\n",
       "      <td>1019.63010</td>\n",
       "      <td>1019.50745</td>\n",
       "      <td>1019.5371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hydronet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412248</th>\n",
       "      <td>1134.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>1.95</td>\n",
       "      <td>KILAUEA</td>\n",
       "      <td>22.211941</td>\n",
       "      <td>-159.407202</td>\n",
       "      <td>315.0</td>\n",
       "      <td>RAPOZO N</td>\n",
       "      <td>Current</td>\n",
       "      <td>...</td>\n",
       "      <td>23.491749</td>\n",
       "      <td>1018.06537</td>\n",
       "      <td>1018.20557</td>\n",
       "      <td>1018.53784</td>\n",
       "      <td>1019.63010</td>\n",
       "      <td>1019.50745</td>\n",
       "      <td>1019.5371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412249</th>\n",
       "      <td>1137.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2.33</td>\n",
       "      <td>KOLOKO RES</td>\n",
       "      <td>22.181408</td>\n",
       "      <td>-159.377758</td>\n",
       "      <td>735.0</td>\n",
       "      <td>KILAUEA SUGAR</td>\n",
       "      <td>Current</td>\n",
       "      <td>...</td>\n",
       "      <td>23.491749</td>\n",
       "      <td>1018.06537</td>\n",
       "      <td>1018.20557</td>\n",
       "      <td>1018.53784</td>\n",
       "      <td>1019.63010</td>\n",
       "      <td>1019.50745</td>\n",
       "      <td>1019.5371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412250</th>\n",
       "      <td>1145.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>1.05</td>\n",
       "      <td>PUU AUAU</td>\n",
       "      <td>22.182760</td>\n",
       "      <td>-159.332203</td>\n",
       "      <td>330.0</td>\n",
       "      <td>LIHUE PLANTATION</td>\n",
       "      <td>Current</td>\n",
       "      <td>...</td>\n",
       "      <td>23.491749</td>\n",
       "      <td>1018.06537</td>\n",
       "      <td>1018.20557</td>\n",
       "      <td>1018.53784</td>\n",
       "      <td>1019.63010</td>\n",
       "      <td>1019.50745</td>\n",
       "      <td>1019.5371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412251</th>\n",
       "      <td>1146.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Moloaa Dairy</td>\n",
       "      <td>22.183333</td>\n",
       "      <td>-159.337500</td>\n",
       "      <td>280.0</td>\n",
       "      <td>RAWS</td>\n",
       "      <td>Current</td>\n",
       "      <td>...</td>\n",
       "      <td>23.491749</td>\n",
       "      <td>1018.06537</td>\n",
       "      <td>1018.20557</td>\n",
       "      <td>1018.53784</td>\n",
       "      <td>1019.63010</td>\n",
       "      <td>1019.50745</td>\n",
       "      <td>1019.5371</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>RAWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412252 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           skn  year  month  data_in              name        lat         lon  \\\n",
       "0          1.0  1948      2     1.33             KALAE  18.916176 -155.674994   \n",
       "1          4.0  1948      2     2.96            KAMAOA  19.004216 -155.663882   \n",
       "2          5.0  1948      2     3.12    KAMAOA-P RANCH  19.025326 -155.667215   \n",
       "3          6.0  1948      2     8.20      KIOLAKAA A&F  19.070326 -155.635548   \n",
       "4          7.0  1948      2     3.79  KIOLAKAA-HAYSELD  19.050326 -155.622216   \n",
       "...        ...   ...    ...      ...               ...        ...         ...   \n",
       "412247  1117.8  2012      5     3.16           Hanalei  22.198500 -159.495300   \n",
       "412248  1134.0  2012      5     1.95           KILAUEA  22.211941 -159.407202   \n",
       "412249  1137.0  2012      5     2.33        KOLOKO RES  22.181408 -159.377758   \n",
       "412250  1145.0  2012      5     1.05          PUU AUAU  22.182760 -159.332203   \n",
       "412251  1146.0  2012      5     0.85      Moloaa Dairy  22.183333 -159.337500   \n",
       "\n",
       "        elevation          Observer    Status2010  ...      skt_5       slp_0  \\\n",
       "0            35.0              USCG  Discontinued  ...  22.042482  1015.34310   \n",
       "1          1070.0    KAWAIHAE RANCH  Discontinued  ...  22.042482  1015.34310   \n",
       "2          1375.0      PARKER RANCH  Discontinued  ...  22.042482  1015.34310   \n",
       "3          1925.0    STATE DIV FTRY  Discontinued  ...  22.042482  1015.34310   \n",
       "4          1050.0      HAYSELDEN WH  Discontinued  ...  22.042482  1015.34310   \n",
       "...           ...               ...           ...  ...        ...         ...   \n",
       "412247       16.0          Hydronet       Current  ...  23.491749  1018.06537   \n",
       "412248      315.0          RAPOZO N       Current  ...  23.491749  1018.06537   \n",
       "412249      735.0     KILAUEA SUGAR       Current  ...  23.491749  1018.06537   \n",
       "412250      330.0  LIHUE PLANTATION       Current  ...  23.491749  1018.06537   \n",
       "412251      280.0              RAWS       Current  ...  23.491749  1018.06537   \n",
       "\n",
       "             slp_1       slp_2       slp_3       slp_4      slp_5  season_dry  \\\n",
       "0       1015.23580  1015.47690  1016.23553  1015.97990  1015.8755           0   \n",
       "1       1015.23580  1015.47690  1016.23553  1015.97990  1015.8755           0   \n",
       "2       1015.23580  1015.47690  1016.23553  1015.97990  1015.8755           0   \n",
       "3       1015.23580  1015.47690  1016.23553  1015.97990  1015.8755           0   \n",
       "4       1015.23580  1015.47690  1016.23553  1015.97990  1015.8755           0   \n",
       "...            ...         ...         ...         ...        ...         ...   \n",
       "412247  1018.20557  1018.53784  1019.63010  1019.50745  1019.5371           1   \n",
       "412248  1018.20557  1018.53784  1019.63010  1019.50745  1019.5371           1   \n",
       "412249  1018.20557  1018.53784  1019.63010  1019.50745  1019.5371           1   \n",
       "412250  1018.20557  1018.53784  1019.63010  1019.50745  1019.5371           1   \n",
       "412251  1018.20557  1018.53784  1019.63010  1019.50745  1019.5371           1   \n",
       "\n",
       "        season_wet      method  \n",
       "0                1  State/NCDC  \n",
       "1                1       State  \n",
       "2                1       State  \n",
       "3                1        NCDC  \n",
       "4                1  State/NCDC  \n",
       "...            ...         ...  \n",
       "412247           0    Hydronet  \n",
       "412248           0       State  \n",
       "412249           0       State  \n",
       "412250           0       State  \n",
       "412251           0        RAWS  \n",
       "\n",
       "[412252 rows x 160 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nonfilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station with skn: 396.0 was chosen out of all stations with more than 750 historical (non-filled) rainfall observations.\n",
      "There are 778 rainfall observations from this station.\n"
     ]
    }
   ],
   "source": [
    "columns = C_SINGLE\n",
    "columns.append('month')\n",
    "# load nonfilled dataset\n",
    "df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "# sample a station: returned object is sorted.\n",
    "df_station = sample_station(df=df_nonfilled, threshold=750, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_station[columns])\n",
    "Y = np.array(df_station['data_in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y)\n",
    "\n",
    "model.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6085696345398741"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(Ytest, yhat, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(\n",
    "    input_dim=20, \n",
    "    lr=0.005, \n",
    "    activation='relu',\n",
    "    n_units=1024,\n",
    "    n_layers=2,\n",
    "    dropout=0.5\n",
    "):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=n_units, activation=activation)(inputs)\n",
    "    \n",
    "    for i in range(n_layers - 1):\n",
    "        if dropout:\n",
    "            x = Dropout(rate=dropout)(x)\n",
    "        x = Dense(units=n_units, activation=activation)(x)\n",
    "    outputs = Dense(units=1, kernel_initializer=tf.keras.initializers.HeNormal, activation='softplus')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss='mse',\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def define_hetero_model_gamma(\n",
    "    input_dim=20, lr=0.0065,\n",
    "    n_additional_layers_main=4,\n",
    "    n_additional_layers_sub=2,\n",
    "    activation='elu',\n",
    "    n_units_main=512,\n",
    "    n_units_sub=256,\n",
    "    dropout=0.5,\n",
    "):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(\n",
    "        units=n_units_main, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal,\n",
    "        kernel_regularizer='l1'\n",
    "    )(inputs)\n",
    "    \n",
    "    for _ in range(n_additional_layers_main):\n",
    "        x = Dense(units=n_units_main, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal, kernel_regularizer='l1')(x)\n",
    "        if dropout:\n",
    "            x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    m = Dense(units=n_units_sub, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal, kernel_regularizer='l1')(x)\n",
    "    for _ in range(n_additional_layers_sub):\n",
    "        m = Dense(units=n_units_sub, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal, kernel_regularizer='l1')(m)\n",
    "    m = Dense(units=10, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal, kernel_regularizer='l1')(m)\n",
    "    m = Dense(units=1, activation='linear', kernel_initializer=tf.keras.initializers.HeNormal, kernel_regularizer='l1')(m)\n",
    "    \n",
    "    s = Dense(units=n_units_sub, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal, kernel_regularizer='l1')(x)\n",
    "    for _ in range(n_additional_layers_sub):\n",
    "        s = Dense(units=n_units_sub, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal, kernel_regularizer='l1')(s)\n",
    "    s = Dense(units=10, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal, kernel_regularizer='l1')(s)\n",
    "    s = Dense(units=1, activation='linear', kernel_initializer=tf.keras.initializers.HeNormal, kernel_regularizer='l1')(s)\n",
    "    \n",
    "    ms = Concatenate(axis=-1)([m, s])\n",
    "    outputs = tfp.layers.DistributionLambda(\n",
    "        make_distribution_fn=lambda t: tfd.Gamma(\n",
    "            concentration=tf.math.softplus(t[...,0]), rate=tf.math.softplus(t[...,1])\n",
    "        ),\n",
    "        convert_to_tensor_fn=lambda d: d.mean()\n",
    "    )(ms)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    epsilon=1e-5 # for loss function\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss=lambda y, p_y: -p_y.log_prob(y + epsilon),\n",
    "        # loss=safe_nll,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def define_hetero_model_normal(\n",
    "    input_dim, lr=0.0065,\n",
    "    n_additional_layers_main=0,\n",
    "    n_additional_layers_sub=0,\n",
    "    activation='relu',\n",
    "    n_units_main=512,\n",
    "    n_units_sub=10,\n",
    "    dropout=0.5,\n",
    "    l2_sigma=100,\n",
    "    sigma_a=0.001,# these hyperparameters might have significant affect\n",
    "    sigma_b=0.03 # these hyperparameters might have signigicant affect\n",
    "):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=n_units_main, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal)(inputs)\n",
    "    # main branch\n",
    "    for _ in range(n_additional_layers_main):\n",
    "        if dropout:\n",
    "            x = Dropout(rate=dropout)(x)\n",
    "        x = Dense(units=n_units_main, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal)(x)\n",
    "    # mean branch\n",
    "    if n_additional_layers_sub == 0:\n",
    "        m = Dense(units=1, activation='linear', kernel_initializer=tf.keras.initializers.HeNormal)(x)\n",
    "    else:\n",
    "        m = Dense(units=n_units_sub, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal)(x)\n",
    "        for _ in range(n_additional_layers_sub - 1):\n",
    "            m = Dense(units=n_units_sub, activation=activation)(m)\n",
    "        m = Dense(units=1, activation='linear', kernel_initializer=tf.keras.initializers.HeNormal)(m)\n",
    "    \n",
    "    # std branch\n",
    "    if n_additional_layers_sub == 0:\n",
    "        s = Dense(units=1, activation='linear', kernel_initializer=tf.keras.initializers.HeNormal, kernel_regularizer=tf.keras.regularizers.L2(l2=l2_sigma))(x)\n",
    "    else:\n",
    "        s = Dense(units=n_units_sub, activation=activation, kernel_initializer=tf.keras.initializers.HeNormal)(x)\n",
    "        for _ in range(n_additional_layers_sub - 1):\n",
    "            s = Dense(units=n_units_sub, activation=activation)(s)\n",
    "        s = Dense(units=1, activation='linear', kernel_initializer=tf.keras.initializers.HeNormal, kernel_regularizer=tf.keras.regularizers.L2(l2=l2_sigma))(s)\n",
    "    \n",
    "    ms = Concatenate(axis=-1)([m, s])\n",
    "    outputs = tfp.layers.DistributionLambda(\n",
    "        make_distribution_fn=lambda t: tfd.Normal(\n",
    "            loc=t[...,0], scale=tf.math.softplus(sigma_a * t[...,1] + sigma_b)\n",
    "        ),\n",
    "        convert_to_tensor_fn=lambda s: s.mean()\n",
    "    )(ms)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        # loss=lambda y, p_y: -p_y.log_prob(y),\n",
    "        loss=lambda y, p_y: -p_y.log_prob(y + 1e-5),\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = C_SINGLE\n",
    "columns.append('month')\n",
    "# load nonfilled dataset\n",
    "df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "# sample a station: returned object is sorted.\n",
    "# df_station = sample_station(df=df_nonfilled, threshold=750, seed=42)\n",
    "df_valid_skn = df_nonfilled.groupby('skn').size().reset_index().rename(columns={0: \"n_data\"})\n",
    "df_vali_skn = df_valid_skn[df_valid_skn['n_data'] > 750]\n",
    "\n",
    "df_valid = df_nonfilled.merge(df_vali_skn, left_on='skn', right_on='skn', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.28\n"
     ]
    }
   ],
   "source": [
    "ytrue = []\n",
    "yhat = []\n",
    "for name, group in df_valid.groupby(by='skn'):\n",
    "    group.sort_values(['year', 'month'])\n",
    "    X = np.array(group[columns])\n",
    "    Y = np.array(group['data_in'])\n",
    "    \n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, shuffle=False)\n",
    "    model = LinearRegression()\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    ytrue.extend(Ytest)\n",
    "    yhat.extend(model.predict(Xtest))\n",
    "\n",
    "rmse = mean_squared_error(ytrue, yhat, squared=False)\n",
    "print(\"{:.2f}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "X = np.array(df_valid[columns])\n",
    "Y = np.array(df_valid['data_in'])\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y)\n",
    "scaler = MinMaxScaler()\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "Xtest = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 29.6706 - root_mean_squared_error: 5.0517\n",
      "Epoch 2/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 20.5390 - root_mean_squared_error: 4.4848\n",
      "Epoch 3/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 17.2666 - root_mean_squared_error: 4.1062\n",
      "Epoch 4/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 15.6542 - root_mean_squared_error: 3.9078\n",
      "Epoch 5/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 14.7549 - root_mean_squared_error: 3.7944\n",
      "Epoch 6/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 13.9053 - root_mean_squared_error: 3.6838\n",
      "Epoch 7/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 13.3034 - root_mean_squared_error: 3.6043\n",
      "Epoch 8/50\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 13.0785 - root_mean_squared_error: 3.5771\n",
      "Epoch 9/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 12.7378 - root_mean_squared_error: 3.5328\n",
      "Epoch 10/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 12.5105 - root_mean_squared_error: 3.5045\n",
      "Epoch 11/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 12.5198 - root_mean_squared_error: 3.5108\n",
      "Epoch 12/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 12.2697 - root_mean_squared_error: 3.4787\n",
      "Epoch 13/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 11.9348 - root_mean_squared_error: 3.4334\n",
      "Epoch 14/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 12.0502 - root_mean_squared_error: 3.4557\n",
      "Epoch 15/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 11.7410 - root_mean_squared_error: 3.4137\n",
      "Epoch 16/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 11.7130 - root_mean_squared_error: 3.4144\n",
      "Epoch 17/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 11.6583 - root_mean_squared_error: 3.4110\n",
      "Epoch 18/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 11.5115 - root_mean_squared_error: 3.3933\n",
      "Epoch 19/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 11.5573 - root_mean_squared_error: 3.4054\n",
      "Epoch 20/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 11.3986 - root_mean_squared_error: 3.3856\n",
      "Epoch 21/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 11.4038 - root_mean_squared_error: 3.3915\n",
      "Epoch 22/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 11.1530 - root_mean_squared_error: 3.3568\n",
      "Epoch 23/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 11.1369 - root_mean_squared_error: 3.3592\n",
      "Epoch 24/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 11.1492 - root_mean_squared_error: 3.3661\n",
      "Epoch 25/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.9444 - root_mean_squared_error: 3.3382\n",
      "Epoch 26/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.8575 - root_mean_squared_error: 3.3290\n",
      "Epoch 27/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.7929 - root_mean_squared_error: 3.3233\n",
      "Epoch 28/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.9788 - root_mean_squared_error: 3.3584\n",
      "Epoch 29/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.7225 - root_mean_squared_error: 3.3216\n",
      "Epoch 30/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.5927 - root_mean_squared_error: 3.3050\n",
      "Epoch 31/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.6781 - root_mean_squared_error: 3.3240\n",
      "Epoch 32/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.4387 - root_mean_squared_error: 3.2891\n",
      "Epoch 33/50\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 10.7447 - root_mean_squared_error: 3.3450\n",
      "Epoch 34/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.3370 - root_mean_squared_error: 3.2818\n",
      "Epoch 35/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.3575 - root_mean_squared_error: 3.2901\n",
      "Epoch 36/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.3296 - root_mean_squared_error: 3.2903\n",
      "Epoch 37/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.3541 - root_mean_squared_error: 3.2993\n",
      "Epoch 38/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.0980 - root_mean_squared_error: 3.2604\n",
      "Epoch 39/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.2263 - root_mean_squared_error: 3.2873\n",
      "Epoch 40/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.2110 - root_mean_squared_error: 3.2895\n",
      "Epoch 41/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.1126 - root_mean_squared_error: 3.2774\n",
      "Epoch 42/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.0475 - root_mean_squared_error: 3.2710\n",
      "Epoch 43/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 10.0555 - root_mean_squared_error: 3.2772\n",
      "Epoch 44/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 9.9328 - root_mean_squared_error: 3.2605\n",
      "Epoch 45/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 9.9214 - root_mean_squared_error: 3.2633\n",
      "Epoch 46/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 9.8417 - root_mean_squared_error: 3.2539\n",
      "Epoch 47/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 9.8583 - root_mean_squared_error: 3.2616\n",
      "Epoch 48/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 9.6596 - root_mean_squared_error: 3.2309\n",
      "Epoch 49/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 9.6665 - root_mean_squared_error: 3.2368\n",
      "Epoch 50/50\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 9.5958 - root_mean_squared_error: 3.2288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b382d080fd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, train on all stations\n",
    "model = define_hetero_model_normal(input_dim=len(columns), n_additional_layers_main=0, n_additional_layers_sub=0, n_units_main=216)\n",
    "model.fit(Xtrain, Ytrain, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 22.1294 - root_mean_squared_error: 4.9915\n",
      "Epoch 2/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 3.4125 - root_mean_squared_error: 1.7832\n",
      "Epoch 3/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.8418 - root_mean_squared_error: 1.5989\n",
      "Epoch 4/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.6387 - root_mean_squared_error: 1.5249\n",
      "Epoch 5/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.5006 - root_mean_squared_error: 1.4713\n",
      "Epoch 6/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.4597 - root_mean_squared_error: 1.4549\n",
      "Epoch 7/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.4178 - root_mean_squared_error: 1.4380\n",
      "Epoch 8/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.3963 - root_mean_squared_error: 1.4292\n",
      "Epoch 9/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.3539 - root_mean_squared_error: 1.4118\n",
      "Epoch 10/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.3950 - root_mean_squared_error: 1.4287\n",
      "Epoch 11/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.3164 - root_mean_squared_error: 1.3961\n",
      "Epoch 12/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.3417 - root_mean_squared_error: 1.4067\n",
      "Epoch 13/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.3911 - root_mean_squared_error: 1.4270\n",
      "Epoch 14/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.3227 - root_mean_squared_error: 1.3988\n",
      "Epoch 15/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2485 - root_mean_squared_error: 1.3674\n",
      "Epoch 16/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2947 - root_mean_squared_error: 1.3870\n",
      "Epoch 17/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.3018 - root_mean_squared_error: 1.3900\n",
      "Epoch 18/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2408 - root_mean_squared_error: 1.3642\n",
      "Epoch 19/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2318 - root_mean_squared_error: 1.3603\n",
      "Epoch 20/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2132 - root_mean_squared_error: 1.3522\n",
      "Epoch 21/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2095 - root_mean_squared_error: 1.3506\n",
      "Epoch 22/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2092 - root_mean_squared_error: 1.3505\n",
      "Epoch 23/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2852 - root_mean_squared_error: 1.3831\n",
      "Epoch 24/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2441 - root_mean_squared_error: 1.3656\n",
      "Epoch 25/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2246 - root_mean_squared_error: 1.3572\n",
      "Epoch 26/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2866 - root_mean_squared_error: 1.3838\n",
      "Epoch 27/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.3112 - root_mean_squared_error: 1.3940\n",
      "Epoch 28/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1790 - root_mean_squared_error: 1.3375\n",
      "Epoch 29/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2157 - root_mean_squared_error: 1.3534\n",
      "Epoch 30/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1861 - root_mean_squared_error: 1.3405\n",
      "Epoch 31/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1883 - root_mean_squared_error: 1.3414\n",
      "Epoch 32/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2133 - root_mean_squared_error: 1.3524\n",
      "Epoch 33/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1602 - root_mean_squared_error: 1.3292\n",
      "Epoch 34/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1843 - root_mean_squared_error: 1.3398\n",
      "Epoch 35/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1646 - root_mean_squared_error: 1.3312\n",
      "Epoch 36/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1898 - root_mean_squared_error: 1.3422\n",
      "Epoch 37/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1470 - root_mean_squared_error: 1.3234\n",
      "Epoch 38/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1394 - root_mean_squared_error: 1.3200\n",
      "Epoch 39/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1598 - root_mean_squared_error: 1.3290\n",
      "Epoch 40/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.2233 - root_mean_squared_error: 1.3568\n",
      "Epoch 41/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1649 - root_mean_squared_error: 1.3313\n",
      "Epoch 42/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1076 - root_mean_squared_error: 1.3059\n",
      "Epoch 43/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1272 - root_mean_squared_error: 1.3147\n",
      "Epoch 44/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1162 - root_mean_squared_error: 1.3098\n",
      "Epoch 45/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1557 - root_mean_squared_error: 1.3273\n",
      "Epoch 46/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1195 - root_mean_squared_error: 1.3113\n",
      "Epoch 47/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1028 - root_mean_squared_error: 1.3038\n",
      "Epoch 48/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1058 - root_mean_squared_error: 1.3051\n",
      "Epoch 49/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0972 - root_mean_squared_error: 1.3013\n",
      "Epoch 50/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1276 - root_mean_squared_error: 1.3148\n",
      "Epoch 51/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1652 - root_mean_squared_error: 1.3315\n",
      "Epoch 52/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1140 - root_mean_squared_error: 1.3088\n",
      "Epoch 53/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1462 - root_mean_squared_error: 1.3232\n",
      "Epoch 54/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0892 - root_mean_squared_error: 1.2978\n",
      "Epoch 55/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1103 - root_mean_squared_error: 1.3072\n",
      "Epoch 56/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1041 - root_mean_squared_error: 1.3044\n",
      "Epoch 57/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0844 - root_mean_squared_error: 1.2956\n",
      "Epoch 58/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0778 - root_mean_squared_error: 1.2926\n",
      "Epoch 59/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1602 - root_mean_squared_error: 1.3295\n",
      "Epoch 60/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1021 - root_mean_squared_error: 1.3036\n",
      "Epoch 61/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0630 - root_mean_squared_error: 1.2859\n",
      "Epoch 62/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0860 - root_mean_squared_error: 1.2963\n",
      "Epoch 63/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0997 - root_mean_squared_error: 1.3025\n",
      "Epoch 64/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0920 - root_mean_squared_error: 1.2990\n",
      "Epoch 65/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1068 - root_mean_squared_error: 1.3057\n",
      "Epoch 66/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1129 - root_mean_squared_error: 1.3085\n",
      "Epoch 67/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0756 - root_mean_squared_error: 1.2917\n",
      "Epoch 68/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0543 - root_mean_squared_error: 1.2819\n",
      "Epoch 69/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0416 - root_mean_squared_error: 1.2762\n",
      "Epoch 70/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0535 - root_mean_squared_error: 1.2816\n",
      "Epoch 71/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1046 - root_mean_squared_error: 1.3048\n",
      "Epoch 72/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0685 - root_mean_squared_error: 1.2886\n",
      "Epoch 73/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1479 - root_mean_squared_error: 1.3242\n",
      "Epoch 74/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1047 - root_mean_squared_error: 1.3049\n",
      "Epoch 75/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0566 - root_mean_squared_error: 1.2830\n",
      "Epoch 76/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.1197 - root_mean_squared_error: 1.3116\n",
      "Epoch 77/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0426 - root_mean_squared_error: 1.2767\n",
      "Epoch 78/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0803 - root_mean_squared_error: 1.2940\n",
      "Epoch 79/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0699 - root_mean_squared_error: 1.2892\n",
      "Epoch 80/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0657 - root_mean_squared_error: 1.2874\n",
      "Epoch 81/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0181 - root_mean_squared_error: 1.2654\n",
      "Epoch 82/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0622 - root_mean_squared_error: 1.2858\n",
      "Epoch 83/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0505 - root_mean_squared_error: 1.2804\n",
      "Epoch 84/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0541 - root_mean_squared_error: 1.2821\n",
      "Epoch 85/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0507 - root_mean_squared_error: 1.2806\n",
      "Epoch 86/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0712 - root_mean_squared_error: 1.2898\n",
      "Epoch 87/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0635 - root_mean_squared_error: 1.2862\n",
      "Epoch 88/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0023 - root_mean_squared_error: 1.2581\n",
      "Epoch 89/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0046 - root_mean_squared_error: 1.2591\n",
      "Epoch 90/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0511 - root_mean_squared_error: 1.2807\n",
      "Epoch 91/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0141 - root_mean_squared_error: 1.2637\n",
      "Epoch 92/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0870 - root_mean_squared_error: 1.2971\n",
      "Epoch 93/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0907 - root_mean_squared_error: 1.2988\n",
      "Epoch 94/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0082 - root_mean_squared_error: 1.2611\n",
      "Epoch 95/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9924 - root_mean_squared_error: 1.2537\n",
      "Epoch 96/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0215 - root_mean_squared_error: 1.2673\n",
      "Epoch 97/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0514 - root_mean_squared_error: 1.2810\n",
      "Epoch 98/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9802 - root_mean_squared_error: 1.2481\n",
      "Epoch 99/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9835 - root_mean_squared_error: 1.2496\n",
      "Epoch 100/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0485 - root_mean_squared_error: 1.2796\n",
      "Epoch 101/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0493 - root_mean_squared_error: 1.2800\n",
      "Epoch 102/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0096 - root_mean_squared_error: 1.2618\n",
      "Epoch 103/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9901 - root_mean_squared_error: 1.2528\n",
      "Epoch 104/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0230 - root_mean_squared_error: 1.2680\n",
      "Epoch 105/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9844 - root_mean_squared_error: 1.2500\n",
      "Epoch 106/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9861 - root_mean_squared_error: 1.2508\n",
      "Epoch 107/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9642 - root_mean_squared_error: 1.2405\n",
      "Epoch 108/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0197 - root_mean_squared_error: 1.2665\n",
      "Epoch 109/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9675 - root_mean_squared_error: 1.2422\n",
      "Epoch 110/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0181 - root_mean_squared_error: 1.2658\n",
      "Epoch 111/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9690 - root_mean_squared_error: 1.2430\n",
      "Epoch 112/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9531 - root_mean_squared_error: 1.2353\n",
      "Epoch 113/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0647 - root_mean_squared_error: 1.2872\n",
      "Epoch 114/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0566 - root_mean_squared_error: 1.2835\n",
      "Epoch 115/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0964 - root_mean_squared_error: 1.3016\n",
      "Epoch 116/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9647 - root_mean_squared_error: 1.2409\n",
      "Epoch 117/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0275 - root_mean_squared_error: 1.2703\n",
      "Epoch 118/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0074 - root_mean_squared_error: 1.2610\n",
      "Epoch 119/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9911 - root_mean_squared_error: 1.2533\n",
      "Epoch 120/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0461 - root_mean_squared_error: 1.2790\n",
      "Epoch 121/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0271 - root_mean_squared_error: 1.2702\n",
      "Epoch 122/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9984 - root_mean_squared_error: 1.2568\n",
      "Epoch 123/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0591 - root_mean_squared_error: 1.2849\n",
      "Epoch 124/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0245 - root_mean_squared_error: 1.2689\n",
      "Epoch 125/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9550 - root_mean_squared_error: 1.2365\n",
      "Epoch 126/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9777 - root_mean_squared_error: 1.2472\n",
      "Epoch 127/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9759 - root_mean_squared_error: 1.2463\n",
      "Epoch 128/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9508 - root_mean_squared_error: 1.2345\n",
      "Epoch 129/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9887 - root_mean_squared_error: 1.2523\n",
      "Epoch 130/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9563 - root_mean_squared_error: 1.2371\n",
      "Epoch 131/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0610 - root_mean_squared_error: 1.2859\n",
      "Epoch 132/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9933 - root_mean_squared_error: 1.2546\n",
      "Epoch 133/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9343 - root_mean_squared_error: 1.2267\n",
      "Epoch 134/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9633 - root_mean_squared_error: 1.2405\n",
      "Epoch 135/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9613 - root_mean_squared_error: 1.2396\n",
      "Epoch 136/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9488 - root_mean_squared_error: 1.2335\n",
      "Epoch 137/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9289 - root_mean_squared_error: 1.2242\n",
      "Epoch 138/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0219 - root_mean_squared_error: 1.2680\n",
      "Epoch 139/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0206 - root_mean_squared_error: 1.2674\n",
      "Epoch 140/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9948 - root_mean_squared_error: 1.2554\n",
      "Epoch 141/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9519 - root_mean_squared_error: 1.2352\n",
      "Epoch 142/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9283 - root_mean_squared_error: 1.2240\n",
      "Epoch 143/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9612 - root_mean_squared_error: 1.2396\n",
      "Epoch 144/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9232 - root_mean_squared_error: 1.2215\n",
      "Epoch 145/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9321 - root_mean_squared_error: 1.2258\n",
      "Epoch 146/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9607 - root_mean_squared_error: 1.2394\n",
      "Epoch 147/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9533 - root_mean_squared_error: 1.2359\n",
      "Epoch 148/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9223 - root_mean_squared_error: 1.2212\n",
      "Epoch 149/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9183 - root_mean_squared_error: 1.2193\n",
      "Epoch 150/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9071 - root_mean_squared_error: 1.2139\n",
      "Epoch 151/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9789 - root_mean_squared_error: 1.2482\n",
      "Epoch 152/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9591 - root_mean_squared_error: 1.2388\n",
      "Epoch 153/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9206 - root_mean_squared_error: 1.2203\n",
      "Epoch 154/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9763 - root_mean_squared_error: 1.2469\n",
      "Epoch 155/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9563 - root_mean_squared_error: 1.2375\n",
      "Epoch 156/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8938 - root_mean_squared_error: 1.2076\n",
      "Epoch 157/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9005 - root_mean_squared_error: 1.2109\n",
      "Epoch 158/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0339 - root_mean_squared_error: 1.2739\n",
      "Epoch 159/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9346 - root_mean_squared_error: 1.2273\n",
      "Epoch 160/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9065 - root_mean_squared_error: 1.2136\n",
      "Epoch 161/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8835 - root_mean_squared_error: 1.2025\n",
      "Epoch 162/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9049 - root_mean_squared_error: 1.2130\n",
      "Epoch 163/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9081 - root_mean_squared_error: 1.2146\n",
      "Epoch 164/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9136 - root_mean_squared_error: 1.2172\n",
      "Epoch 165/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8964 - root_mean_squared_error: 1.2089\n",
      "Epoch 166/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8841 - root_mean_squared_error: 1.2030\n",
      "Epoch 167/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9216 - root_mean_squared_error: 1.2213\n",
      "Epoch 168/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0298 - root_mean_squared_error: 1.2722\n",
      "Epoch 169/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 2.0870 - root_mean_squared_error: 1.2984\n",
      "Epoch 170/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9818 - root_mean_squared_error: 1.2498\n",
      "Epoch 171/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9225 - root_mean_squared_error: 1.2217\n",
      "Epoch 172/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8639 - root_mean_squared_error: 1.1932\n",
      "Epoch 173/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8728 - root_mean_squared_error: 1.1975\n",
      "Epoch 174/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8910 - root_mean_squared_error: 1.2065\n",
      "Epoch 175/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8552 - root_mean_squared_error: 1.1889\n",
      "Epoch 176/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8662 - root_mean_squared_error: 1.1944\n",
      "Epoch 177/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8830 - root_mean_squared_error: 1.2026\n",
      "Epoch 178/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8752 - root_mean_squared_error: 1.1988\n",
      "Epoch 179/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8967 - root_mean_squared_error: 1.2093\n",
      "Epoch 180/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9148 - root_mean_squared_error: 1.2182\n",
      "Epoch 181/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8867 - root_mean_squared_error: 1.2045\n",
      "Epoch 182/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8886 - root_mean_squared_error: 1.2055\n",
      "Epoch 183/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8747 - root_mean_squared_error: 1.1986\n",
      "Epoch 184/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9384 - root_mean_squared_error: 1.2296\n",
      "Epoch 185/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9248 - root_mean_squared_error: 1.2230\n",
      "Epoch 186/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8831 - root_mean_squared_error: 1.2028\n",
      "Epoch 187/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8671 - root_mean_squared_error: 1.1950\n",
      "Epoch 188/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9049 - root_mean_squared_error: 1.2135\n",
      "Epoch 189/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8359 - root_mean_squared_error: 1.1796\n",
      "Epoch 190/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9206 - root_mean_squared_error: 1.2210\n",
      "Epoch 191/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9038 - root_mean_squared_error: 1.2130\n",
      "Epoch 192/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9390 - root_mean_squared_error: 1.2299\n",
      "Epoch 193/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8973 - root_mean_squared_error: 1.2099\n",
      "Epoch 194/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8727 - root_mean_squared_error: 1.1979\n",
      "Epoch 195/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8787 - root_mean_squared_error: 1.2010\n",
      "Epoch 196/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8807 - root_mean_squared_error: 1.2019\n",
      "Epoch 197/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8588 - root_mean_squared_error: 1.1910\n",
      "Epoch 198/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8730 - root_mean_squared_error: 1.1981\n",
      "Epoch 199/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8504 - root_mean_squared_error: 1.1870\n",
      "Epoch 200/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8321 - root_mean_squared_error: 1.1779\n",
      "Epoch 201/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8383 - root_mean_squared_error: 1.1809\n",
      "Epoch 202/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8598 - root_mean_squared_error: 1.1916\n",
      "Epoch 203/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8435 - root_mean_squared_error: 1.1836\n",
      "Epoch 204/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8468 - root_mean_squared_error: 1.1853\n",
      "Epoch 205/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8574 - root_mean_squared_error: 1.1905\n",
      "Epoch 206/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8490 - root_mean_squared_error: 1.1864\n",
      "Epoch 207/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8845 - root_mean_squared_error: 1.2038\n",
      "Epoch 208/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9072 - root_mean_squared_error: 1.2151\n",
      "Epoch 209/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8755 - root_mean_squared_error: 1.1996\n",
      "Epoch 210/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8535 - root_mean_squared_error: 1.1887\n",
      "Epoch 211/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8196 - root_mean_squared_error: 1.1719\n",
      "Epoch 212/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8521 - root_mean_squared_error: 1.1881\n",
      "Epoch 213/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9153 - root_mean_squared_error: 1.2191\n",
      "Epoch 214/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9884 - root_mean_squared_error: 1.2540\n",
      "Epoch 215/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8651 - root_mean_squared_error: 1.1946\n",
      "Epoch 216/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8396 - root_mean_squared_error: 1.1819\n",
      "Epoch 217/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8550 - root_mean_squared_error: 1.1897\n",
      "Epoch 218/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8505 - root_mean_squared_error: 1.1874\n",
      "Epoch 219/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8041 - root_mean_squared_error: 1.1641\n",
      "Epoch 220/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8058 - root_mean_squared_error: 1.1651\n",
      "Epoch 221/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8206 - root_mean_squared_error: 1.1725\n",
      "Epoch 222/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7898 - root_mean_squared_error: 1.1570\n",
      "Epoch 223/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7860 - root_mean_squared_error: 1.1551\n",
      "Epoch 224/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8361 - root_mean_squared_error: 1.1803\n",
      "Epoch 225/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7907 - root_mean_squared_error: 1.1575\n",
      "Epoch 226/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8044 - root_mean_squared_error: 1.1644\n",
      "Epoch 227/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8045 - root_mean_squared_error: 1.1644\n",
      "Epoch 228/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7718 - root_mean_squared_error: 1.1479\n",
      "Epoch 229/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8643 - root_mean_squared_error: 1.1946\n",
      "Epoch 230/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.9526 - root_mean_squared_error: 1.2374\n",
      "Epoch 231/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7930 - root_mean_squared_error: 1.1588\n",
      "Epoch 232/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8315 - root_mean_squared_error: 1.1783\n",
      "Epoch 233/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7837 - root_mean_squared_error: 1.1542\n",
      "Epoch 234/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7913 - root_mean_squared_error: 1.1581\n",
      "Epoch 235/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7848 - root_mean_squared_error: 1.1547\n",
      "Epoch 236/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7728 - root_mean_squared_error: 1.1486\n",
      "Epoch 237/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7987 - root_mean_squared_error: 1.1619\n",
      "Epoch 238/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7663 - root_mean_squared_error: 1.1453\n",
      "Epoch 239/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8055 - root_mean_squared_error: 1.1653\n",
      "Epoch 240/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7586 - root_mean_squared_error: 1.1412\n",
      "Epoch 241/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7600 - root_mean_squared_error: 1.1421\n",
      "Epoch 242/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7831 - root_mean_squared_error: 1.1539\n",
      "Epoch 243/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8676 - root_mean_squared_error: 1.1963\n",
      "Epoch 244/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7837 - root_mean_squared_error: 1.1544\n",
      "Epoch 245/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7535 - root_mean_squared_error: 1.1389\n",
      "Epoch 246/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7596 - root_mean_squared_error: 1.1420\n",
      "Epoch 247/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8206 - root_mean_squared_error: 1.1732\n",
      "Epoch 248/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8529 - root_mean_squared_error: 1.1893\n",
      "Epoch 249/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.8788 - root_mean_squared_error: 1.2022\n",
      "Epoch 250/250\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.7909 - root_mean_squared_error: 1.1581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3305828043669252"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then fine tune\n",
    "skn = 396\n",
    "df_station = df_nonfilled[df_nonfilled['skn'] == skn]\n",
    "X_station = np.array(df_station[columns])\n",
    "Y_station = np.array(df_station['data_in'])\n",
    "\n",
    "Xtrain_station, Xtest_station, Ytrain_station, Ytest_station = train_test_split(X_station, Y_station, shuffle=False)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "Xtrain_station = scaler.fit_transform(Xtrain_station)\n",
    "Xtest_station = scaler.transform(Xtest_station)\n",
    "model.fit(Xtrain_station, Ytrain_station, epochs=250, verbose=True)\n",
    "\n",
    "yhat = model.predict(Xtest_station)\n",
    "mean_squared_error(Ytest_station, yhat, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3305828043669252"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_station = model.predict(Xtest_station)\n",
    "mean_squared_error(Ytest_station, yhat_station, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4567623368823552"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(Xtest)\n",
    "mean_squared_error(Ytest, yhat, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2b3817df29b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.scatter(Ytest_station, yhat_station, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.579783, 4.579783, 4.579783, ..., 4.579783, 4.579783, 4.579783],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89, 7.29, 6.63, ..., 3.27, 0.48, 4.07])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61059609, 0.52238814, 0.75152781, ..., 0.45454545, 0.45454545,\n",
       "        0.45454545],\n",
       "       [0.37396047, 0.48982191, 0.5587547 , ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.64578349, 0.43147723, 0.83654289, ..., 0.63636364, 0.63636364,\n",
       "        0.63636364],\n",
       "       ...,\n",
       "       [0.79060934, 0.44640369, 0.88690531, ..., 0.63636364, 0.63636364,\n",
       "        0.63636364],\n",
       "       [0.72929127, 0.41383854, 0.75043221, ..., 0.72727273, 0.72727273,\n",
       "        0.72727273],\n",
       "       [0.43997423, 0.46675568, 0.65292404, ..., 0.27272727, 0.27272727,\n",
       "        0.27272727]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mdf_filtered\u001b[49m[df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m i]\n\u001b[1;32m      3\u001b[0m df_test \u001b[38;5;241m=\u001b[39m df_filtered[df_filtered[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m i]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# skn = 396\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "df_train = df_filtered[df_filtered['fold'] != i]\n",
    "df_test = df_filtered[df_filtered['fold'] == i]\n",
    "\n",
    "# skn = 396\n",
    "skn = 54\n",
    "columns = C_SINGLE\n",
    "EPSILON = 1e-6\n",
    "\n",
    "Xtrain, Xtest = np.array(df_train[columns]), np.array(df_test[columns])\n",
    "Ytrain, Ytest = np.array(df_train['data_in']), np.array(df_test['data_in'])\n",
    "# Ytrain, Ytest = np.log(Ytrain + EPSILON), np.log(Ytest + EPSILON)\n",
    "\n",
    "Xtrain_station = np.array(df_train[df_train['skn'] == skn][columns])\n",
    "Ytrain_station = np.array(df_train[df_train['skn'] == skn]['data_in'])\n",
    "# Ytrain_station = np.log(Ytrain_station + EPSILON)\n",
    "\n",
    "Xtest_station = np.array(df_test[df_test['skn'] == skn][columns])\n",
    "Ytest_station = np.array(df_test[df_test['skn'] == skn]['data_in'])\n",
    "# Ytest_station = np.log(Ytest_station + EPSILON)\n",
    "\n",
    "\n",
    "# validation set\n",
    "Xtrain, Xvalid, Ytrain, Yvalid = train_test_split(Xtrain, Ytrain, test_size=0.1)\n",
    "Xtrain_station, Xvalid_station, Ytrain_station, Yvalid_station = train_test_split(Xtrain_station, Ytrain_station, test_size=0.1)\n",
    "\n",
    "# scale data\n",
    "scaler = MinMaxScaler()\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "Xvalid = scaler.transform(Xvalid)\n",
    "Xtest = scaler.transform(Xtest)\n",
    "\n",
    "Xtrain_station = scaler.transform(Xtrain_station)\n",
    "Xvalid_station = scaler.transform(Xvalid_station)\n",
    "Xtest_station = scaler.transform(Xtest_station)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "filepath = \"fold_0_epoch_{epoch:d}.hdf5\"\n",
    "saver = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='min', period=500)\n",
    "#\n",
    "model_nn = define_model(\n",
    "    input_dim=len(columns), \n",
    "    lr=0.0001,\n",
    "    activation='elu',\n",
    "    n_units=216,\n",
    "    n_layers=0,\n",
    "    dropout=0.5\n",
    ")\n",
    "history_general = model_nn.fit(Xtrain, Ytrain, epochs=2000, verbose=True, callbacks=[callback, saver], validation_data=(Xvalid, Yvalid))\n",
    "\n",
    "# intermediate performance\n",
    "# yhat_all = model_nn.predict(Xtest)\n",
    "# mean_squared_error(Ytest, yhat_all, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp",
   "language": "python",
   "name": "tfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
