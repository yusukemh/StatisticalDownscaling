{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 00:08:41.024912: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/tools/nmap/7.80/lib\n"
     ]
    }
   ],
   "source": [
    "# set the environment variable for warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# others\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "from copy import deepcopy\n",
    "import sherpa\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "import time\n",
    "from scipy.stats import gamma, norm, beta\n",
    "\n",
    "# Variables from config file\n",
    "sys.path.append('/home/yusukemh/github/yusukemh/StatisticalDownscaling/codes/')\n",
    "from config import BASE_DIR, FILE_NAMES, LABELS, ATTRIBUTES, BEST_MODEL_COLUMNS, ISLAND_RANGES, C_SINGLE, C_INT50, C_INT100, C_GRID, C_COMMON\n",
    "\n",
    "# util\n",
    "from util import cross_val_predict_for_nn, sample_station, estimate_epochs, define_model, define_hetero_model_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_air2m = xr.open_dataset(f\"{BASE_DIR}/air.2m.mon.mean.regridded.nc\")\n",
    "ds_air1000_500 = xr.open_dataset(f\"{BASE_DIR}/air.1000-500.mon.mean.nc\")\n",
    "ds_hgt500 = xr.open_dataset(f\"{BASE_DIR}/hgt500.mon.mean.nc\")\n",
    "ds_hgt1000 = xr.open_dataset(f\"{BASE_DIR}/hgt1000.mon.mean.nc\")\n",
    "ds_omega500 = xr.open_dataset(f\"{BASE_DIR}/omega500.mon.mean.nc\")\n",
    "ds_pottemp_1000_500 = xr.open_dataset(f\"{BASE_DIR}/pottmp.1000-500.mon.mean.nc\")\n",
    "ds_pottemp_1000_850 = xr.open_dataset(f\"{BASE_DIR}/pottmp.1000-850.mon.mean.nc\")\n",
    "ds_pwtr = xr.open_dataset(f\"{BASE_DIR}/pwtr.mon.mean.nc\")\n",
    "ds_u700 = xr.open_dataset(f\"{BASE_DIR}/shum_x_uwnd.700.mon.mean.nc\")\n",
    "ds_u925 = xr.open_dataset(f\"{BASE_DIR}/shum_x_uwnd.925.mon.mean.nc\")\n",
    "ds_v700 = xr.open_dataset(f\"{BASE_DIR}/shum_x_vwnd.700.mon.mean.nc\")\n",
    "ds_v950 = xr.open_dataset(f\"{BASE_DIR}/shum_x_vwnd.925.mon.mean.nc\")\n",
    "ds_shum700 = xr.open_dataset(f\"{BASE_DIR}/shum700.mon.mean.nc\")\n",
    "ds_shum925 = xr.open_dataset(f\"{BASE_DIR}/shum925.mon.mean.nc\")\n",
    "ds_skt = xr.open_dataset(f\"{BASE_DIR}/skt.mon.mean.regridded.nc\")\n",
    "ds_slp = xr.open_dataset(f\"{BASE_DIR}/slp.mon.mean.nc\")\n",
    "\n",
    "# ait temperature difference\n",
    "datasets = [ # list of tuples. (dataset object, attribute string in ds)\n",
    "    (ds_air2m, \"air\"), # surface air temperature 2m\n",
    "    (ds_air1000_500, \"air\"), # air temperature difference\n",
    "    (ds_hgt500, \"hgt\"), # geopotential height (500hPa)\n",
    "    (ds_hgt1000, \"hgt\"), # geopotential height (1000hPa)\n",
    "    (ds_omega500, \"omega\"), # omega\n",
    "    (ds_pottemp_1000_500, \"pottmp\"), # potential temperature difference 1000-500\n",
    "    (ds_pottemp_1000_850, \"pottmp\"), # potential temperature fifference 1000-850\n",
    "    (ds_pwtr, \"pr_wtr\"), # precipitable water\n",
    "    (ds_u700, \"shum\"), # zonal moisture (u) transport\n",
    "    (ds_u925, \"shum\"), # zonal moisture (u) transport\n",
    "    (ds_v700, \"shum\"), # meridional moisture (v) transport\n",
    "    (ds_v950, \"shum\"), # meridional moisture (v) transport\n",
    "    (ds_shum700, \"shum\"), # specific humidity: 700 hPa \n",
    "    (ds_shum925, \"shum\"), # specific humidity: 925 hPa\n",
    "    (ds_skt, \"skt\"), # skin temperature\n",
    "    (ds_slp, \"slp\") # sea level pressure\n",
    "]\n",
    "# combine all the cdf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:  (lat: 73, level: 1, lon: 144, time: 840)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n",
       "  * level    (level) float32 700.0\n",
       "  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n",
       "  * time     (time) datetime64[ns] 1948-01-01 1948-02-01 ... 2017-12-01\n",
       "Data variables:\n",
       "    shum     (time, level, lat, lon) float32 ...\n",
       "Attributes:\n",
       "    description:    Data is from NMC initialized reanalysis\\n(4x/day).  It co...\n",
       "    platform:       Model\n",
       "    Conventions:    COARDS\n",
       "    NCO:            4.2.6\n",
       "    history:        Sun Aug 26 20:22:35 2018: ncks -O -d level,700.000000 -d ...\n",
       "    title:          monthly mean shum from the NCEP Reanalysis\n",
       "    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n",
       "    dataset_title:  NCEP-NCAR Reanalysis 1</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-b4da56dc-0b96-4388-a1d1-ddc57e1c11b6' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-b4da56dc-0b96-4388-a1d1-ddc57e1c11b6' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>lat</span>: 73</li><li><span class='xr-has-index'>level</span>: 1</li><li><span class='xr-has-index'>lon</span>: 144</li><li><span class='xr-has-index'>time</span>: 840</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-bfad2530-3a33-41da-9726-cdb7b6bbb592' class='xr-section-summary-in' type='checkbox'  checked><label for='section-bfad2530-3a33-41da-9726-cdb7b6bbb592' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>90.0 87.5 85.0 ... -87.5 -90.0</div><input id='attrs-cb30f434-0378-482f-aa42-1c317ca163bf' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-cb30f434-0378-482f-aa42-1c317ca163bf' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-d21d5538-519a-475a-9927-247c939c2c73' class='xr-var-data-in' type='checkbox'><label for='data-d21d5538-519a-475a-9927-247c939c2c73' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_north</dd><dt><span>long_name :</span></dt><dd>Latitude</dd><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>axis :</span></dt><dd>Y</dd><dt><span>actual_range :</span></dt><dd>[ 90. -90.]</dd></dl></div><div class='xr-var-data'><pre>array([ 90. ,  87.5,  85. ,  82.5,  80. ,  77.5,  75. ,  72.5,  70. ,  67.5,\n",
       "        65. ,  62.5,  60. ,  57.5,  55. ,  52.5,  50. ,  47.5,  45. ,  42.5,\n",
       "        40. ,  37.5,  35. ,  32.5,  30. ,  27.5,  25. ,  22.5,  20. ,  17.5,\n",
       "        15. ,  12.5,  10. ,   7.5,   5. ,   2.5,   0. ,  -2.5,  -5. ,  -7.5,\n",
       "       -10. , -12.5, -15. , -17.5, -20. , -22.5, -25. , -27.5, -30. , -32.5,\n",
       "       -35. , -37.5, -40. , -42.5, -45. , -47.5, -50. , -52.5, -55. , -57.5,\n",
       "       -60. , -62.5, -65. , -67.5, -70. , -72.5, -75. , -77.5, -80. , -82.5,\n",
       "       -85. , -87.5, -90. ], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>level</span></div><div class='xr-var-dims'>(level)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>700.0</div><input id='attrs-b5d2b117-1ea8-47ff-acf1-43df46da0f4e' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-b5d2b117-1ea8-47ff-acf1-43df46da0f4e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-8889dbf0-8ca7-4a94-94f9-a1da24293cc2' class='xr-var-data-in' type='checkbox'><label for='data-8889dbf0-8ca7-4a94-94f9-a1da24293cc2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>millibar</dd><dt><span>long_name :</span></dt><dd>Level</dd><dt><span>positive :</span></dt><dd>down</dd><dt><span>GRIB_id :</span></dt><dd>100</dd><dt><span>GRIB_name :</span></dt><dd>hPa</dd><dt><span>axis :</span></dt><dd>Z</dd><dt><span>actual_range :</span></dt><dd>[700. 700.]</dd></dl></div><div class='xr-var-data'><pre>array([700.], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>0.0 2.5 5.0 ... 352.5 355.0 357.5</div><input id='attrs-eceef105-7970-4fda-b722-699781b2f032' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-eceef105-7970-4fda-b722-699781b2f032' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-09f0bb34-1be8-49c4-ac32-55d5347b3d6f' class='xr-var-data-in' type='checkbox'><label for='data-09f0bb34-1be8-49c4-ac32-55d5347b3d6f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>degrees_east</dd><dt><span>long_name :</span></dt><dd>Longitude</dd><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>axis :</span></dt><dd>X</dd><dt><span>actual_range :</span></dt><dd>[  0.  357.5]</dd></dl></div><div class='xr-var-data'><pre>array([  0. ,   2.5,   5. ,   7.5,  10. ,  12.5,  15. ,  17.5,  20. ,  22.5,\n",
       "        25. ,  27.5,  30. ,  32.5,  35. ,  37.5,  40. ,  42.5,  45. ,  47.5,\n",
       "        50. ,  52.5,  55. ,  57.5,  60. ,  62.5,  65. ,  67.5,  70. ,  72.5,\n",
       "        75. ,  77.5,  80. ,  82.5,  85. ,  87.5,  90. ,  92.5,  95. ,  97.5,\n",
       "       100. , 102.5, 105. , 107.5, 110. , 112.5, 115. , 117.5, 120. , 122.5,\n",
       "       125. , 127.5, 130. , 132.5, 135. , 137.5, 140. , 142.5, 145. , 147.5,\n",
       "       150. , 152.5, 155. , 157.5, 160. , 162.5, 165. , 167.5, 170. , 172.5,\n",
       "       175. , 177.5, 180. , 182.5, 185. , 187.5, 190. , 192.5, 195. , 197.5,\n",
       "       200. , 202.5, 205. , 207.5, 210. , 212.5, 215. , 217.5, 220. , 222.5,\n",
       "       225. , 227.5, 230. , 232.5, 235. , 237.5, 240. , 242.5, 245. , 247.5,\n",
       "       250. , 252.5, 255. , 257.5, 260. , 262.5, 265. , 267.5, 270. , 272.5,\n",
       "       275. , 277.5, 280. , 282.5, 285. , 287.5, 290. , 292.5, 295. , 297.5,\n",
       "       300. , 302.5, 305. , 307.5, 310. , 312.5, 315. , 317.5, 320. , 322.5,\n",
       "       325. , 327.5, 330. , 332.5, 335. , 337.5, 340. , 342.5, 345. , 347.5,\n",
       "       350. , 352.5, 355. , 357.5], dtype=float32)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>1948-01-01 ... 2017-12-01</div><input id='attrs-c6fae67c-febb-4f20-96bc-06638d273c3a' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c6fae67c-febb-4f20-96bc-06638d273c3a' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1b3f3b6e-ed74-4ec5-b775-8afc436149f2' class='xr-var-data-in' type='checkbox'><label for='data-1b3f3b6e-ed74-4ec5-b775-8afc436149f2' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Time</dd><dt><span>delta_t :</span></dt><dd>0000-01-00 00:00:00</dd><dt><span>avg_period :</span></dt><dd>0000-01-00 00:00:00</dd><dt><span>prev_avg_period :</span></dt><dd>0000-00-01 00:00:00</dd><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>axis :</span></dt><dd>T</dd><dt><span>actual_range :</span></dt><dd>[1297320. 1910208.]</dd></dl></div><div class='xr-var-data'><pre>array([&#x27;1948-01-01T00:00:00.000000000&#x27;, &#x27;1948-02-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;1948-03-01T00:00:00.000000000&#x27;, ..., &#x27;2017-10-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-11-01T00:00:00.000000000&#x27;, &#x27;2017-12-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-b414eef0-ebd9-44de-bb64-3e7ecc435eba' class='xr-section-summary-in' type='checkbox'  checked><label for='section-b414eef0-ebd9-44de-bb64-3e7ecc435eba' class='xr-section-summary' >Data variables: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>shum</span></div><div class='xr-var-dims'>(time, level, lat, lon)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-0d7daaf5-4498-4fc8-bb3d-4df20e412678' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-0d7daaf5-4498-4fc8-bb3d-4df20e412678' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4047ff6a-a9b4-45f9-8397-641dd4b5f73c' class='xr-var-data-in' type='checkbox'><label for='data-4047ff6a-a9b4-45f9-8397-641dd4b5f73c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>Monthly Mean of Specific Humidity</dd><dt><span>units :</span></dt><dd>grams/kg</dd><dt><span>precision :</span></dt><dd>3</dd><dt><span>var_desc :</span></dt><dd>Specific Humidity</dd><dt><span>level_desc :</span></dt><dd>Multiple levels</dd><dt><span>statistic :</span></dt><dd>Mean</dd><dt><span>parent_stat :</span></dt><dd>Other</dd><dt><span>valid_range :</span></dt><dd>[-9.999999e-02  1.004300e+02]</dd><dt><span>dataset :</span></dt><dd>NCEP Reanalysis Derived Products</dd><dt><span>actual_range :</span></dt><dd>[7.9994202e-03 1.0523001e+01]</dd></dl></div><div class='xr-var-data'><pre>[8830080 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-20c1056a-9e5e-4cec-824b-55c529a44362' class='xr-section-summary-in' type='checkbox'  checked><label for='section-20c1056a-9e5e-4cec-824b-55c529a44362' class='xr-section-summary' >Attributes: <span>(8)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>description :</span></dt><dd>Data is from NMC initialized reanalysis\n",
       "(4x/day).  It consists of most variables interpolated to\n",
       "pressure surfaces from model (sigma) surfaces.</dd><dt><span>platform :</span></dt><dd>Model</dd><dt><span>Conventions :</span></dt><dd>COARDS</dd><dt><span>NCO :</span></dt><dd>4.2.6</dd><dt><span>history :</span></dt><dd>Sun Aug 26 20:22:35 2018: ncks -O -d level,700.000000 -d lat,-90.000000,90.000000 -d lon,0.000000,357.500000 -d time,0,839 /Datasets/ncep.reanalysis.derived/pressure/shum.mon.mean.nc /Public/www/X98.151.202.176.237.20.22.34.nc\n",
       "Mon Jul  5 22:28:55 1999: ncrcat shum.mon.mean.nc /Datasets/ncep.reanalysis.derived/pressure/shum.mon.mean.nc /dm/dmwork/nmc.rean.ingest/combinedMMs/shum.mon.mean.nc\n",
       "/home/hoop/crdc/cpreanjuke2farm/cpreanjuke2farm Tue Oct 17 20:07:08 1995 from shum.85.nc\n",
       "created 95/02/06 by Hoop (netCDF2.3)\n",
       "Converted to chunked, deflated non-packed NetCDF4 2014/09</dd><dt><span>title :</span></dt><dd>monthly mean shum from the NCEP Reanalysis</dd><dt><span>References :</span></dt><dd>http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reanalysis.derived.html</dd><dt><span>dataset_title :</span></dt><dd>NCEP-NCAR Reanalysis 1</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 73, level: 1, lon: 144, time: 840)\n",
       "Coordinates:\n",
       "  * lat      (lat) float32 90.0 87.5 85.0 82.5 80.0 ... -82.5 -85.0 -87.5 -90.0\n",
       "  * level    (level) float32 700.0\n",
       "  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n",
       "  * time     (time) datetime64[ns] 1948-01-01 1948-02-01 ... 2017-12-01\n",
       "Data variables:\n",
       "    shum     (time, level, lat, lon) float32 ...\n",
       "Attributes:\n",
       "    description:    Data is from NMC initialized reanalysis\\n(4x/day).  It co...\n",
       "    platform:       Model\n",
       "    Conventions:    COARDS\n",
       "    NCO:            4.2.6\n",
       "    history:        Sun Aug 26 20:22:35 2018: ncks -O -d level,700.000000 -d ...\n",
       "    title:          monthly mean shum from the NCEP Reanalysis\n",
       "    References:     http://www.esrl.noaa.gov/psd/data/gridded/data.ncep.reana...\n",
       "    dataset_title:  NCEP-NCAR Reanalysis 1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[12][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations = pd.read_csv(f\"{BASE_DIR}/SKNlocations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18.91367961, 22.23135314)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_locations['Lat_DD'].min(), df_locations['Lat_DD'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air2m_0 air1000_500_0 hgt500_0 hgt1000_0 omega500_0 pottemp1000-500_0 pottemp1000-850_0 pr_wtr_0 shum-uwnd-700_0 shum-uwnd-925_0 shum-vwnd-700_0 shum-vwnd-950_0 shum700_0 shum925_0 skt_0 slp_0 air2m_1 air1000_500_1 hgt500_1 hgt1000_1 omega500_1 pottemp1000-500_1 pottemp1000-850_1 pr_wtr_1 shum-uwnd-700_1 shum-uwnd-925_1 shum-vwnd-700_1 shum-vwnd-950_1 shum700_1 shum925_1 skt_1 slp_1 air2m_2 air1000_500_2 hgt500_2 hgt1000_2 omega500_2 pottemp1000-500_2 pottemp1000-850_2 pr_wtr_2 shum-uwnd-700_2 shum-uwnd-925_2 shum-vwnd-700_2 shum-vwnd-950_2 shum700_2 shum925_2 skt_2 slp_2 air2m_3 air1000_500_3 hgt500_3 hgt1000_3 omega500_3 pottemp1000-500_3 pottemp1000-850_3 pr_wtr_3 shum-uwnd-700_3 shum-uwnd-925_3 shum-vwnd-700_3 shum-vwnd-950_3 shum700_3 shum925_3 skt_3 slp_3 air2m_4 air1000_500_4 hgt500_4 hgt1000_4 omega500_4 pottemp1000-500_4 pottemp1000-850_4 pr_wtr_4 shum-uwnd-700_4 shum-uwnd-925_4 shum-vwnd-700_4 shum-vwnd-950_4 shum700_4 shum925_4 skt_4 slp_4 air2m_5 air1000_500_5 hgt500_5 hgt1000_5 omega500_5 pottemp1000-500_5 pottemp1000-850_5 pr_wtr_5 shum-uwnd-700_5 shum-uwnd-925_5 shum-vwnd-700_5 shum-vwnd-950_5 shum700_5 shum925_5 skt_5 slp_5 data_in lat lon elevation season_wet season_dry "
     ]
    }
   ],
   "source": [
    "reanalysis_data = [\n",
    "    'air2m', 'air1000_500', 'hgt500', 'hgt1000', 'omega500',\n",
    "    'pottemp1000-500', 'pottemp1000-850', 'pr_wtr', 'shum-uwnd-700',\n",
    "    'shum-uwnd-925', 'shum-vwnd-700', 'shum-vwnd-950', 'shum700', 'shum925', \n",
    "    'skt', 'slp'\n",
    "]\n",
    "\n",
    "columns = []\n",
    "for i in range(6):\n",
    "    for item in reanalysis_data:\n",
    "        columns.append(f\"{item}_{i}\")\n",
    "\n",
    "columns.extend(['data_in', 'lat', 'lon', 'elevation', 'season_wet', 'season_dry'])\n",
    "for item in columns:\n",
    "    print(item, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "df_train = pd.read_csv(f\"{BASE_DIR}/train.csv\", usecols=columns + ['year', 'month', 'skn', 'data_in'])\n",
    "df_valid = pd.read_csv(f\"{BASE_DIR}/valid.csv\", usecols=columns + ['year', 'month', 'skn', 'data_in'])\n",
    "df_test = pd.read_csv(f\"{BASE_DIR}/test.csv\", usecols=columns + ['year', 'month', 'skn', 'data_in'])\n",
    "df_combined = pd.concat([df_train, df_valid, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def process(i):\n",
    "    return i * i\n",
    "    \n",
    "results = Parallel(n_jobs=2)(delayed(process)(i) for i in range(10))\n",
    "print(results)  # prints [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 2, 2, 0, 2, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "n_cpu = cpu_count()\n",
    "def return_random_number(_):\n",
    "    return np.random.randint(3)\n",
    "with Pool(n_cpu) as p:\n",
    "    result = p.map(return_random_number, [_ for _ in range(n_cpu)])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'hello.<locals>.loop'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         result \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mmap(loop, [_ \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_cpu)])\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mhello\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mhello\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     def loop(_):\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#         print(temp)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(n_cpu) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m----> 9\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_cpu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/sadow_lts/personal/yusukemh/Anaconda3/envs/tfp/lib/python3.10/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sadow_lts/personal/yusukemh/Anaconda3/envs/tfp/lib/python3.10/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/sadow_lts/personal/yusukemh/Anaconda3/envs/tfp/lib/python3.10/multiprocessing/pool.py:537\u001b[0m, in \u001b[0;36mPool._handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     \u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     job, idx \u001b[38;5;241m=\u001b[39m task[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/sadow_lts/personal/yusukemh/Anaconda3/envs/tfp/lib/python3.10/multiprocessing/connection.py:211\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_writable()\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_bytes(\u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/sadow_lts/personal/yusukemh/Anaconda3/envs/tfp/lib/python3.10/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'hello.<locals>.loop'"
     ]
    }
   ],
   "source": [
    "def hello():\n",
    "    temp = 19\n",
    "    n_cpu = cpu_count()\n",
    "    def loop(_):\n",
    "        return 19\n",
    "#     def loop(_):\n",
    "#         print(temp)\n",
    "    with Pool(n_cpu) as p:\n",
    "        result = p.map(loop, [_ for _ in range(n_cpu)])\n",
    "        print(result)\n",
    "hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3],\n",
       " [1, 2, 3]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1,2,3] for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def sqrt_func(i, j):\n",
    "    return i + j\n",
    "result = Parallel(n_jobs=-1)(delayed(sqrt_func)(i, j) for i in range(5) for j in range(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 2, 2, 3, 3, 4, 4, 5]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def func(X, Y):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    Y = scaler.transform(Y)\n",
    "    return X, Y\n",
    "    \n",
    "X = np.random.random((10,10))\n",
    "Y = np.random.random((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77278497, 0.3523481 , 0.44008981, 0.44132626, 0.74630071,\n",
       "        0.26041846, 0.6445427 , 0.37371003, 0.60245987, 0.76818882],\n",
       "       [0.22351023, 0.56613931, 0.97605876, 0.41191462, 0.60281716,\n",
       "        0.46592501, 0.80463901, 0.20344072, 0.43559862, 0.24372955],\n",
       "       [0.8808992 , 0.2514928 , 0.27569716, 0.2712373 , 0.77735979,\n",
       "        0.8186965 , 0.59878394, 0.9547254 , 0.93762773, 0.76537389],\n",
       "       [0.905788  , 0.72661338, 0.94508593, 0.79022218, 0.58737696,\n",
       "        0.35757129, 0.7151338 , 0.2031919 , 0.18484327, 0.54981129],\n",
       "       [0.28793288, 0.03955429, 0.77359109, 0.03490754, 0.6811471 ,\n",
       "        0.06922893, 0.6925942 , 0.05142748, 0.25145844, 0.85500327],\n",
       "       [0.60790958, 0.35081524, 0.22201916, 0.32241246, 0.82647519,\n",
       "        0.39572965, 0.42907647, 0.16655156, 0.33024554, 0.36269539],\n",
       "       [0.53498888, 0.86188524, 0.46927766, 0.4162485 , 0.32442874,\n",
       "        0.68898393, 0.58763007, 0.30337506, 0.65304007, 0.04284047],\n",
       "       [0.03659361, 0.33176209, 0.6835159 , 0.24873069, 0.37888982,\n",
       "        0.36935902, 0.78651116, 0.39081234, 0.80173842, 0.61950685],\n",
       "       [0.86996169, 0.53555408, 0.6291334 , 0.67321849, 0.29252803,\n",
       "        0.48099147, 0.68793495, 0.25598557, 0.27663934, 0.92111367],\n",
       "       [0.40232538, 0.97131511, 0.79607436, 0.72977227, 0.87078774,\n",
       "        0.15326682, 0.61031304, 0.83302589, 0.09549151, 0.67490252]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = func(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77278497, 0.3523481 , 0.44008981, 0.44132626, 0.74630071,\n",
       "        0.26041846, 0.6445427 , 0.37371003, 0.60245987, 0.76818882],\n",
       "       [0.22351023, 0.56613931, 0.97605876, 0.41191462, 0.60281716,\n",
       "        0.46592501, 0.80463901, 0.20344072, 0.43559862, 0.24372955],\n",
       "       [0.8808992 , 0.2514928 , 0.27569716, 0.2712373 , 0.77735979,\n",
       "        0.8186965 , 0.59878394, 0.9547254 , 0.93762773, 0.76537389],\n",
       "       [0.905788  , 0.72661338, 0.94508593, 0.79022218, 0.58737696,\n",
       "        0.35757129, 0.7151338 , 0.2031919 , 0.18484327, 0.54981129],\n",
       "       [0.28793288, 0.03955429, 0.77359109, 0.03490754, 0.6811471 ,\n",
       "        0.06922893, 0.6925942 , 0.05142748, 0.25145844, 0.85500327],\n",
       "       [0.60790958, 0.35081524, 0.22201916, 0.32241246, 0.82647519,\n",
       "        0.39572965, 0.42907647, 0.16655156, 0.33024554, 0.36269539],\n",
       "       [0.53498888, 0.86188524, 0.46927766, 0.4162485 , 0.32442874,\n",
       "        0.68898393, 0.58763007, 0.30337506, 0.65304007, 0.04284047],\n",
       "       [0.03659361, 0.33176209, 0.6835159 , 0.24873069, 0.37888982,\n",
       "        0.36935902, 0.78651116, 0.39081234, 0.80173842, 0.61950685],\n",
       "       [0.86996169, 0.53555408, 0.6291334 , 0.67321849, 0.29252803,\n",
       "        0.48099147, 0.68793495, 0.25598557, 0.27663934, 0.92111367],\n",
       "       [0.40232538, 0.97131511, 0.79607436, 0.72977227, 0.87078774,\n",
       "        0.15326682, 0.61031304, 0.83302589, 0.09549151, 0.67490252]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "\thel;\n"
     ]
    }
   ],
   "source": [
    "print('s')\n",
    "print('\\thel;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# others\n",
    "from copy import deepcopy\n",
    "from xgboost import XGBRegressor\n",
    "import sherpa\n",
    "import sys\n",
    "\n",
    "# Variables from config file\n",
    "sys.path.append('/home/yusukemh/github/yusukemh/StatisticalDownscaling/codes/')\n",
    "from config import BASE_DIR, FILE_NAMES, LABELS, ATTRIBUTES, BEST_MODEL_COLUMNS, ISLAND_RANGES, C_SINGLE, C_INT50, C_INT100, C_GRID, C_COMMON\n",
    "\n",
    "# util\n",
    "from util import cross_val_predict_for_nn, estimate_epochs\n",
    "\n",
    "# define models\n",
    "def define_model(input_dim=20, lr=0.005):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=256, activation='elu')(inputs)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    outputs = Dense(units=1, kernel_initializer='normal', activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss='mse',\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def define_hetero_model_normal(input_dim=20, lr=0.0065):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=512, activation='selu', kernel_initializer='normal')(inputs)\n",
    "    x = Dense(units=512, activation='selu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=512, activation='selu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    m = Dense(units=256, activation='selu', kernel_initializer='normal')(x)\n",
    "    m = Dense(units=10, activation='selu', kernel_initializer='normal')(m)\n",
    "    m = Dense(units=1, activation='linear', kernel_initializer='normal')(m)\n",
    "    \n",
    "    s = Dense(units=256, activation='selu', kernel_initializer='normal')(x)\n",
    "    s = Dense(units=10, activation='selu', kernel_initializer='normal')(s)\n",
    "    s = Dense(units=1, activation='linear', kernel_initializer='normal', kernel_regularizer=tf.keras.regularizers.L2(l2=100))(s)\n",
    "    \n",
    "    ms = Concatenate(axis=-1)([m, s])\n",
    "    outputs = tfp.layers.DistributionLambda(\n",
    "        make_distribution_fn=lambda t: tfd.Normal(\n",
    "            loc=2.5 * t[...,0] + 0.01, scale=tf.math.softplus(0.001*t[...,1]+0.03)#this part is important\n",
    "        ),\n",
    "        convert_to_tensor_fn=lambda s: s.mean()\n",
    "    )(ms)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss=lambda y, p_y: -p_y.log_prob(y),\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def safe_nll(y, p_y):\n",
    "    epsilon=1e-5\n",
    "    return -p_y.log_prob(y + epsilon) # y = 0 yields nan\n",
    "\n",
    "def define_hetero_model_gamma(input_dim=20, lr=0.0065):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(inputs)\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    m = Dense(units=256, activation='elu', kernel_initializer='normal')(x)\n",
    "    m = Dense(units=10, activation='elu', kernel_initializer='normal')(m)\n",
    "    m = Dense(units=1, activation='linear', kernel_initializer='normal')(m)\n",
    "    \n",
    "    s = Dense(units=256, activation='elu', kernel_initializer='normal')(x)\n",
    "    s = Dense(units=10, activation='elu', kernel_initializer='normal')(s)\n",
    "    s = Dense(units=1, activation='linear', kernel_initializer='normal')(s)\n",
    "    \n",
    "    ms = Concatenate(axis=-1)([m, s])\n",
    "    outputs = tfp.layers.DistributionLambda(\n",
    "        make_distribution_fn=lambda t: tfd.Gamma(\n",
    "            concentration=tf.math.softplus(t[...,0]), rate=tf.math.softplus(t[...,1])\n",
    "        ),\n",
    "        convert_to_tensor_fn=lambda d: d.mean()\n",
    "    )(ms)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        #loss=lambda y, p_y: -p_y.log_prob(y),\n",
    "        loss=safe_nll,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def run_single_experiment(\n",
    "    X, Y,\n",
    "    model_func, model_params,\n",
    "    n_trial, skn\n",
    "):\n",
    "    # first, run linear regression\n",
    "    linear_regression = LinearRegression()\n",
    "    y_pred = cross_val_predict(linear_regression, X, Y, n_jobs=-1)\n",
    "    rmse_lr = mean_squared_error(Y, y_pred, squared=False)\n",
    "    # estimate the # epochs\n",
    "    estimated_epochs = estimate_epochs(\n",
    "        X=X, Y=Y, model_func=model_func, model_params=model_params, n_iter=30\n",
    "    )\n",
    "    \n",
    "    rmses = []\n",
    "    for trial in range(n_trial):\n",
    "        y_pred = cross_val_predict_for_nn(\n",
    "            X=X, Y=Y, model_func=model_func, model_params=model_params, callback=None, batch_size=64,\n",
    "            epochs=int(estimated_epochs), early_stopping=False, verbose=False\n",
    "        )\n",
    "        rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "        rmses.append(rmse)\n",
    "    rmses = np.array(rmses)\n",
    "    m, s = np.mean(rmses), np.std(rmses)\n",
    "    return pd.DataFrame(\n",
    "        dict(\n",
    "            n_samples=X.shape[0],\n",
    "            estimated_epochs=estimated_epochs,\n",
    "            rmse_LR=rmse_lr,\n",
    "            rmse_NN_mean=m,\n",
    "            rmse_NN_std=s,\n",
    "            rel_imp=(rmse_lr - m)/rmse_lr\n",
    "        ),\n",
    "        index=[skn]\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    file_name = './progress.txt'\n",
    "\n",
    "    columns = C_SINGLE\n",
    "    # load nonfilled dataset\n",
    "    df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "    # sample a station: returned object is sorted.\n",
    "\n",
    "    df_n_data = df_nonfilled.groupby('skn').size().reset_index().rename(columns={0:\"n_data\"})\n",
    "    valid_skn = df_n_data[df_n_data['n_data'] > 750]['skn']\n",
    "\n",
    "    stats_regular = []\n",
    "    stats_normal = []\n",
    "    stats_gamma = []\n",
    "\n",
    "    for i, skn in enumerate(valid_skn):\n",
    "        with open(file_name, 'a') as f:\n",
    "            f.write(f'Running experiment on skn {skn}\\n')\n",
    "            f.write(f'{i}/{valid_skn.shape[0]}\\n')\n",
    "\n",
    "        df_station = df_nonfilled[df_nonfilled['skn'] == skn].sort_values(['year', 'month'])\n",
    "\n",
    "        X = np.array(df_station[columns])\n",
    "        Y = np.array(df_station['data_in'])\n",
    "\n",
    "        with open(file_name, 'a') as f:\n",
    "            f.write(f'\\tRunning regular NN\\n')\n",
    "\n",
    "        # regular NN\n",
    "        stats_regular.append(\n",
    "            run_single_experiment(\n",
    "                X, Y, model_func=define_model, model_params=dict(input_dim=len(columns), lr=0.0005),\n",
    "                n_trial=20, skn=skn\n",
    "            )\n",
    "        )\n",
    "\n",
    "        with open(file_name, 'a') as f:\n",
    "            f.write(f'\\tRunning normal NN\\n')\n",
    "\n",
    "        stats_normal.append(\n",
    "            run_single_experiment(\n",
    "                X, Y, model_func=define_hetero_model_normal, model_params=dict(input_dim=len(columns), lr=0.0005),\n",
    "                n_trial=20, skn=skn\n",
    "            )\n",
    "        )\n",
    "\n",
    "        with open(file_name, 'a') as f:\n",
    "            f.write(f'\\tRunning gamma NN\\n')\n",
    "\n",
    "        stats_gamma.append(\n",
    "            run_single_experiment(\n",
    "                X, Y, model_func=define_hetero_model_gamma, model_params=dict(input_dim=len(columns), lr=0.001),\n",
    "                n_trial=20, skn=skn\n",
    "            )\n",
    "        )\n",
    "\n",
    "    pd.concat(stats_regular).to_csv(f\"./stats_regular.csv\", index=False)\n",
    "    pd.concat(stats_normal).to_csv(f\"./stats_normal.csv\", index=False)\n",
    "    pd.concat(stats_gamma).to_csv(f\"./stats_gamma.csv\", index=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 20:20:10.892195: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/apps/software/tools/nmap/7.80/lib\n"
     ]
    }
   ],
   "source": [
    "# set the environment variable for warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# others\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "from copy import deepcopy\n",
    "import sherpa\n",
    "from xgboost import XGBRegressor\n",
    "import sys\n",
    "import time\n",
    "from scipy.stats import gamma, norm, beta\n",
    "\n",
    "# Variables from config file\n",
    "sys.path.append('/home/yusukemh/github/yusukemh/StatisticalDownscaling/codes/')\n",
    "from config import BASE_DIR, FILE_NAMES, LABELS, ATTRIBUTES, BEST_MODEL_COLUMNS, ISLAND_RANGES, C_SINGLE, C_INT50, C_INT100, C_GRID, C_COMMON\n",
    "\n",
    "# util\n",
    "from util import cross_val_predict_for_nn, sample_station, estimate_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station with skn: 396.0 was chosen out of all stations with more than 750 historical (non-filled) rainfall observations.\n",
      "There are 778 rainfall observations from this station.\n"
     ]
    }
   ],
   "source": [
    "columns = C_SINGLE\n",
    "# load nonfilled dataset\n",
    "df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "# sample a station: returned object is sorted.\n",
    "df_station = sample_station(df=df_nonfilled, threshold=750, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a NN model\n",
    "def define_model(input_dim=20, lr=0.005):\n",
    "    \n",
    "    inputs = Input(shape=(input_dim,))\n",
    "        \n",
    "#     inputs_1 = tf.keras.layers.GaussianNoise(stddev=1)(inputs)\n",
    "#     inputs_2 = tf.keras.layers.GaussianNoise(stddev=0.5)(inputs)\n",
    "#     inputs_3 = tf.keras.layers.GaussianNoise(stddev=0.2)(inputs)\n",
    "    \n",
    "    x = Dense(units=256, activation='elu')(inputs)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    \n",
    "    outputs_1 = Dense(units=1, activation='linear')(x)\n",
    "    \n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    \n",
    "    outputs_2 = Dense(units=1, activation='linear')(x)\n",
    "    \n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    \n",
    "    outputs_3 = Dense(units=1, activation='linear')(x)\n",
    "\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=256, activation='elu')(x)\n",
    "    \n",
    "    outputs = Dense(units=1, kernel_initializer='normal', activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    rates = tf.constant([1.4, 0.9, 0.3, 0.1])\n",
    "    #rates = tf.constant([1.,1.,1.,1.])\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        \n",
    "        loss_1 = mse(\n",
    "            tf.keras.layers.GaussianNoise(stddev=3)(y_true),\n",
    "            outputs_1\n",
    "        )\n",
    "        \n",
    "        loss_2 = mse(\n",
    "            tf.keras.layers.GaussianNoise(stddev=1)(y_true),\n",
    "            outputs_2\n",
    "        )\n",
    "        \n",
    "        loss_3 = mse(\n",
    "            tf.keras.layers.GaussianNoise(stddev=0.2)(y_true),\n",
    "            outputs_3\n",
    "        )\n",
    "        \n",
    "        loss = mse(y_true, y_pred)\n",
    "        # return rates[0] * loss_1 + rates[1] * loss_2 + rates[2] * loss_3 + rates[3] * loss\n",
    "\n",
    "        losses = tf.stack([loss_1, loss_2, loss_3, loss], axis=0)\n",
    "        # final_loss = tf.math.multiply(rates, [loss_1, loss_2, loss_3, loss])\n",
    "        final_loss = tf.math.multiply(rates, losses)\n",
    "        return tf.reduce_sum(final_loss, axis=-1)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss=custom_loss,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_52:0' shape=(4,) dtype=float32>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(np.arange(3 + 1, 0, -1).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a NN model\n",
    "def define_model(input_dim=20, lr=0.005, n_stacks=3):\n",
    "    \n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = tf.keras.layers.Lambda(lambda x: x)(inputs)\n",
    "     \n",
    "    intermediate_outputs = []\n",
    "    for stack in range(n_stacks):\n",
    "        x = Dense(units=256, activation='elu')(x)\n",
    "        x = Dropout(rate=0.5)(x)\n",
    "        x = Dense(units=256, activation='elu')(x)\n",
    "        _outputs = Dense(units=1, activation='linear')(x)\n",
    "        intermediate_outputs.append(_outputs)\n",
    "\n",
    "    # outputs = tf.keras.layers.Lambda(lambda x: x)(x)\n",
    "    outputs = Dense(units=1, kernel_initializer='normal', activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    rates = tf.constant(np.arange(n_stacks + 1).astype('float32'))\n",
    "    std = tf.constant(np.log(np.arange(n_stacks + 1, 0, -1).astype('float32')))\n",
    "    \n",
    "    def custom_loss(y_true, y_pred):\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        \n",
    "        mses = []\n",
    "        for i in range(n_stacks):\n",
    "            mses.append(mse(\n",
    "                tf.keras.layers.GaussianNoise(stddev=std[i])(y_true),\n",
    "                intermediate_outputs[i]\n",
    "            ))\n",
    "        mses.append(mse(y_true, y_pred))\n",
    "\n",
    "        losses = tf.stack(mses, axis=0)\n",
    "        final_loss = tf.math.multiply(rates, mses)\n",
    "        return tf.reduce_sum(final_loss, axis=-1)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss=custom_loss,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean number of epochs: 14.0\n",
      "Std: 0.000\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_station[columns])\n",
    "Y = np.array(df_station['data_in'])\n",
    "# model = define_model(input_dim=len(columns), lr=0.005)\n",
    "model_params={\"input_dim\": len(columns), \"lr\": 0.005, \"n_stacks\": 10}\n",
    "estimated_epochs = estimate_epochs(\n",
    "    X=X, Y=Y,\n",
    "    model_func=define_model,\n",
    "    model_params=model_params,\n",
    "    n_iter=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: single observation, normal NN\n",
      "RMSE with NN: 1.885\n",
      "RMSE with LR: 1.535\n"
     ]
    }
   ],
   "source": [
    "# now fix the epoch, remove early stopping, and run cross_val_predict\n",
    "yhat_nn = cross_val_predict_for_nn(# implemented in util.py\n",
    "    model_func=define_model,\n",
    "    model_params=model_params,\n",
    "    X=X, Y=Y,\n",
    "    callback=None,\n",
    "    batch_size=64,\n",
    "    epochs=int(estimated_epochs),\n",
    "    early_stopping=False,\n",
    "    verbose=False\n",
    ")\n",
    "rmse_nn = mean_squared_error(Y, yhat_nn, squared=False)\n",
    "linear_regression = LinearRegression()\n",
    "yhat_lr = cross_val_predict(linear_regression, X, Y, n_jobs=-1)\n",
    "rmse_lr = mean_squared_error(Y, yhat_lr, squared=False)\n",
    "\n",
    "print(\"Result: single observation, normal NN\")\n",
    "print(\"RMSE with NN: {:.3f}\".format(rmse_nn))\n",
    "print(\"RMSE with LR: {:.3f}\".format(rmse_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station with skn: 396.0 was chosen out of all stations with more than 750 historical (non-filled) rainfall observations.\n",
      "There are 778 rainfall observations from this station.\n"
     ]
    }
   ],
   "source": [
    "columns = C_SINGLE\n",
    "# load nonfilled dataset\n",
    "df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "# sample a station: returned object is sorted.\n",
    "df_station = sample_station(df=df_nonfilled, threshold=750, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_hetero_model_gamma(input_dim=20, lr=0.0065):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(inputs)\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=512, activation='elu', kernel_initializer='normal')(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    \n",
    "    m = Dense(units=256, activation='elu', kernel_initializer='normal')(x)\n",
    "    m = Dense(units=10, activation='elu', kernel_initializer='normal')(m)\n",
    "    m = Dense(units=1, activation='linear', kernel_initializer='normal')(m)\n",
    "    \n",
    "    s = Dense(units=256, activation='elu', kernel_initializer='normal')(x)\n",
    "    s = Dense(units=10, activation='elu', kernel_initializer='normal')(s)\n",
    "    s = Dense(units=1, activation='linear', kernel_initializer='normal')(s)\n",
    "    \n",
    "    ms = Concatenate(axis=-1)([m, s])\n",
    "    outputs = tfp.layers.DistributionLambda(\n",
    "        make_distribution_fn=lambda t: tfd.Gamma(\n",
    "            concentration=tf.math.softplus(t[...,0]), rate=tf.math.softplus(t[...,1])\n",
    "        ),\n",
    "        convert_to_tensor_fn=lambda d: d.mean()\n",
    "    )(ms)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    epsilon=1e-5 # for loss function\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss=lambda y, p_y: -p_y.log_prob(y + epsilon),\n",
    "        # loss=safe_nll,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean number of epochs: 13.2\n",
      "Std: 3.400\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_station[columns])\n",
    "Y = np.array(df_station['data_in'])\n",
    "# Y = np.clip(Y, a_min=1e-10, a_max=None)\n",
    "\n",
    "\n",
    "model_params = dict(\n",
    "    input_dim=len(columns),\n",
    "    lr=0.001\n",
    ")\n",
    "batch_size = 64\n",
    "\n",
    "estimated_epochs = estimate_epochs(\n",
    "    X=X, Y=Y,\n",
    "    model_func=define_hetero_model_gamma,\n",
    "    model_params=model_params,\n",
    "    n_iter=10,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with NN: 1.456\n"
     ]
    }
   ],
   "source": [
    "# now fix the epoch, remove early stopping, and run cross_val_predict\n",
    "epochs = int(estimated_epochs)\n",
    "n_ensamble = 10\n",
    "y_preds = []\n",
    "for _ in range(n_ensamble):\n",
    "    yhat_nn = cross_val_predict_for_nn(# implemented in util.py\n",
    "        model_func=define_hetero_model_gamma,\n",
    "        model_params=model_params,\n",
    "        X=X, Y=Y,\n",
    "        callback=None,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        early_stopping=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    y_preds.append(yhat_nn)\n",
    "    print(f\"{_+1}/{n_ensamble}\", end='\\r')\n",
    "mean_pred = np.mean(y_preds, axis=0)\n",
    "rmse_nn = mean_squared_error(Y, mean_pred, squared=False)\n",
    "print(\"RMSE with NN: {:.3f}\".format(rmse_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean number of epochs: 33.7\n",
      "Std: 11.411\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_station[columns])\n",
    "Y = np.array(df_station['data_in'])\n",
    "# Y = np.clip(Y, a_min=1e-10, a_max=None)\n",
    "\n",
    "\n",
    "model_params = dict(\n",
    "    input_dim=len(columns),\n",
    "    lr=0.001\n",
    ")\n",
    "batch_size = 64\n",
    "\n",
    "estimated_epochs = estimate_epochs(\n",
    "    X=X, Y=Y,\n",
    "    model_func=define_hetero_model_normal_rev,\n",
    "    model_params=model_params,\n",
    "    n_iter=10,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with NN: 1.474\n"
     ]
    }
   ],
   "source": [
    "# now fix the epoch, remove early stopping, and run cross_val_predict\n",
    "epochs = int(estimated_epochs)\n",
    "n_ensamble = 10\n",
    "y_preds = []\n",
    "for _ in range(n_ensamble):\n",
    "    yhat_nn = cross_val_predict_for_nn(# implemented in util.py\n",
    "        model_func=define_hetero_model_normal_rev,\n",
    "        model_params=model_params,\n",
    "        X=X, Y=Y,\n",
    "        callback=None,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        early_stopping=False,\n",
    "        verbose=False\n",
    "    )\n",
    "    y_preds.append(yhat_nn)\n",
    "    print(f\"{_+1}/{n_ensamble}\", end='\\r')\n",
    "mean_pred = np.mean(y_preds, axis=0)\n",
    "rmse_nn = mean_squared_error(Y, mean_pred, squared=False)\n",
    "print(\"RMSE with NN: {:.3f}\".format(rmse_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model__(\n",
    "    input_dim=20, \n",
    "    lr=0.005, \n",
    "    activation='relu',\n",
    "    n_units=256,\n",
    "    n_layers=4,\n",
    "    dropout=0.5\n",
    "):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=n_units, activation=activation)(inputs)\n",
    "    \n",
    "    for i in range(n_layers - 1):\n",
    "        if dropout:\n",
    "            x = Dropout(rate=dropout)(x)\n",
    "        x = Dense(units=n_units, activation=activation)(x)\n",
    "    outputs = Dense(units=1, kernel_initializer='normal', activation='relu')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "        loss='mse',\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station with skn: 396.0 was chosen out of all stations with more than 750 historical (non-filled) rainfall observations.\n",
      "There are 778 rainfall observations from this station.\n"
     ]
    }
   ],
   "source": [
    "columns = C_SINGLE\n",
    "# load nonfilled dataset\n",
    "df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "# sample a station: returned object is sorted.\n",
    "df_station = sample_station(df=df_nonfilled, threshold=750, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean number of epochs: 12.5\n",
      "Std: 2.655\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "model_params = {\n",
    "    \"input_dim\"         : len(columns),\n",
    "    \"activation\"        : 'relu',\n",
    "    \"dropout\"           : 0.4578657205946084,\n",
    "    \"lr\"                : 0.0043961731420066,\n",
    "    \"n_layers\"          : 2,\n",
    "    \"n_units\"           : 905,\n",
    "}\n",
    "batch_size = 116\n",
    "#############################################\n",
    "\n",
    "X = np.array(df_station[columns])\n",
    "Y = np.array(df_station['data_in'])\n",
    "\n",
    "estimated_epochs = estimate_epochs(\n",
    "    X=X, Y=Y,\n",
    "    model_func=define_model,\n",
    "    model_params=model_params,\n",
    "    batch_size=batch_size,\n",
    "    n_iter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: single observation, normal NN\n",
      "RMSE with NN: 1.446\n",
      "RMSE with LR: 1.535\n"
     ]
    }
   ],
   "source": [
    "# now fix the epoch, remove early stopping, and run cross_val_predict\n",
    "yhat_nn = cross_val_predict_for_nn(# implemented in util.py\n",
    "    model_func=define_model,\n",
    "    model_params=model_params,\n",
    "    X=X, Y=Y,\n",
    "    callback=None,\n",
    "    batch_size=batch_size,\n",
    "    epochs=int(estimated_epochs),\n",
    "    early_stopping=False,\n",
    "    verbose=False\n",
    ")\n",
    "rmse_nn = mean_squared_error(Y, yhat_nn, squared=False)\n",
    "linear_regression = LinearRegression()\n",
    "yhat_lr = cross_val_predict(linear_regression, X, Y, n_jobs=-1)\n",
    "rmse_lr = mean_squared_error(Y, yhat_lr, squared=False)\n",
    "\n",
    "print(\"Result: single observation, normal NN\")\n",
    "print(\"RMSE with NN: {:.3f}\".format(rmse_nn))\n",
    "print(\"RMSE with LR: {:.3f}\".format(rmse_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_(\n",
    "    input_dim=20, \n",
    "    lr=0.005, \n",
    "    activation='relu',\n",
    "    n_units=256,\n",
    "    n_layers=4,\n",
    "    dropout=0.5\n",
    "):\n",
    "#     inputs = Input(shape=(input_dim,))\n",
    "#     x = Dense(units=n_units, activation=activation)(inputs)\n",
    "    \n",
    "#     for i in range(n_layers - 1):\n",
    "#         if dropout:\n",
    "#             x = Dropout(rate=dropout)(x)\n",
    "#         x = Dense(units=n_units, activation=activation)(x)\n",
    "#     outputs = Dense(units=1, kernel_initializer=tf.keras.initializers.HeNormal, activation='linear')(x)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "#     model.compile(\n",
    "#         optimizer=tf.optimizers.Adam(learning_rate=lr),\n",
    "#         loss='mse',\n",
    "#         metrics=[RootMeanSquaredError()]\n",
    "#     )\n",
    "\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(units=1024, activation='relu')(inputs)\n",
    "    x = Dense(units=1024, activation='relu')(x)\n",
    "    x = Dense(units=1024, activation='relu')(x)\n",
    "    \n",
    "    outputs = Dense(units=1, activation='softplus')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mse',\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station with skn: 396.0 was chosen out of all stations with more than 750 historical (non-filled) rainfall observations.\n",
      "There are 778 rainfall observations from this station.\n"
     ]
    }
   ],
   "source": [
    "columns = C_SINGLE\n",
    "# load nonfilled dataset\n",
    "df_nonfilled = pd.read_csv(f\"{BASE_DIR}/nonfilled_dataset.csv\", usecols=C_SINGLE + C_COMMON)\n",
    "# sample a station: returned object is sorted.\n",
    "df_station = sample_station(df=df_nonfilled, threshold=750, seed=42)\n",
    "\n",
    "model = define_model_(input_dim = len(columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean number of epochs: 8.9\n",
      "Std: 2.343\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df_station[columns])\n",
    "Y = np.array(df_station['data_in'])\n",
    "\n",
    "# define hyperparameters\n",
    "############################\n",
    "model_params = dict(\n",
    "    input_dim=len(columns),\n",
    "    lr=0.0005,\n",
    "    activation='elu',\n",
    "    n_units=256,\n",
    "    n_layers=2,\n",
    "    dropout=0.5\n",
    ")\n",
    "batch_size = 64\n",
    "#############################\n",
    "\n",
    "estimated_epochs = estimate_epochs(\n",
    "    X=X, Y=Y,\n",
    "    model_func=define_model_,\n",
    "    model_params=model_params,\n",
    "    batch_size=batch_size,\n",
    "    n_iter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: single observation, normal NN\n",
      "RMSE with NN: 1.518\n",
      "RMSE with LR: 1.535\n"
     ]
    }
   ],
   "source": [
    "# now fix the epoch, remove early stopping, and run cross_val_predict\n",
    "yhat_nn = cross_val_predict_for_nn(# implemented in util.py\n",
    "    model_func=define_model_,\n",
    "    model_params=model_params,\n",
    "    X=X, Y=Y,\n",
    "    callback=None,\n",
    "    batch_size=batch_size,\n",
    "    epochs=int(estimated_epochs),\n",
    "    early_stopping=False,\n",
    "    verbose=False\n",
    ")\n",
    "rmse_nn = mean_squared_error(Y, yhat_nn, squared=False)\n",
    "linear_regression = LinearRegression()\n",
    "yhat_lr = cross_val_predict(linear_regression, X, Y, n_jobs=-1)\n",
    "rmse_lr = mean_squared_error(Y, yhat_lr, squared=False)\n",
    "\n",
    "print(\"Result: single observation, normal NN\")\n",
    "print(\"RMSE with NN: {:.3f}\".format(rmse_nn))\n",
    "print(\"RMSE with LR: {:.3f}\".format(rmse_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2abf3d2a5480>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.scatter(Y, yhat_nn, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp",
   "language": "python",
   "name": "tfp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
