{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e33ac81-8da0-4273-9499-aea84fe85bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cef254e-2af1-4129-a6b0-bbdd6687d6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sherpa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/yusukemh/github/yusukemh/StatisticalDownscaling/writeup')\n",
    "from config import C_COMMON, C_GRID, C_SINGLE, FILENAME\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c96e6fba-90cc-4ec7-a54e-b5c077cddb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_inner_fold(df, n_folds=5):\n",
    "    # assign fold for each sample\n",
    "    df_len_by_month = pd.DataFrame(df.groupby(by=['year', 'month']).size()).reset_index().rename({0: \"len\"}, axis=1)\n",
    "    df_len_by_month = df_len_by_month.sort_values(['year', 'month'])\n",
    "    df_len_by_month['cumsum'] = df_len_by_month['len'].cumsum()\n",
    "    n_samples_total = df_len_by_month['cumsum'].iloc[-1]\n",
    "    n_samples_per_fold = np.ceil(n_samples_total / n_folds)\n",
    "    df_len_by_month['inner_fold'] = df_len_by_month.apply(lambda row: int(row['cumsum'] / n_samples_per_fold), axis=1)\n",
    "    df_w_fold = pd.merge(left=df, right=df_len_by_month, left_on=['year', 'month'], right_on=['year', 'month'])\n",
    "    \n",
    "    return df_w_fold\n",
    "\n",
    "def load_data(columns, filename):\n",
    "    \"\"\"\n",
    "    Loads dataset and splits into train and test.\n",
    "    It also splits training dataset into 5 folds as a column named 'inner_fold'\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filename, usecols=C_COMMON + columns).sort_values(['year', 'month'])\n",
    "    df_train = df.query('fold != 4')\n",
    "    df_test = df.query('fold == 4')\n",
    "    assert (sorted(df_train['skn'].unique()) == sorted(df_test['skn'].unique()))\n",
    "    \n",
    "    df_train = assign_inner_fold(df_train)\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f9c2a36-9551-4e45-afd9-25840c8eae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = C_SINGLE\n",
    "df_train, _ = load_data(columns, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc39d4b4-02b6-4ffe-b9f4-de9f899deb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = C_SINGLE\n",
    "# df = pd.read_csv(FILENAME, usecols=C_COMMON + columns).sort_values(['year', 'month'])\n",
    "\n",
    "# # we use the last 1/5 data as the heldout clean dataset. We do not use this fold for any use except for just reporting the result.\n",
    "# df_train_outer = df.query('fold != 4')\n",
    "# df_test_outer = df.query('fold == 4')\n",
    "# assert (sorted(df_test_outer['skn'].unique()) == sorted(df_train_outer['skn'].unique()))\n",
    "\n",
    "# # split the trainig data into 5 folds for inner cross validation\n",
    "# def assign_inner_fold(df, n_folds=5):\n",
    "#     # assign fold for each sample\n",
    "#     df_len_by_month = pd.DataFrame(df.groupby(by=['year', 'month']).size()).reset_index().rename({0: \"len\"}, axis=1)\n",
    "#     df_len_by_month = df_len_by_month.sort_values(['year', 'month'])\n",
    "#     df_len_by_month['cumsum'] = df_len_by_month['len'].cumsum()\n",
    "#     n_samples_total = df_len_by_month['cumsum'].iloc[-1]\n",
    "#     n_samples_per_fold = np.ceil(n_samples_total / n_folds)\n",
    "    \n",
    "#     df_len_by_month['inner_fold'] = df_len_by_month.apply(lambda row: int(row['cumsum'] / n_samples_per_fold), axis=1)\n",
    "    \n",
    "#     df_w_fold = pd.merge(left=df, right=df_len_by_month, left_on=['year', 'month'], right_on=['year', 'month'])\n",
    "    \n",
    "#     return df_w_fold\n",
    "\n",
    "# df_inner_split = assign_inner_fold(df_train_outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c52c61ab-7678-4ed8-beea-ec6aec33b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def define_model(\n",
    "    input_dim=20,\n",
    "    n_units=512,\n",
    "    activation='selu',#selu\n",
    "    learning_rate=0.00001,\n",
    "    loss='mse',\n",
    "    batch_size=64\n",
    "):\n",
    "    inputs = Input(shape=(input_dim))\n",
    "    # x = Dense(units=n_units, activation=activation, kernel_regularizer='l1')(inputs)\n",
    "    x = Dense(units=n_units, activation=activation)(inputs)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=n_units, activation=activation)(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=n_units, activation=activation)(x)\n",
    "    x = Dropout(rate=0.5)(x)# serves as regularization\n",
    "    outputs = Dense(units=1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    return model, batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e82b924-e2b5-43e7-a6df-b7b37f565812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self, model_func, params, columns):\n",
    "        self.model_func = model_func\n",
    "        self.params = params\n",
    "        self.columns = columns\n",
    "        pass\n",
    "    \n",
    "    def cross_val_predict(self, df, skn, verbose=0, n_folds=5):\n",
    "        assert 'inner_fold' in df.columns, 'define fold with column name \"inner_fold\"'\n",
    "        df_station = df[df['skn'] == skn]\n",
    "        \n",
    "        list_ytrue = []\n",
    "        list_ypred = []\n",
    "        for k in range(n_folds):\n",
    "            # split the dataset\n",
    "            df_train = df_station[df_station['inner_fold'] != k]\n",
    "            df_test = df_station[df_station['inner_fold'] == k]\n",
    "            \n",
    "            # convert to numpy\n",
    "            x_train, x_test = np.array(df_train[self.columns]), np.array(df_test[self.columns])\n",
    "            y_train, y_test = np.array(df_train['data_in']), np.array(df_test['data_in'])\n",
    "            \n",
    "            # scale the input and output\n",
    "            x_train, x_test = self.transform_x(x_train, x_test)\n",
    "            y_train, y_test, y_scaler = self.transform_y(y_train, y_test)\n",
    "            \n",
    "            # train the model\n",
    "            self.train(x_train, y_train, verbose=0, retrain_full=False) # to speed up computation for hyperparaemter tuning\n",
    "            \n",
    "            # make prediction and scale\n",
    "            y_pred = self.model.predict(x_test)\n",
    "            y_pred = self.inverse_transform_y(y_pred, y_scaler)\n",
    "            # scale y_test\n",
    "            y_test = self.inverse_transform_y(y_test, y_scaler)\n",
    "            \n",
    "            # keep the record\n",
    "            list_ytrue.extend(y_test)\n",
    "            list_ypred.extend(y_pred)\n",
    "        \n",
    "        # calculate the loss and return\n",
    "        return {\n",
    "            \"mse\": mean_squared_error(list_ytrue, list_ypred, squared=False),\n",
    "            \"mae\": mean_absolute_error(list_ytrue, list_ypred)\n",
    "        }\n",
    "\n",
    "    def transform_x(self, x_train, x_test):\n",
    "        scaler = MinMaxScaler()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "        return x_train, x_test\n",
    "    \n",
    "    def transform_y(self, y_train, y_test):\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        y_train = np.log(y_train + 1.)\n",
    "        y_test = np.log(y_test + 1.)\n",
    "\n",
    "        y_train = scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "        y_test = scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "        return y_train, y_test, scaler\n",
    "    \n",
    "    def inverse_transform_y(self, y, scaler):\n",
    "        y = scaler.inverse_transform(y)\n",
    "        y = np.power(np.e, y) - 1\n",
    "        return y\n",
    "    \n",
    "    def train(self, x, y, verbose=0, retrain_full=False):\n",
    "        # build the model\n",
    "        self.model, batch_size = self.model_func(**self.params)\n",
    "        \n",
    "        callbacks = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0,\n",
    "                patience=20,\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.95,\n",
    "                patience=10\n",
    "            )\n",
    "        ]\n",
    "        history = self.model.fit(\n",
    "            x, y,\n",
    "            epochs=500,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=0.2,\n",
    "            callbacks=callbacks,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        if retrain_full:\n",
    "            epochs = len(history.history['loss'])\n",
    "            # rebuild the model\n",
    "            self.model, batch_size = self.model_func(**params)\n",
    "            callbacks = [EarlyStopping(monitor='loss', min_delta=0, patience=1e3, restore_best_weights=True)]\n",
    "            history = self.model.fit(\n",
    "                x, y,\n",
    "                epochs=epochs,\n",
    "                validation_split=0,\n",
    "                callbacks=callbacks,\n",
    "                batch_size=batch_size,\n",
    "                verbose=verbose\n",
    "            )\n",
    "        return history        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "207727a9-f94b-4877-ba71-4d57c3f1d3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.0 {'mse': 5.1910487470013384, 'mae': 3.349645200220334}\n",
      "79.0 {'mse': 6.044588694398829, 'mae': 3.8787937445801806}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_86609/1451760029.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_86609/2777310586.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(self, df, skn, verbose, n_folds)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrain_full\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to speed up computation for hyperparaemter tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# make prediction and scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_86609/2777310586.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, verbose, retrain_full)\u001b[0m\n\u001b[1;32m     88\u001b[0m             )\n\u001b[1;32m     89\u001b[0m         ]\n\u001b[0;32m---> 90\u001b[0;31m         history = self.model.fit(\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         if x is not None)\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Ensure ordering of collective ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m       \u001b[0mmanager_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollective_manager_ids_from_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mmanager_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmanager_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmanager_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollective_manager_scopes_opened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36mcollective_manager_ids_from_op\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m   \u001b[0;32melif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"StatefulPartitionedCall\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLLECTIVE_MANAGER_IDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2423\u001b[0m     \u001b[0;34m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2424\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationOpType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2426\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for skn in df_train['skn'].unique():\n",
    "    model = NeuralNetwork(\n",
    "        model_func=define_model,\n",
    "        params = {\n",
    "            'input_dim': 16,\n",
    "            'n_units': 362,\n",
    "            'learning_rate': 0.000695,\n",
    "            'loss': 'mse',\n",
    "            'batch_size': 128\n",
    "        },\n",
    "        columns=columns\n",
    "    )\n",
    "    ret = model.cross_val_predict(df_train, skn)\n",
    "    print(skn, ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b019884-c745-4808-ba73-8fb7ec6893ad",
   "metadata": {},
   "source": [
    "# get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "e0cf5c5b-7619-4d80-a4f5-5e65ad459afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.read_csv('nn_report_240_single.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "d5177b70-3303-4cd4-ad01-95e233874a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby = df_report.groupby(by='trial_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "e17ae9dd-90c1-4345-a52e-abb8959290d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mae_index = df_groupby[df_groupby['mae'] == df_groupby['mae'].min()].index.values[0]\n",
    "min_mse_index = df_groupby[df_groupby['rmse'] == df_groupby['rmse'].min()].index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "2b15e498-f9ef-4230-bd78-434f41a3a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "idx = min_mse_index\n",
    "params['input_dim'] = int(df_report[df_report['trial_id'] == idx].iloc[0]['input_dim'])\n",
    "params['n_units'] = int(df_report[df_report['trial_id'] == idx].iloc[0]['n_units'])\n",
    "params['learning_rate'] = float(df_report[df_report['trial_id'] == idx].iloc[0]['learning_rate'])\n",
    "params['loss'] = df_report[df_report['trial_id'] == idx].iloc[0]['loss']\n",
    "batch_size = df_report[df_report['trial_id'] == idx].iloc[0]['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "54f7178f-cf2d-4161-87be-e6ccf255c7c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>input_dim</th>\n",
       "      <th>n_units</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>skn</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>trial_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>54.0</td>\n",
       "      <td>128</td>\n",
       "      <td>3.433046</td>\n",
       "      <td>5.296056</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>79.0</td>\n",
       "      <td>128</td>\n",
       "      <td>3.886207</td>\n",
       "      <td>5.973462</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>338.0</td>\n",
       "      <td>128</td>\n",
       "      <td>2.544070</td>\n",
       "      <td>4.762007</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>250.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.394395</td>\n",
       "      <td>2.049286</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>267.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.505138</td>\n",
       "      <td>2.224552</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>296.1</td>\n",
       "      <td>128</td>\n",
       "      <td>0.799617</td>\n",
       "      <td>1.681203</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>311.0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.796940</td>\n",
       "      <td>1.520546</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>396.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.051577</td>\n",
       "      <td>1.784216</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>400.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.138457</td>\n",
       "      <td>1.805463</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>406.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.241432</td>\n",
       "      <td>1.891523</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>410.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.374516</td>\n",
       "      <td>2.157048</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>485.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.682477</td>\n",
       "      <td>2.451334</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>703.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.069706</td>\n",
       "      <td>2.117684</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>718.0</td>\n",
       "      <td>128</td>\n",
       "      <td>3.898725</td>\n",
       "      <td>5.374983</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>770.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.435372</td>\n",
       "      <td>2.314500</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>783.0</td>\n",
       "      <td>128</td>\n",
       "      <td>3.270729</td>\n",
       "      <td>4.529812</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>784.0</td>\n",
       "      <td>128</td>\n",
       "      <td>4.192942</td>\n",
       "      <td>5.592003</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>965.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.245860</td>\n",
       "      <td>2.106967</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>128</td>\n",
       "      <td>2.565427</td>\n",
       "      <td>4.470704</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>128</td>\n",
       "      <td>2.602223</td>\n",
       "      <td>3.759634</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>128</td>\n",
       "      <td>2.223426</td>\n",
       "      <td>3.740062</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>87.0</td>\n",
       "      <td>128</td>\n",
       "      <td>3.806575</td>\n",
       "      <td>5.621916</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>702.7</td>\n",
       "      <td>128</td>\n",
       "      <td>1.008225</td>\n",
       "      <td>2.055014</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.605019</td>\n",
       "      <td>2.486570</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  input_dim     n_units  learning_rate loss     skn  \\\n",
       "1776           0         16  362.231815       0.000695  mse    54.0   \n",
       "1777           0         16  362.231815       0.000695  mse    79.0   \n",
       "1778           0         16  362.231815       0.000695  mse   338.0   \n",
       "1779           0         16  362.231815       0.000695  mse   250.0   \n",
       "1780           0         16  362.231815       0.000695  mse   267.0   \n",
       "1781           0         16  362.231815       0.000695  mse   296.1   \n",
       "1782           0         16  362.231815       0.000695  mse   311.0   \n",
       "1783           0         16  362.231815       0.000695  mse   396.0   \n",
       "1784           0         16  362.231815       0.000695  mse   400.0   \n",
       "1785           0         16  362.231815       0.000695  mse   406.0   \n",
       "1786           0         16  362.231815       0.000695  mse   410.0   \n",
       "1787           0         16  362.231815       0.000695  mse   485.0   \n",
       "1788           0         16  362.231815       0.000695  mse   703.0   \n",
       "1789           0         16  362.231815       0.000695  mse   718.0   \n",
       "1790           0         16  362.231815       0.000695  mse   770.0   \n",
       "1791           0         16  362.231815       0.000695  mse   783.0   \n",
       "1792           0         16  362.231815       0.000695  mse   784.0   \n",
       "1793           0         16  362.231815       0.000695  mse   965.0   \n",
       "1794           0         16  362.231815       0.000695  mse  1075.0   \n",
       "1795           0         16  362.231815       0.000695  mse  1117.0   \n",
       "1796           0         16  362.231815       0.000695  mse  1134.0   \n",
       "1797           0         16  362.231815       0.000695  mse    87.0   \n",
       "1798           0         16  362.231815       0.000695  mse   702.7   \n",
       "1799           0         16  362.231815       0.000695  mse  1020.1   \n",
       "\n",
       "      batch_size       mae      rmse  trial_id  \n",
       "1776         128  3.433046  5.296056        74  \n",
       "1777         128  3.886207  5.973462        74  \n",
       "1778         128  2.544070  4.762007        74  \n",
       "1779         128  1.394395  2.049286        74  \n",
       "1780         128  1.505138  2.224552        74  \n",
       "1781         128  0.799617  1.681203        74  \n",
       "1782         128  0.796940  1.520546        74  \n",
       "1783         128  1.051577  1.784216        74  \n",
       "1784         128  1.138457  1.805463        74  \n",
       "1785         128  1.241432  1.891523        74  \n",
       "1786         128  1.374516  2.157048        74  \n",
       "1787         128  1.682477  2.451334        74  \n",
       "1788         128  1.069706  2.117684        74  \n",
       "1789         128  3.898725  5.374983        74  \n",
       "1790         128  1.435372  2.314500        74  \n",
       "1791         128  3.270729  4.529812        74  \n",
       "1792         128  4.192942  5.592003        74  \n",
       "1793         128  1.245860  2.106967        74  \n",
       "1794         128  2.565427  4.470704        74  \n",
       "1795         128  2.602223  3.759634        74  \n",
       "1796         128  2.223426  3.740062        74  \n",
       "1797         128  3.806575  5.621916        74  \n",
       "1798         128  1.008225  2.055014        74  \n",
       "1799         128  1.605019  2.486570        74  "
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report[df_report['trial_id'] == idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "ecb9bc16-cd24-459e-8c69-8570643c22fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.524202419975154"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ypred = []\n",
    "list_ytrue = []\n",
    "for fold in range(5):\n",
    "    x_train, x_test, y_train, y_test= prepare_dataset(df_inner_split, skn=skn, inner_fold=0)\n",
    "    linear_regression = LinearRegression()\n",
    "    linear_regression.fit(x_train, y_train)\n",
    "    yhat = linear_regression.predict(x_test)\n",
    "    list_ytrue.append(y_test)\n",
    "    list_ypred.append(yhat)\n",
    "mean_absolute_error(list_ytrue, list_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be59392-f412-4436-97b6-c00223b5329b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
