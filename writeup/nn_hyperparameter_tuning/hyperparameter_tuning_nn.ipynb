{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2e33ac81-8da0-4273-9499-aea84fe85bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cef254e-2af1-4129-a6b0-bbdd6687d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sherpa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/yusukemh/github/yusukemh/StatisticalDownscaling/writeup')\n",
    "from config import C_COMMON, C_GRID, C_SINGLE, FILENAME\n",
    "from util import load_data, NeuralNetwork\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from tqdm import tqdm\n",
    "\n",
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c52c61ab-7678-4ed8-beea-ec6aec33b94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import L1, L2\n",
    "\n",
    "def define_model(\n",
    "    input_dim=20,\n",
    "    n_units=512,\n",
    "    activation='selu',#selu\n",
    "    learning_rate=0.00001,\n",
    "    loss='mse',\n",
    "    batch_size=64\n",
    "):\n",
    "    inputs = Input(shape=(input_dim))\n",
    "    x = Dense(units=n_units, activation=activation, kernel_regularizer=L2(l2=0.01))(inputs)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=n_units, activation=activation, kernel_regularizer=L2(l2=0.01))(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=n_units, activation=activation, kernel_regularizer=L2(l2=0.01))(x)\n",
    "    x = Dropout(rate=0.5)(x)# serves as regularization\n",
    "    outputs = Dense(units=1, activation='softplus')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    return model, batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f9c2a36-9551-4e45-afd9-25840c8eae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = C_SINGLE\n",
    "n_run = 100\n",
    "\n",
    "df_train, df_test = load_data(columns + C_COMMON, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dacefd2-552c-4478-b57c-36fd03955d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_model = NeuralNetwork(\n",
    "    params={\n",
    "        'n_units': 815,\n",
    "        'learning_rate': 0.00012633633813255,\n",
    "        'input_dim': 16,\n",
    "        'batch_size': 64,\n",
    "        'loss': 'mse'\n",
    "    },\n",
    "    columns=columns,\n",
    "    model_func=define_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bed530a-a720-4bfb-af75-abd45daed138",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'skn': 54, 'rmse_nn': 4.6742818573917075, 'mae_nn': 3.1465105790969643}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_model.evaluate_by_station(df_train, df_test, skn=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2555153-53a6-4129-8abd-c1e5af37eb81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "207727a9-f94b-4877-ba71-4d57c3f1d3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sherpa.core:\n",
      "-------------------------------------------------------\n",
      "SHERPA Dashboard running. Access via\n",
      "http://10.100.11.207:8887 if on a cluster or\n",
      "http://localhost:8887 if running locally.\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'sherpa.app.app' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:werkzeug: * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "100%|██████████| 24/24 [00:00<00:00, 327.88it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.15it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.58it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.78it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.65it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.63it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 333.65it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.67it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 334.26it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.78it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 347.30it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.16it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.66it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.57it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.65it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.26it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 339.80it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.39it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.96it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.38it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.76it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.88it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.75it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.14it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.70it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.11it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 332.64it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.00it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.70it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.59it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 333.20it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.42it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.32it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 339.34it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.86it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.16it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.46it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.35it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.87it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.60it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.72it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.26it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 334.52it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.40it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.45it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.99it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.88it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 328.70it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 306.06it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.70it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 346.10it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.52it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.64it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.47it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.28it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.09it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.44it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.32it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.68it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.42it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.81it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.95it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.40it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.10it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.06it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 334.70it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 334.24it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.27it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.65it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.49it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.39it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.51it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.76it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.02it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.92it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.94it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.04it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.05it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.27it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.10it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.16it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.15it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 348.86it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.05it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 334.68it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.47it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 375.65it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.36it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 333.35it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.48it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 332.00it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.34it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.42it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 336.73it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.59it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 337.43it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 335.68it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.48it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 332.94it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 338.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# set up sherpa\n",
    "parameters = [\n",
    "    sherpa.Discrete('n_units', [256, 1024]),\n",
    "    sherpa.Continuous('learning_rate', [0.00001, 0.01]),\n",
    "    sherpa.Choice('batch_size', [64, 128, 192, 256, 512, 1024]),\n",
    "    sherpa.Choice('loss', ['mse', 'mae'])\n",
    "]\n",
    "study = sherpa.Study(\n",
    "    parameters=parameters,\n",
    "    algorithm=sherpa.algorithms.RandomSearch(max_num_trials=n_run),\n",
    "    lower_is_better=True\n",
    ")\n",
    "\n",
    "dfs = []\n",
    "for i, trial in enumerate(study):\n",
    "    # obtain hyperparameters\n",
    "    params = {key: val for key, val in trial.parameters.items()}\n",
    "    params['input_dim'] = len(columns)\n",
    "\n",
    "    for skn in tqdm(df_train['skn'].unique()):\n",
    "        model = NeuralNetwork(\n",
    "            model_func=define_model,\n",
    "            params=params,\n",
    "            columns=columns\n",
    "        )\n",
    "        ret = model.cross_val_predict(df_train, skn)\n",
    "        df = pd.DataFrame()\n",
    "        df['trial_id'] = i,\n",
    "        df['rmse'] = [ret['rmse']]\n",
    "        df['mae'] = [ret['mae']]\n",
    "        df['skn'] = [skn]\n",
    "        for key, val in params.items():\n",
    "            df[key] = [val]\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b019884-c745-4808-ba73-8fb7ec6893ad",
   "metadata": {},
   "source": [
    "# get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0cf5c5b-7619-4d80-a4f5-5e65ad459afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.read_csv('nn_report_500_single.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5177b70-3303-4cd4-ad01-95e233874a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby = df_report.groupby(by='trial_id').mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37074394-f0cf-456f-ba43-f83e46fe0d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>epochs</th>\n",
       "      <th>skn</th>\n",
       "      <th>n_units</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>input_dim</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.704507</td>\n",
       "      <td>7.457255</td>\n",
       "      <td>27.875000</td>\n",
       "      <td>564.620833</td>\n",
       "      <td>688.0</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>512.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.978413</td>\n",
       "      <td>7.537671</td>\n",
       "      <td>25.541667</td>\n",
       "      <td>564.620833</td>\n",
       "      <td>555.0</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>256.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.877413</td>\n",
       "      <td>7.234314</td>\n",
       "      <td>42.166667</td>\n",
       "      <td>564.620833</td>\n",
       "      <td>394.0</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>192.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.318749</td>\n",
       "      <td>7.989835</td>\n",
       "      <td>22.750000</td>\n",
       "      <td>564.620833</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>512.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.335918</td>\n",
       "      <td>9.390875</td>\n",
       "      <td>21.375000</td>\n",
       "      <td>564.620833</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.664232</td>\n",
       "      <td>9.693049</td>\n",
       "      <td>25.500000</td>\n",
       "      <td>564.620833</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.341678</td>\n",
       "      <td>8.116387</td>\n",
       "      <td>23.291667</td>\n",
       "      <td>564.620833</td>\n",
       "      <td>421.0</td>\n",
       "      <td>0.007488</td>\n",
       "      <td>512.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.002604</td>\n",
       "      <td>7.662700</td>\n",
       "      <td>27.291667</td>\n",
       "      <td>564.620833</td>\n",
       "      <td>945.0</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>512.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.615754</td>\n",
       "      <td>9.007943</td>\n",
       "      <td>21.458333</td>\n",
       "      <td>564.620833</td>\n",
       "      <td>708.0</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>256.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.336774</td>\n",
       "      <td>8.210041</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>564.620833</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>256.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0       rmse       mae     epochs         skn  n_units  \\\n",
       "trial_id                                                                    \n",
       "0                0.0   9.704507  7.457255  27.875000  564.620833    688.0   \n",
       "1                0.0   9.978413  7.537671  25.541667  564.620833    555.0   \n",
       "2                0.0   9.877413  7.234314  42.166667  564.620833    394.0   \n",
       "3                0.0  10.318749  7.989835  22.750000  564.620833    441.0   \n",
       "4                0.0  12.335918  9.390875  21.375000  564.620833    525.0   \n",
       "...              ...        ...       ...        ...         ...      ...   \n",
       "495              0.0  12.664232  9.693049  25.500000  564.620833    600.0   \n",
       "496              0.0  10.341678  8.116387  23.291667  564.620833    421.0   \n",
       "497              0.0  10.002604  7.662700  27.291667  564.620833    945.0   \n",
       "498              0.0  11.615754  9.007943  21.458333  564.620833    708.0   \n",
       "499              0.0  10.336774  8.210041  21.750000  564.620833    575.0   \n",
       "\n",
       "          learning_rate  batch_size  input_dim  \n",
       "trial_id                                        \n",
       "0              0.002495       512.0       16.0  \n",
       "1              0.004155       256.0       16.0  \n",
       "2              0.003582       192.0       16.0  \n",
       "3              0.008499       512.0       16.0  \n",
       "4              0.004710        64.0       16.0  \n",
       "...                 ...         ...        ...  \n",
       "495            0.002289        64.0       16.0  \n",
       "496            0.007488       512.0       16.0  \n",
       "497            0.001313       512.0       16.0  \n",
       "498            0.006114       256.0       16.0  \n",
       "499            0.006253       256.0       16.0  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1602cf5-7585-4fc3-83fc-2276a1a17e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_units': 835,\n",
       " 'learning_rate': 0.0002633633813255,\n",
       " 'input_dim': 16,\n",
       " 'batch_size': 64,\n",
       " 'loss': 'mse'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective = 'rmse'\n",
    "idx_best_objective = df_groupby[objective].argmin()\n",
    "df_report.query(f'trial_id == {idx_best_objective}').iloc[0][['n_units', 'learning_rate', 'input_dim', 'batch_size', 'loss']].to_dict()\n",
    "# df_groupby.iloc[idx_best_objective]# [['n_units', 'learning_rate', 'input_dim', 'batch_size', 'loss']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69486f82-237c-44d2-ab84-093942f51e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3e0df5-c9dc-49d2-9c10-ab8ec82dbc41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f59c589-5198-4a70-aa63-5b051d346168",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc885b4-d704-4b38-b3f9-0214ea6ac710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40816186-e012-4101-8b6a-fa111a39389b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e17ae9dd-90c1-4345-a52e-abb8959290d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_units': 835,\n",
       " 'learning_rate': 0.0002633633813255,\n",
       " 'batch_size': 64,\n",
       " 'input_dim': 16}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective = 'rmse'\n",
    "params = df_groupby[df_groupby[objective] == df_groupby[objective].min()][['n_units', 'learning_rate', 'batch_size', 'input_dim']].iloc[0].to_dict()\n",
    "{key: val if key == 'learning_rate' else int(val) for key, val in params.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "2b15e498-f9ef-4230-bd78-434f41a3a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "idx = min_mse_index\n",
    "params['input_dim'] = int(df_report[df_report['trial_id'] == idx].iloc[0]['input_dim'])\n",
    "params['n_units'] = int(df_report[df_report['trial_id'] == idx].iloc[0]['n_units'])\n",
    "params['learning_rate'] = float(df_report[df_report['trial_id'] == idx].iloc[0]['learning_rate'])\n",
    "params['loss'] = df_report[df_report['trial_id'] == idx].iloc[0]['loss']\n",
    "batch_size = df_report[df_report['trial_id'] == idx].iloc[0]['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "54f7178f-cf2d-4161-87be-e6ccf255c7c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>input_dim</th>\n",
       "      <th>n_units</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>skn</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>trial_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>54.0</td>\n",
       "      <td>128</td>\n",
       "      <td>3.433046</td>\n",
       "      <td>5.296056</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>79.0</td>\n",
       "      <td>128</td>\n",
       "      <td>3.886207</td>\n",
       "      <td>5.973462</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>338.0</td>\n",
       "      <td>128</td>\n",
       "      <td>2.544070</td>\n",
       "      <td>4.762007</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>250.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.394395</td>\n",
       "      <td>2.049286</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>267.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.505138</td>\n",
       "      <td>2.224552</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>296.1</td>\n",
       "      <td>128</td>\n",
       "      <td>0.799617</td>\n",
       "      <td>1.681203</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>311.0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.796940</td>\n",
       "      <td>1.520546</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>396.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.051577</td>\n",
       "      <td>1.784216</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>400.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.138457</td>\n",
       "      <td>1.805463</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>406.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.241432</td>\n",
       "      <td>1.891523</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>410.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.374516</td>\n",
       "      <td>2.157048</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>485.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.682477</td>\n",
       "      <td>2.451334</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>703.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.069706</td>\n",
       "      <td>2.117684</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>718.0</td>\n",
       "      <td>128</td>\n",
       "      <td>3.898725</td>\n",
       "      <td>5.374983</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>770.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.435372</td>\n",
       "      <td>2.314500</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>783.0</td>\n",
       "      <td>128</td>\n",
       "      <td>3.270729</td>\n",
       "      <td>4.529812</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>784.0</td>\n",
       "      <td>128</td>\n",
       "      <td>4.192942</td>\n",
       "      <td>5.592003</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>965.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1.245860</td>\n",
       "      <td>2.106967</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>128</td>\n",
       "      <td>2.565427</td>\n",
       "      <td>4.470704</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>128</td>\n",
       "      <td>2.602223</td>\n",
       "      <td>3.759634</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>128</td>\n",
       "      <td>2.223426</td>\n",
       "      <td>3.740062</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>87.0</td>\n",
       "      <td>128</td>\n",
       "      <td>3.806575</td>\n",
       "      <td>5.621916</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>702.7</td>\n",
       "      <td>128</td>\n",
       "      <td>1.008225</td>\n",
       "      <td>2.055014</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>362.231815</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>mse</td>\n",
       "      <td>1020.1</td>\n",
       "      <td>128</td>\n",
       "      <td>1.605019</td>\n",
       "      <td>2.486570</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  input_dim     n_units  learning_rate loss     skn  \\\n",
       "1776           0         16  362.231815       0.000695  mse    54.0   \n",
       "1777           0         16  362.231815       0.000695  mse    79.0   \n",
       "1778           0         16  362.231815       0.000695  mse   338.0   \n",
       "1779           0         16  362.231815       0.000695  mse   250.0   \n",
       "1780           0         16  362.231815       0.000695  mse   267.0   \n",
       "1781           0         16  362.231815       0.000695  mse   296.1   \n",
       "1782           0         16  362.231815       0.000695  mse   311.0   \n",
       "1783           0         16  362.231815       0.000695  mse   396.0   \n",
       "1784           0         16  362.231815       0.000695  mse   400.0   \n",
       "1785           0         16  362.231815       0.000695  mse   406.0   \n",
       "1786           0         16  362.231815       0.000695  mse   410.0   \n",
       "1787           0         16  362.231815       0.000695  mse   485.0   \n",
       "1788           0         16  362.231815       0.000695  mse   703.0   \n",
       "1789           0         16  362.231815       0.000695  mse   718.0   \n",
       "1790           0         16  362.231815       0.000695  mse   770.0   \n",
       "1791           0         16  362.231815       0.000695  mse   783.0   \n",
       "1792           0         16  362.231815       0.000695  mse   784.0   \n",
       "1793           0         16  362.231815       0.000695  mse   965.0   \n",
       "1794           0         16  362.231815       0.000695  mse  1075.0   \n",
       "1795           0         16  362.231815       0.000695  mse  1117.0   \n",
       "1796           0         16  362.231815       0.000695  mse  1134.0   \n",
       "1797           0         16  362.231815       0.000695  mse    87.0   \n",
       "1798           0         16  362.231815       0.000695  mse   702.7   \n",
       "1799           0         16  362.231815       0.000695  mse  1020.1   \n",
       "\n",
       "      batch_size       mae      rmse  trial_id  \n",
       "1776         128  3.433046  5.296056        74  \n",
       "1777         128  3.886207  5.973462        74  \n",
       "1778         128  2.544070  4.762007        74  \n",
       "1779         128  1.394395  2.049286        74  \n",
       "1780         128  1.505138  2.224552        74  \n",
       "1781         128  0.799617  1.681203        74  \n",
       "1782         128  0.796940  1.520546        74  \n",
       "1783         128  1.051577  1.784216        74  \n",
       "1784         128  1.138457  1.805463        74  \n",
       "1785         128  1.241432  1.891523        74  \n",
       "1786         128  1.374516  2.157048        74  \n",
       "1787         128  1.682477  2.451334        74  \n",
       "1788         128  1.069706  2.117684        74  \n",
       "1789         128  3.898725  5.374983        74  \n",
       "1790         128  1.435372  2.314500        74  \n",
       "1791         128  3.270729  4.529812        74  \n",
       "1792         128  4.192942  5.592003        74  \n",
       "1793         128  1.245860  2.106967        74  \n",
       "1794         128  2.565427  4.470704        74  \n",
       "1795         128  2.602223  3.759634        74  \n",
       "1796         128  2.223426  3.740062        74  \n",
       "1797         128  3.806575  5.621916        74  \n",
       "1798         128  1.008225  2.055014        74  \n",
       "1799         128  1.605019  2.486570        74  "
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report[df_report['trial_id'] == idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "ecb9bc16-cd24-459e-8c69-8570643c22fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.524202419975154"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ypred = []\n",
    "list_ytrue = []\n",
    "for fold in range(5):\n",
    "    x_train, x_test, y_train, y_test= prepare_dataset(df_inner_split, skn=skn, inner_fold=0)\n",
    "    linear_regression = LinearRegression()\n",
    "    linear_regression.fit(x_train, y_train)\n",
    "    yhat = linear_regression.predict(x_test)\n",
    "    list_ytrue.append(y_test)\n",
    "    list_ypred.append(yhat)\n",
    "mean_absolute_error(list_ytrue, list_ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be59392-f412-4436-97b6-c00223b5329b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
