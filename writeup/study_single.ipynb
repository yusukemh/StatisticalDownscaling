{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1bcbf107-37c1-40ce-8a5a-4b57bb72263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# others\n",
    "import multiprocessing as mp\n",
    "from xgboost import XGBRegressor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# config\n",
    "import sys\n",
    "sys.path.append('/home/yusukemh/github/yusukemh/StatisticalDownscaling/writeup')\n",
    "from config import C_COMMON, C_SINGLE, C_GRID, FILENAME\n",
    "\n",
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4c6131f5-0cb8-4b5f-a0bd-099cb8251487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILENAME, usecols=C_COMMON + C_SINGLE)\n",
    "columns = C_SINGLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ca0124-c994-45d5-8dca-f00358c10504",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "10587d28-c7ca-4f09-a436-077ea7eb2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(df: pd.DataFrame, model, skn: int, columns: list, verbose=False):\n",
    "    \"\"\"\n",
    "    Runs cross_val_predict for a single skn, using XGB or LinearRegression.\n",
    "    The same functionality as sklearn.model_selection.cross_val_predict,\n",
    "    except the split is not exactly 1/5 (thus pre-determined by preprocessing).\n",
    "    This is because the split has to be made in the way it won't separate samples in the same month into different folds.\n",
    "        Args:\n",
    "            :param df: dataset for evaluation. Must contain 'fold' column that specifies assignment of each sample to the folds.\n",
    "            :param model: one of [sklearn.linear_models.LinearRegression, xgboost.XGBRegressor]\n",
    "            :param skn: identifier for stations\n",
    "            :param columns: list of str indicating which columns to use as input data for the model\n",
    "    \"\"\"\n",
    "    assert 'fold' in df.columns, \"Must contain a column 'fold' to specify assignment of samples to the folds.\"\n",
    "    n_folds = len(df['fold'].unique())\n",
    "    dfs = [] # list of dfs containing result for each fold\n",
    "    \n",
    "    iterator = tqdm(range(n_folds)) if verbose else range(n_folds)\n",
    "    \n",
    "    for fold in iterator:\n",
    "        df_train = df.query(f'(fold != {fold}) & (skn == {skn})')\n",
    "        df_test = df.query(f'(fold == {fold}) & (skn == {skn})')\n",
    "        \n",
    "        x_train, x_test = np.array(df_train[columns]), np.array(df_test[columns])\n",
    "        y_train, y_test = np.array(df_train['data_in']), np.array(df_test['data_in'])\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        yhat = model.predict(x_test)\n",
    "        \n",
    "        _df = pd.DataFrame(\n",
    "            {\n",
    "                'skn' : df_test['skn'].values,\n",
    "                'year': df_test['year'].values,\n",
    "                'month': df_test['month'].values,\n",
    "                'observed': df_test['data_in'].values,\n",
    "                'prediction': yhat,\n",
    "            }\n",
    "        )\n",
    "        dfs.append(_df)\n",
    "        \n",
    "    return pd.concat(dfs)\n",
    "\n",
    "def parallelize(func, args, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    :param args: iterable. list of arguments for the function\n",
    "    \"\"\"\n",
    "    if n_jobs == -1:\n",
    "        pool = mp.Pool(mp.cpu_count())\n",
    "    else:\n",
    "        pool = mp.Pool(n_jobs)\n",
    "    result_objects = [pool.apply_async(func, args=_args) for _args in args]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return [r.get() for r in result_objects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2bd9035f-8737-4dd4-a5a7-47f6bc63e3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.004229222338949"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "df_result = cross_val_predict(df, linear_regression, skn=79, columns=columns, verbose=False)\n",
    "mean_squared_error(df_result['observed'], df_result['prediction'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "17142742-19d9-49f3-9fbe-01030a86d01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.792404950412038"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost = XGBRegressor()\n",
    "df_result = cross_val_predict(df, xgboost, skn=79, columns=columns, verbose=True)\n",
    "mean_squared_error(df_result['observed'], df_result['prediction'], squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "6d27b92f-a86e-445e-a376-b30341a04100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.87988209724426\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result_dfs = parallelize(\n",
    "    cross_val_predict,\n",
    "    [[skn] for skn in df['skn'].unique()]\n",
    ")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3252bb54-3270-49da-9c16-0392c00a05b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:32<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.77909517288208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for skn in tqdm(df['skn'].unique()):\n",
    "    _df = cross_val_predict(df, xgboost, skn, columns, False)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a9c01e10-ae2f-4b16-bc85-366798258037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.09046173095703\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "Parallel(n_jobs=12)(delayed(cross_val_predict)(df, xgboost, skn, columns, False) for skn in df['skn'].unique())\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16499402-29a6-465b-8cd7-747f9481f194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f6b48935-60bb-49e3-8def-8540bee39521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4abf7d73-e0bf-4c02-b441-6dfc8c354b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0273005962371826\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "Parallel(n_jobs=12)(delayed(dummy)(skn, i) for skn, i in zip(range(10), range(1,11)))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d4702-6918-43d9-91c9-5dd1539a5487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde1a57-bc77-4e47-8efc-e329e8c95cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e43dc6-ac5b-422a-b1c1-2b3600d8023d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "eab3b0d6-59ec-44ef-8623-4c24c387bd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(skn, i):\n",
    "    time.sleep(1)\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5fa6586d-0ad0-4914-9534-9751e5da2050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.035521030426025\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for i in range(24):\n",
    "    dummy(0, i)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ffe37ed5-592f-466a-9e56-7b050f143dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.629427433013916\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "test = paralellize(\n",
    "    dummy,\n",
    "    [(skn, 0) for skn in df['skn'].unique()]\n",
    ")\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "875e05cb-b652-44ce-930f-51dcd949d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool = mp.Pool(mp.cpu_count())\n",
    "# result_objects = [pool.apply_async(dummy, args=[skn]) for skn in df['skn'].unique()]\n",
    "# results = [r.get() for r in result_objects]\n",
    "# pool.close()\n",
    "# pool.join()\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d59ac-438e-4d27-9af4-1fefb1d13d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
