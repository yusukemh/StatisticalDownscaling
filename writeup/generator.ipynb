{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a5340111-fa80-4268-a327-9797bc702d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "\n",
    "# basic libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "\n",
    "# sklearn\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# others\n",
    "# import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "# config\n",
    "import sys\n",
    "sys.path.append('/home/yusukemh/github/yusukemh/StatisticalDownscaling/writeup')\n",
    "from config import C_COMMON, C_SINGLE, C_GRID, FILENAME\n",
    "from util import load_data\n",
    "\n",
    "# enable autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "class Generator(Sequence):\n",
    "    # Class is a dataset wrapper for better training performance\n",
    "    def __init__(self, x_set, y_set, batch_size=256):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(self.x.shape[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(self.x.shape[0] / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]  # Line A\n",
    "        inds = self.indices.take(range(idx * self.batch_size, (idx + 1) * self.batch_size), mode='wrap')\n",
    "        batch_x = self.x[inds]\n",
    "        batch_y = self.y[inds]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self, model_func, params, columns):\n",
    "        self.model_func = model_func\n",
    "        self.params = params\n",
    "        self.columns = columns\n",
    "        pass\n",
    "    \n",
    "    def evaluate_by_station(self, df_train, df_test, skn):\n",
    "        df_train_station = df_train[df_train['skn'] == skn]\n",
    "        df_test_station = df_test[df_test['skn'] == skn]\n",
    "\n",
    "        # convert to numpy\n",
    "        x_train, x_test = np.array(df_train_station[self.columns]), np.array(df_test_station[self.columns])\n",
    "        y_train, y_test = np.array(df_train_station['data_in']), np.array(df_test_station['data_in'])\n",
    "\n",
    "        # scale the input and output\n",
    "        x_train, x_test = self.transform_x(x_train, x_test)\n",
    "        y_train, y_test = self.transform_y(y_train, y_test)\n",
    "        \n",
    "        # train the model with retrain_full = True\n",
    "        history = self.train(x_train, y_train, verbose=0, retrain_full=True)\n",
    "\n",
    "        # make prediction and scale\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        y_pred = self.inverse_transform_y(y_pred)\n",
    "\n",
    "        # scale y_test\n",
    "        y_test = self.inverse_transform_y(y_test)\n",
    "        \n",
    "        return {\n",
    "            \"skn\": skn,\n",
    "            \"rmse_nn\": mean_squared_error(y_test, y_pred, squared=False),\n",
    "            \"mae_nn\": mean_absolute_error(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def evaluate(self, df_train, df_test):\n",
    "        ret_vals = []\n",
    "        for skn in tqdm(df_train['skn'].unique()):\n",
    "            r = self.evaluate_by_station(df_train, df_test, skn)\n",
    "            ret_vals.append(r)\n",
    "\n",
    "        return pd.DataFrame(ret_vals)\n",
    "            \n",
    "            \n",
    "    \n",
    "    def cross_val_predict(self, df, skn, verbose=0, n_folds=5):\n",
    "        assert 'inner_fold' in df.columns, 'define fold with column name \"inner_fold\"'\n",
    "        df_station = df[df['skn'] == skn]\n",
    "        \n",
    "        list_ytrue = []\n",
    "        list_ypred = []\n",
    "        for k in range(n_folds):\n",
    "            # split the dataset\n",
    "            df_train = df_station[df_station['inner_fold'] != k]\n",
    "            df_test = df_station[df_station['inner_fold'] == k]\n",
    "            \n",
    "            # convert to numpy\n",
    "            x_train, x_test = np.array(df_train[self.columns]), np.array(df_test[self.columns])\n",
    "            y_train, y_test = np.array(df_train['data_in']), np.array(df_test['data_in'])\n",
    "            \n",
    "            # scale the input and output\n",
    "            x_train, x_test = self.transform_x(x_train, x_test)\n",
    "            y_train, y_test = self.transform_y(y_train, y_test)\n",
    "            \n",
    "            # train the model\n",
    "            history = self.train(x_train, y_train, verbose=0, retrain_full=False) # to speed up computation for hyperparaemter tuning\n",
    "            \n",
    "            # make prediction and scale\n",
    "            y_pred = self.model.predict(x_test)\n",
    "            y_pred = self.inverse_transform_y(y_pred)\n",
    "            # scale y_test\n",
    "            y_test = self.inverse_transform_y(y_test)\n",
    "            \n",
    "            # keep the record\n",
    "            list_ytrue.extend(y_test)\n",
    "            list_ypred.extend(y_pred)\n",
    "        \n",
    "        # calculate the loss and return\n",
    "        return {\n",
    "            \"rmse\": mean_squared_error(list_ytrue, list_ypred, squared=False),\n",
    "            \"mae\": mean_absolute_error(list_ytrue, list_ypred),\n",
    "            'epochs': len(history.history['loss'])\n",
    "        }\n",
    "\n",
    "    def transform_x(self, x_train, x_test):\n",
    "        scaler = MinMaxScaler()\n",
    "        x_train = scaler.fit_transform(x_train)\n",
    "        x_test = scaler.transform(x_test)\n",
    "        return x_train, x_test\n",
    "    \n",
    "    def transform_y(self, y_train, y_test):\n",
    "        y_train = np.log(y_train + 1.)\n",
    "        y_test = np.log(y_test + 1.)\n",
    "\n",
    "        return y_train, y_test# , scaler\n",
    "    \n",
    "    def inverse_transform_y(self, y):\n",
    "        y = np.power(np.e, y) - 1\n",
    "        return y\n",
    "    \n",
    "    def train(self, x, y, verbose=0, retrain_full=False):\n",
    "        # split into train and validation\n",
    "        # strictly speaking, this is not appropriate because scaler fit to the union of train/valid\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, shuffle=False)\n",
    "        # build the model\n",
    "        self.model, batch_size = self.model_func(**self.params)\n",
    "        # set up callbacks\n",
    "        callbacks = [\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0,\n",
    "                patience=20,\n",
    "                restore_best_weights=True,\n",
    "            ),\n",
    "            ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.95,\n",
    "                patience=10\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # set up the generators\n",
    "        train_datagen = Generator(x_train, y_train, batch_size)\n",
    "        valid_datagen = Generator(x_valid, y_valid, batch_size)\n",
    "        \n",
    "        history = self.model.fit_generator(\n",
    "            train_datagen,\n",
    "            steps_per_epoch=np.ceil(len(x_train)/batch_size),\n",
    "            validation_data=valid_datagen,\n",
    "            validation_steps=np.ceil(len(x_valid)/batch_size),\n",
    "            epochs=int(1e3),\n",
    "            callbacks=callbacks,\n",
    "            verbose=0\n",
    "            \n",
    "            # epochs=int(1e3),\n",
    "            # batch_size=batch_size,\n",
    "            # validation_split=0.2,\n",
    "            # callbacks=callbacks,\n",
    "            # verbose=0\n",
    "        )\n",
    "        \n",
    "        if retrain_full:\n",
    "            epochs = len(history.history['loss'])\n",
    "            train_datagen = Generator(x, y, batch_size)\n",
    "            # rebuild the model\n",
    "            self.model, batch_size = self.model_func(**self.params)\n",
    "            callbacks = [EarlyStopping(monitor='loss', min_delta=0, patience=1e3, restore_best_weights=True)]\n",
    "            history = self.model.fit(\n",
    "                train_datagen,\n",
    "                steps_per_epoch=np.ceil(len(x) / batch_size),\n",
    "                epochs=epochs,\n",
    "                callbacks=callbacks,\n",
    "                verbose=0,\n",
    "                #epochs=epochs,\n",
    "                #validation_split=0,\n",
    "                #callbacks=callbacks,\n",
    "                #batch_size=batch_size,\n",
    "                #verbose=0\n",
    "            )\n",
    "        return history        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5915875b-b4be-432b-919f-74c1504c2fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7,  8,  9, 10,  1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "test.take(range(5, 11), mode='wrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5afbefc3-fa26-4083-835e-fbffea6fb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import L2\n",
    "\n",
    "def define_model(\n",
    "    input_dim=20,\n",
    "    n_units=512,\n",
    "    activation='selu',#selu\n",
    "    learning_rate=0.00001,\n",
    "    loss='mse',\n",
    "    batch_size=64\n",
    "):\n",
    "    inputs = Input(shape=(input_dim))\n",
    "    x = Dense(units=n_units, activation=activation, kernel_regularizer=L2(l2=0.01))(inputs)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=n_units, activation=activation, kernel_regularizer=L2(l2=0.01))(x)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(units=n_units, activation=activation, kernel_regularizer=L2(l2=0.01))(x)\n",
    "    x = Dropout(rate=0.5)(x)# serves as regularization\n",
    "    outputs = Dense(units=1, activation='softplus')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[RootMeanSquaredError()]\n",
    "    )\n",
    "    return model, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0f78af-588b-41ce-a3db-fd11a31f67ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "454cfefa-b205-4b67-827d-bf9b08ad3cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = C_SINGLE\n",
    "df_train, df_test = load_data(columns + C_COMMON, FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35b09913-cde3-423e-be41-10c2755e121c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': 5.789018970581302, 'mae': 3.572849455263069, 'epochs': 330}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_model = NeuralNetwork(\n",
    "    columns = columns,\n",
    "    params = {'n_units': 274, 'learning_rate': 0.001701746715659, 'input_dim': 16, 'batch_size': 192, 'loss': 'mse'},\n",
    "    model_func=define_model\n",
    ")\n",
    "n_model.cross_val_predict(df_train, skn=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d42bf-299f-42a0-9516-86632b7b5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure cross_val_predict works, and add n_iter for evaluate and evaluate_by_station to take the mean, std of perfoemance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a707fcd5-6536-4669-b131-995c194f1733",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "  4%|▍         | 1/24 [00:35<13:25, 35.03s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "  8%|▊         | 2/24 [00:54<09:24, 25.65s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 12%|█▎        | 3/24 [02:25<19:28, 55.64s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 17%|█▋        | 4/24 [03:58<23:25, 70.27s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 21%|██        | 5/24 [05:29<24:43, 78.06s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 25%|██▌       | 6/24 [06:10<19:38, 65.45s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 29%|██▉       | 7/24 [07:05<17:33, 61.99s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 33%|███▎      | 8/24 [08:38<19:10, 71.90s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 38%|███▊      | 9/24 [09:14<15:08, 60.54s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 42%|████▏     | 10/24 [09:51<12:27, 53.37s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 46%|████▌     | 11/24 [10:32<10:43, 49.49s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 50%|█████     | 12/24 [11:00<08:36, 43.04s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 54%|█████▍    | 13/24 [12:37<10:51, 59.18s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 58%|█████▊    | 14/24 [13:18<08:59, 53.94s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 62%|██████▎   | 15/24 [14:02<07:38, 50.93s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 67%|██████▋   | 16/24 [15:29<08:12, 61.61s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 71%|███████   | 17/24 [16:45<07:41, 65.89s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 75%|███████▌  | 18/24 [17:24<05:46, 57.82s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 79%|███████▉  | 19/24 [17:53<04:05, 49.20s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 83%|████████▎ | 20/24 [18:32<03:05, 46.26s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 88%|████████▊ | 21/24 [20:13<03:08, 62.77s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 92%|█████████▏| 22/24 [21:48<02:24, 72.22s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      " 96%|█████████▌| 23/24 [23:22<01:18, 78.72s/it]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "100%|██████████| 24/24 [25:01<00:00, 62.58s/it]\n"
     ]
    }
   ],
   "source": [
    "from hyperparameters import NN_PARAMS\n",
    "ret_vals = []\n",
    "for item in tqdm(NN_PARAMS):\n",
    "    station_model = NeuralNetwork(\n",
    "        columns=columns,\n",
    "        params=item['params'],\n",
    "        model_func=define_model\n",
    "    )\n",
    "    r = station_model.evaluate_by_station(df_train, df_test, skn=item['skn'])\n",
    "    ret_vals.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a080448c-9865-4bb8-b250-f271a4cbace1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]/home/yusukemh/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 8.5489 - root_mean_squared_error: 1.3962 - val_loss: 34.9929 - val_root_mean_squared_error: 5.3319\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 28.6793 - root_mean_squared_error: 4.7027 - val_loss: 7.2776 - val_root_mean_squared_error: 0.8584\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.9652 - root_mean_squared_error: 1.1935 - val_loss: 9.5655 - val_root_mean_squared_error: 1.7451\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.2526 - root_mean_squared_error: 1.6530 - val_loss: 10.6801 - val_root_mean_squared_error: 2.0449\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 10.1796 - root_mean_squared_error: 1.9186 - val_loss: 10.7791 - val_root_mean_squared_error: 2.0742\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10.4265 - root_mean_squared_error: 1.9874 - val_loss: 10.5698 - val_root_mean_squared_error: 2.0286\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10.1628 - root_mean_squared_error: 1.9257 - val_loss: 9.7923 - val_root_mean_squared_error: 1.8327\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 9.4623 - root_mean_squared_error: 1.7404 - val_loss: 7.6438 - val_root_mean_squared_error: 1.1089\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.8511 - root_mean_squared_error: 1.1987 - val_loss: 7.5185 - val_root_mean_squared_error: 1.0590\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 8.0502 - root_mean_squared_error: 1.2857 - val_loss: 9.1544 - val_root_mean_squared_error: 1.6671\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9.0069 - root_mean_squared_error: 1.6223 - val_loss: 7.4477 - val_root_mean_squared_error: 1.0471\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.9462 - root_mean_squared_error: 1.2629 - val_loss: 6.7300 - val_root_mean_squared_error: 0.6352\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.2455 - root_mean_squared_error: 0.9586 - val_loss: 7.5700 - val_root_mean_squared_error: 1.1262\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.6860 - root_mean_squared_error: 1.1766 - val_loss: 8.1238 - val_root_mean_squared_error: 1.3590\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 8.0645 - root_mean_squared_error: 1.3371 - val_loss: 8.0832 - val_root_mean_squared_error: 1.3532\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.9951 - root_mean_squared_error: 1.3202 - val_loss: 7.5803 - val_root_mean_squared_error: 1.1630\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.5390 - root_mean_squared_error: 1.1451 - val_loss: 6.8501 - val_root_mean_squared_error: 0.8041\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.1365 - root_mean_squared_error: 0.9659 - val_loss: 6.5195 - val_root_mean_squared_error: 0.5831\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.9512 - root_mean_squared_error: 0.8785 - val_loss: 6.8533 - val_root_mean_squared_error: 0.8358\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.1967 - root_mean_squared_error: 1.0207 - val_loss: 7.0604 - val_root_mean_squared_error: 0.9652\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 7.4388 - root_mean_squared_error: 1.1446 - val_loss: 6.7039 - val_root_mean_squared_error: 0.7761\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 7.0049 - root_mean_squared_error: 0.9504 - val_loss: 6.3705 - val_root_mean_squared_error: 0.5448\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.7439 - root_mean_squared_error: 0.8186 - val_loss: 6.3549 - val_root_mean_squared_error: 0.5561\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.7332 - root_mean_squared_error: 0.8292 - val_loss: 6.4779 - val_root_mean_squared_error: 0.6785\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.7002 - root_mean_squared_error: 0.8262 - val_loss: 6.5371 - val_root_mean_squared_error: 0.7399\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.8402 - root_mean_squared_error: 0.9222 - val_loss: 6.4519 - val_root_mean_squared_error: 0.7000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.7610 - root_mean_squared_error: 0.8939 - val_loss: 6.2879 - val_root_mean_squared_error: 0.5947\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.5952 - root_mean_squared_error: 0.8130 - val_loss: 6.1584 - val_root_mean_squared_error: 0.5016\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.4255 - root_mean_squared_error: 0.7203 - val_loss: 6.1203 - val_root_mean_squared_error: 0.4910\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.4220 - root_mean_squared_error: 0.7367 - val_loss: 6.1681 - val_root_mean_squared_error: 0.5628\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.5048 - root_mean_squared_error: 0.8084 - val_loss: 6.1932 - val_root_mean_squared_error: 0.6084\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.4222 - root_mean_squared_error: 0.7740 - val_loss: 6.1267 - val_root_mean_squared_error: 0.5765\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.3368 - root_mean_squared_error: 0.7365 - val_loss: 6.0395 - val_root_mean_squared_error: 0.5237\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.3223 - root_mean_squared_error: 0.7464 - val_loss: 5.9626 - val_root_mean_squared_error: 0.4762\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.1776 - root_mean_squared_error: 0.6646 - val_loss: 5.9352 - val_root_mean_squared_error: 0.4782\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.1425 - root_mean_squared_error: 0.6603 - val_loss: 5.9372 - val_root_mean_squared_error: 0.5099\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 6.1706 - root_mean_squared_error: 0.7024 - val_loss: 5.9253 - val_root_mean_squared_error: 0.5264\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.1320 - root_mean_squared_error: 0.6955 - val_loss: 5.8968 - val_root_mean_squared_error: 0.5268\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.0760 - root_mean_squared_error: 0.6758 - val_loss: 5.8521 - val_root_mean_squared_error: 0.5116\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 6.0190 - root_mean_squared_error: 0.6547 - val_loss: 5.8060 - val_root_mean_squared_error: 0.4943\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.9664 - root_mean_squared_error: 0.6362 - val_loss: 5.7652 - val_root_mean_squared_error: 0.4819\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.9608 - root_mean_squared_error: 0.6540 - val_loss: 5.7389 - val_root_mean_squared_error: 0.4843\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.9124 - root_mean_squared_error: 0.6388 - val_loss: 5.7169 - val_root_mean_squared_error: 0.4913\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.9306 - root_mean_squared_error: 0.6745 - val_loss: 5.6923 - val_root_mean_squared_error: 0.4957\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.8966 - root_mean_squared_error: 0.6708 - val_loss: 5.6529 - val_root_mean_squared_error: 0.4853\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.9122 - root_mean_squared_error: 0.7035 - val_loss: 5.6150 - val_root_mean_squared_error: 0.4765\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.7960 - root_mean_squared_error: 0.6388 - val_loss: 5.5791 - val_root_mean_squared_error: 0.4695\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.7345 - root_mean_squared_error: 0.6131 - val_loss: 5.5664 - val_root_mean_squared_error: 0.4868\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.7109 - root_mean_squared_error: 0.6176 - val_loss: 5.5371 - val_root_mean_squared_error: 0.4866\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 5.6924 - root_mean_squared_error: 0.6261 - val_loss: 5.5113 - val_root_mean_squared_error: 0.4897\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.6708 - root_mean_squared_error: 0.6319 - val_loss: 5.4804 - val_root_mean_squared_error: 0.4874\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.6688 - root_mean_squared_error: 0.6527 - val_loss: 5.4452 - val_root_mean_squared_error: 0.4805\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.5685 - root_mean_squared_error: 0.5951 - val_loss: 5.4043 - val_root_mean_squared_error: 0.4672\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.5654 - root_mean_squared_error: 0.6160 - val_loss: 5.3730 - val_root_mean_squared_error: 0.4639\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.5218 - root_mean_squared_error: 0.6034 - val_loss: 5.3421 - val_root_mean_squared_error: 0.4610\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.4910 - root_mean_squared_error: 0.6012 - val_loss: 5.3177 - val_root_mean_squared_error: 0.4651\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.4547 - root_mean_squared_error: 0.5944 - val_loss: 5.2874 - val_root_mean_squared_error: 0.4626\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.4635 - root_mean_squared_error: 0.6246 - val_loss: 5.2628 - val_root_mean_squared_error: 0.4664\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.3932 - root_mean_squared_error: 0.5899 - val_loss: 5.2281 - val_root_mean_squared_error: 0.4595\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.3875 - root_mean_squared_error: 0.6087 - val_loss: 5.2008 - val_root_mean_squared_error: 0.4603\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.3291 - root_mean_squared_error: 0.5833 - val_loss: 5.1741 - val_root_mean_squared_error: 0.4615\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.3231 - root_mean_squared_error: 0.6017 - val_loss: 5.1484 - val_root_mean_squared_error: 0.4637\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.2845 - root_mean_squared_error: 0.5926 - val_loss: 5.1246 - val_root_mean_squared_error: 0.4677\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.2770 - root_mean_squared_error: 0.6092 - val_loss: 5.0942 - val_root_mean_squared_error: 0.4645\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.2577 - root_mean_squared_error: 0.6158 - val_loss: 5.0657 - val_root_mean_squared_error: 0.4629\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.2115 - root_mean_squared_error: 0.6002 - val_loss: 5.0424 - val_root_mean_squared_error: 0.4671\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.1785 - root_mean_squared_error: 0.5952 - val_loss: 5.0125 - val_root_mean_squared_error: 0.4640\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.1539 - root_mean_squared_error: 0.5972 - val_loss: 4.9892 - val_root_mean_squared_error: 0.4678\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 5.1099 - root_mean_squared_error: 0.5827 - val_loss: 4.9631 - val_root_mean_squared_error: 0.4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_227558/3436213725.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_227558/2713887723.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, df_train, df_test)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mret_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mskn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'skn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_by_station\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mret_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_227558/2713887723.py\u001b[0m in \u001b[0;36mevaluate_by_station\u001b[0;34m(self, df_train, df_test, skn)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# train the model with retrain_full = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrain_full\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# make prediction and scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_227558/2713887723.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, verbose, retrain_full)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mvalid_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         history = self.model.fit_generator(\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0mtrain_datagen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[0;32m-> 1847\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1848\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/climate/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# n_model.evaluate(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7efab22f-9bf9-4d02-a5fc-b8c842ada832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'skn': 54.0, 'rmse_nn': 4.8431024466497705, 'mae_nn': 3.0914463170980784},\n",
       " {'skn': 79.0, 'rmse_nn': 6.368086866764725, 'mae_nn': 4.105100464089943},\n",
       " {'skn': 87.0, 'rmse_nn': 5.208669796473459, 'mae_nn': 3.37957601492572},\n",
       " {'skn': 250.0, 'rmse_nn': 2.2157803460396273, 'mae_nn': 1.3270023535467255},\n",
       " {'skn': 267.0, 'rmse_nn': 2.2336697521762474, 'mae_nn': 1.4160992786791415},\n",
       " {'skn': 296.1, 'rmse_nn': 1.1442526100796995, 'mae_nn': 0.6380257667766676},\n",
       " {'skn': 311.0, 'rmse_nn': 1.2396139381603444, 'mae_nn': 0.5953852845453154},\n",
       " {'skn': 338.0, 'rmse_nn': 2.672605371750324, 'mae_nn': 1.8492123743180304},\n",
       " {'skn': 396.0, 'rmse_nn': 1.2921348638193793, 'mae_nn': 0.743996364183915},\n",
       " {'skn': 400.0, 'rmse_nn': 1.3514261195929214, 'mae_nn': 0.8701712177934825},\n",
       " {'skn': 406.0, 'rmse_nn': 1.6197638161201364, 'mae_nn': 1.1496237303210841},\n",
       " {'skn': 410.0, 'rmse_nn': 1.4479689882305888, 'mae_nn': 0.9798297832562373},\n",
       " {'skn': 485.0, 'rmse_nn': 1.85977139749722, 'mae_nn': 1.403804300748385},\n",
       " {'skn': 702.7, 'rmse_nn': 1.2675473860764785, 'mae_nn': 0.7156845442216466},\n",
       " {'skn': 703.0, 'rmse_nn': 1.3979935210668848, 'mae_nn': 0.8194517620564393},\n",
       " {'skn': 718.0, 'rmse_nn': 4.3038270416199165, 'mae_nn': 3.2910321376526275},\n",
       " {'skn': 770.0, 'rmse_nn': 1.9244455435715058, 'mae_nn': 1.2367707405576278},\n",
       " {'skn': 783.0, 'rmse_nn': 4.585263882827174, 'mae_nn': 3.1718387969128488},\n",
       " {'skn': 784.0, 'rmse_nn': 5.019178110576687, 'mae_nn': 4.19729157125874},\n",
       " {'skn': 965.0, 'rmse_nn': 1.8920033170824442, 'mae_nn': 1.0620319257944058},\n",
       " {'skn': 1020.1, 'rmse_nn': 2.4444345175568185, 'mae_nn': 1.497139049266775},\n",
       " {'skn': 1075.0, 'rmse_nn': 2.9113734118339902, 'mae_nn': 1.880179319693372},\n",
       " {'skn': 1117.0, 'rmse_nn': 3.5271158741566127, 'mae_nn': 2.2934690295121607},\n",
       " {'skn': 1134.0, 'rmse_nn': 2.938571548992674, 'mae_nn': 1.9404979308446242}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_vals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate",
   "language": "python",
   "name": "climate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
